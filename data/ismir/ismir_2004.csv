Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,Samer M. Abdallah;Mark D. Plumbley,Polyphonic transcription by non-negative sparse coding of power spectra.,2004,https://doi.org/10.5281/zenodo.1415072,"Samer A. Abdallah+Queen Mary, University of London>GBR>education|Centre for Digital Music>GBR>facility;Mark D. Plumbley+Queen Mary, University of London>GBR>education|Centre for Digital Music>GBR>facility","We present a system for adaptive spectral basis decomposition that learns to identify independent spectral features given a sequence of short-term Fourier spectra. When applied to recordings of polyphonic piano music, the individual notes are identified as salient features, and hence each short-term spectrum is decomposed into a sum of note spectra; the resulting encoding can be used as a basis for polyphonic transcription. The system is based on a probabilistic model equivalent to a form of noisy independent component analysis (ICA) or sparse coding with non-negativity constraints. We introduce a novel modification to this model that recognises that a short-term Fourier spectrum can be thought of as a noisy realisation of the power spectral density of an underlying Gaussian process, where the noise is essentially multiplicative and non-Gaussian. Results are presented for an analysis of a live recording of polyphonic piano music."
1,Norman H. Adams;Mark A. Bartsch;Jonah Shifrin;Gregory H. Wakefield,Time Series Alignment for Music Information Retrieval.,2004,https://doi.org/10.5281/zenodo.1415694,Norman H. Adams+University of Michigan>USA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Mark A. Bartsch+University of Michigan>USA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Jonah B. Shifrin+University of Michigan>USA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Gregory H. Wakefield+University of Michigan>USA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown,"Time series representations are common in MIR applications such as query-by-humming, where a sung query might be represented by a series of ‘notes’ for database retrieval. While such a transcription into a sequence of (pitch, duration) pairs is convenient and musically intuitive, there is no evidence that it is an optimal representation. The present work explores three time series representations for sung queries: a sequence of notes, a ‘smooth’ pitch contour, and a novel sequence of pitch histograms. Dynamic alignment procedures are described for the three representations. Multiple continuity constraints are explored and a modified dynamic alignment procedure is described for the histogram representation. We measure the performance of the three representations using a collection of naturally sung queries applied to a target database of varying size. The results show that the note representation lends itself to rapid retrieval whereas the contour representation lends itself to robust performance. The histogram representation yields performance nearly as robust as the contour representation, but with computational complexity similar to the note representation."
2,Philippe Aigrain,Whose future is it?,2004,https://doi.org/10.5281/zenodo.1416404,Philippe Aigrain+Sopinspace>ESP>company,""""""
3,Miguel A. Alonso;Gaël Richard;Bertrand David,Tempo And Beat Estimation Of Musical Signals.,2004,https://doi.org/10.5281/zenodo.1415784,Miguel Alonso+ENST-GET>FRA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Bertrand David+ENST-GET>FRA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Gaël Richard+ENST-GET>FRA>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown,"Tempo estimation is fundamental in automatic music processing and in many multimedia applications. This paper presents an automatic tempo tracking system that processes audio recordings and determines the beats per minute and temporal beat location. The concept of spectral energy flux is deﬁned and leads to an efﬁcient note onset detector. The algorithm involves three stages: a front-end analysis that efﬁciently extracts onsets, a periodicity detection block and the temporal estimation of beat locations. The performance of the proposed method is evaluated using a large database of 489 excerpts from several musical genres. The global recognition rate is 89.7 %. Results are discussed and compared to other tempo estimation systems."
4,Jean-Julien Aucouturier;François Pachet,Tools and Architecture for the Evaluation of Similarity Measures : Case Study of Timbre Similarity.,2004,https://doi.org/10.5281/zenodo.1416562,Jean-Julien Aucouturier+SONY CSL Paris>FRA>company|SONY CSL Paris>FRA>company;Francois Pachet+SONY CSL Paris>FRA>company|SONY CSL Paris>FRA>company,"The systematic testing of the very many parameters and algorithmic variants involved in the design of high-level music descriptors at large, and similarity measure in particular, is a daunting task, which requires the building of a general architecture which is nearly as complex as a full-fledged Music Browsing system. In this paper, we report on experiments done in an attempt to improve the performance of the music similarity measure described in [2], using the Cuidado Music Browser ([8]). We do not principally report on the actual results of the evaluation, but rather on the methodology and the various tools that were built to support such a task. We show that many non-technical browsing features are useful at various stages of the evaluation process, and in turn that some of the tools developed for the expert user can be reinjected into the Music Browser, and benefit the non-technical user."
5,Jean-Julien Aucouturier;François Pachet;Peter Hanappe,From Sound Sampling To Song Sampling.,2004,https://doi.org/10.5281/zenodo.1416028,Jean-Julien Aucouturier+SONY CSL Paris>FRA>company;Francois Pachet+SONY CSL Paris>FRA>company;Peter Hanappe+SONY CSL Paris>FRA>company,"This paper proposes to use the techniques of Music Information Retrieval in the context of Music Interaction. We describe a system, the SongSampler, inspired by the technology of audio sampling, which automatically samples a song to produce an instrument (typically using a MIDI keyboard) that plays sounds found in the original audio file. Playing with such an instrument creates an original situation in which listeners play their own music with the sounds of their favourite tunes, in a constant interaction with a music database. The paper describes the main technical issues at stake concerning the integration of music information retrieval in an interactive instrument, and reports on preliminary experiments."
6,David Bainbridge 0001;Sally Jo Cunningham;J. Stephen Downie,GREENSTONE as a Music Digital Library Toolkit.,2004,https://doi.org/10.5281/zenodo.1417573,David Bainbridge+University of Waikato>NZL>education;Sally Jo Cunningham+University of Waikato>NZL>education;J. Stephen Downie+University of Illinois>USA>education,""""""
7,David Bainbridge 0001;Sally Jo Cunningham;J. Stephen Downie,Visual Collaging Of Music In A Digital Library.,2004,https://doi.org/10.5281/zenodo.1415832,David Bainbridge+University of Waikato>NZL>education;Sally Jo Cunningham+University of Waikato>NZL>education;J. Stephen Downie+University of Illinois>USA>education,"This article explores the role visual browsing can play within a digital music library. The context to the work is provided through a review of related techniques drawn from the fields of digital libraries and human computer interaction. Implemented within the open source digital library toolkit Greenstone, a prototype system is described that combines images located through textual metadata with a visualisation technique known as collaging to provide a leisurely, undirected interaction with a music collection. Emphasis in the article is given to the augmentations of the basic technique to work in the musical domain."
8,Roberto Basili 0001;Alfredo Serafini;Armando Stellato,Classification of musical genre: a machine learning approach.,2004,https://doi.org/10.5281/zenodo.1416754,Roberto Basili+University of Rome Tor Vergata>ITA>education;Alfredo Serafini+University of Rome Tor Vergata>ITA>education;Armando Stellato+University of Rome Tor Vergata>ITA>education,"In this paper, we investigate the impact of machine learning algorithms in the development of automatic music classification models aiming to capture genres distinctions. The study of genres as bodies of musical items aggregated according to subjective and local criteria requires corresponding inductive models of such a notion. This process can be thus modeled as an example-driven learning task. We investigated the impact of different musical features on the inductive accuracy by first creating a medium-sized collection of examples for widely recognized genres and then evaluating the performances of different learning algorithms. In this work, features are derived from the MIDI transcriptions of the song collection."
9,Stephan Baumann 0001;Tim Pohle;Shankar Vembu,Towards a Socio-cultural Compatibility of MIR Systems.,2004,https://doi.org/10.5281/zenodo.1417733,Stephan Baumann+German Research Center for Artificial Intelligence>DEU>facility|Technical University of Hamburg>DEU>education;Tim Pohle+German Research Center for Artificial Intelligence>DEU>facility|Technical University of Hamburg>DEU>education;Vembu Shankar+German Research Center for Artificial Intelligence>DEU>facility|Technical University of Hamburg>DEU>education,"Future MIR systems will be of great use and pleasure for potential users. If researchers have a clear picture about their “customers” in mind they can aim at building and evaluating their systems exactly inside the different socio-cultural environments of such music listeners. Since music is in most cases embedded into a socio-cultural process we propose especially to evaluate MIR applications outside the lab during daily activities. For this purpose we designed a mobile music recommendation system relying on a trimodal music similarity metric, which allows for subjective on-the-fly adjustments of recommendations. It offers online access to large-scale metadata repositories as well as an audio database containing 1000 songs. We did first small-scale evaluations of this approach and came to interesting results regarding the perception of song similarity concerning the relations between sound, cultural issues and lyrics. Our paper will also give insights to the three different underlying approaches for song similarity computation (sound, cultural issues, lyrics), focusing in detail on a novel clustering of album reviews as found at online music retailers. Keywords: Socio-cultural issues in MIR, multimodal song similarity, ecological validation."
10,Paul Brossier;Juan Pablo Bello;Mark D. Plumbley,Fast labelling of notes in music signals.,2004,https://doi.org/10.5281/zenodo.1416132,"Paul M. Brossier+Queen Mary College, University of London>GBR>education;Juan P. Bello+Queen Mary College, University of London>GBR>education;Mark D. Plumbley+Queen Mary College, University of London>GBR>education","We present a new system for the estimation of note attributes from a live monophonic music source, within a short time delay and without any previous knowledge of the signal. The labelling is based on the temporal segmentation and the successive estimation of the fundamental frequency of the current note object. The setup, implemented around a small C library, is directed at the robust note segmentation of a variety of audio signals. A system for evaluation of performances is also presented. The further extension to polyphonic signals is considered, as well as design concerns such as portability and integration in other software environments."
11,Pedro Cano;Markus Koppenberger,The emergence of complex network patterns in music networks.,2004,https://doi.org/10.5281/zenodo.1417663,"Pedro Cano+Institut de l’Audiovisual, Universitat Pompeu Fabra>ESP>education;Markus Koppenberger+Institut de l’Audiovisual, Universitat Pompeu Fabra>ESP>education","Viewing biological, social or technological systems as networks formed by nodes and connections between them can help better understand them. We study the topology of several music networks, namely citation in allmusic.com and co-occurrence of artists in playlists. The analysis uncovers the emergence of complex network phenomena in music information networks built considering artists as nodes and its relations as links. The properties provide some hints on searchability and possible optimizations in the design of music recommendation systems. It may also provide a deeper understanding on the similarity measures that can be derived from existing music knowledge sources."
12,Michael A. Casey;Tim Crawford,Automatic Location And Measurement Of Score-based Gestures In Audio Recordings.,2004,https://doi.org/10.5281/zenodo.1415184,Michael Casey+Goldsmiths College University of London>GBR>education;Tim Crawford+Goldsmiths College University of London>GBR>education,"This paper reports on our first experiments in using the feature extraction tools of the MPEG-7 international standard for multimedia content description on a novel problem, the automatic identification and analysis of score-based performance features in audio recordings of music. Our test material consists of recordings of two pieces of 17th- and 18th-century lute music in which our aim is to recognise and isolate performance features such as trills and chord-spreadings. Using the audio tools from the MPEG-7 standard facilitates interoperability and allows us to share both score and audio metadata. As well as using low-level audio MIR techniques within this MPEG-7 context, the work has potential importance as an ‘ornamentation filter’ for MIR systems. It may also form a useful component in methods for instrumental performer identification."
13,Òscar Celma,Architecture for an MPEG-7 Web Browser.,2004,https://doi.org/10.5281/zenodo.1417229,Oscar Celma+Universitat Pompeu Fabra>ESP>education,The MPEG-7 standard provides description mechanisms and taxonomy management for multimedia documents. There are several approaches to design a multimedia database system using MPEG-7 descriptors. We discuss two of them: relational databases and native XML databases. We have implemented a search and retrieval application for MPEG-7 descriptions based on the latter.
14,Fernando William Cruz;Edilson Ferneda;Márcio da Costa P. Brandão;Evandro de Barros Costa;Hyggo Oliveira de Almeida;Murilo Bastos da Cunha;Rafael de Sousa;João Denicol;Carlos da Silva,A Brazilian Popular Music Oriented Digital Library For Musical Harmony E-Learning.,2004,https://doi.org/10.5281/zenodo.1417042,Fernando W. Cruz+Catholic University of Brasília>BRA>education;Edilson Ferneda+Catholic University of Brasília>BRA>education;Márcio Brandão+University of Brasília>BRA>education;Evandro de B. Costa+Federal University of Alagoas>BRA>education;Hyggo O. de Almeida+Federal University of Campina Grande>BRA>education;Murilo B. da Cunha+University of Brasília>BRA>education;Rafael T. de Sousa Jr.+University of Brasília>BRA>education;João Ricardo E. Denicol+Catholic University of Brasília>BRA>education;Carlos Alan P. da Silva+Federal University of Campina Grande>BRA>education,"This poster presents a digital library proposal conceived for people interested in acquiring knowledge about Brazilian popular music harmony, particularly in Choro. This Brazilian musical style is a complex popular music form based on improvisation, although it contains classical music elements such as the counterpoint. We are proposing two ways of accessing the music virtual library content: a guided navigation mode, in which users interact with a cooperative Web-based learning system; and a free navigation mode, in which users can make their own queries, both through browsers or client applications."
15,Roger B. Dannenberg;Ning Hu,Understanding Search Performance in Query-by-Humming Systems.,2004,https://doi.org/10.5281/zenodo.1416900,Roger B. Dannenberg+Carnegie Mellon University>USA>education;Ning Hu+Carnegie Mellon University>USA>education,"Previous work in Query-by-Humming systems has left open many questions. Although a variety of techniques have been explored, there has been relatively little work to compare them under controlled conditions, especially with “real” audio queries from human subjects. Previous work comparing note-interval matching, melodic contour matching, and HMM-based matching is extended with comparisons to the Phillips CubyHum algorithm and various n-gram search algorithms. We also explore the sensitivity of note-interval dynamic programming searches to different parameters and consider two-stage searches combining a fast n-gram search with a more precise but slower dynamic programming algorithm."
16,Laurent Daudet;Gaël Richard;Pierre Leveau,Methodology and Tools for the evaluation of automatic onset detection algorithms in music.,2004,https://doi.org/10.5281/zenodo.1417247,Pierre Leveau+Laboratoire d’Acoustique Musicale>FRA>facility;Laurent Daudet+Laboratoire d’Acoustique Musicale>FRA>facility;Gaël Richard+GET - ENST (Télécom Paris)>FRA>education,"This paper addresses the problem of the performance evaluation of algorithms for the automatic detection of note onsets in music signals. Our experiments show that creating a database of reference files with reliable human-annotated onset times is a complex task, since its subjective part cannot be neglected. This work provides a methodology to construct such a database. With the use of a carefully designed software tool, called SOL (Sound Onset Labellizer), we can obtain a set of reference onset times that are cross-validated amongst different expert listeners. We show that the mean error of annotated times across test subjects is very much signal-dependent. This value can be used, when evaluating automatic labelling, as an indication of the relevant tolerance window. The SOL annotation software is to be released freely for research purposes. Our test library, 17 short sequences containing about 750 onsets, comes from copyright-free music or from the public RWC database. The corresponding validated onset labels are also freely distributed, and are intended to form the starting point for the definition of a reliable benchmark."
17,Matthew E. P. Davies;Mark D. Plumbley,Causal Tempo Tracking of Audio.,2004,https://doi.org/10.5281/zenodo.1417873,Matthew E. P. Davies+Queen Mary University of London>GBR>education;Mark D. Plumbley+Queen Mary University of London>GBR>education,"We introduce a causal approach to tempo tracking for musical audio signals. Our system is designed towards an eventual real-time implementation; requiring minimal high-level knowledge of the musical audio. The tempo tracking system is divided into two sections: an onset analysis stage, used to derive a rhythmically meaningful representation from the input audio, followed by a beat matching algorithm using auto- and cross-correlative methods to generate short term predictions of future beats in the audio. The algorithm is evaluated over a range of musical styles by comparing the predicted output to beats tapped by a musician. An investigation is also presented into three rhythmically complex beat tracking problems, where the tempo is not constant. Preliminary results demonstrate good accuracy for this type of system."
18,Simon Dixon;Fabien Gouyon;Gerhard Widmer,Towards Characterisation of Music via Rhythmic Patterns.,2004,https://doi.org/10.5281/zenodo.1416220,Simon Dixon+Austrian Research Institute for AI>AUT>facility;Fabien Gouyon+Universitat Pompeu Fabra>ESP>education;Gerhard Widmer+Medical University of Vienna>AUT>education,"A central problem in music information retrieval is finding suitable representations which enable efficient and accurate computation of musical similarity and identity. Low level audio features are ideal for calculating identity, but are of limited use for similarity measures, as many aspects of music can only be captured by considering high level features. We present a new method of characterising music by typical bar-length rhythmic patterns which are automatically extracted from the audio signal, and demonstrate the usefulness of this representation by its application in a genre classification task. Recent work has shown the importance of tempo and periodicity features for genre recognition, and we extend this research by employing the extracted temporal patterns as features. Standard classification algorithms are utilised to discriminate 8 classes of Standard and Latin ballroom dance music (698 pieces). Although pattern extraction is error-prone, and patterns are not always unique to a genre, classification by rhythmic pattern alone achieves up to 50% correctness (baseline 16%), and by combining with other features, a classification rate of 96% is obtained."
19,Shyamala Doraisamy;Stefan M. Rüger,A Polyphonic Music Retrieval System Using N-Grams.,2004,https://doi.org/10.5281/zenodo.1417961,Shyamala Doraisamy+University Putra Malaysia>MYS>education;Stefan Rüger+Imperial College London>GBR>education,"This paper describes the development of a polyphonic music retrieval system with the n-gram approach. Musical n-grams are constructed from polyphonic musical performances in MIDI using the pitch and rhythm dimensions of music. These are encoded using text characters enabling the musical words generated to be indexed with existing text search engines. The Lemur Toolkit was adapted for the development of a demonstrator system on a collection of around 10,000 polyphonic MIDI performances. The indexing, search and retrieval with musical n-grams and this toolkit have been extensively evaluated through a series of experimental work over the past three years, published elsewhere. We discuss how the system works internally and describe our proposal for enhancements to Lemur towards the indexing of ‘overlaying’ as opposed to indexing a ‘bag of terms’. This includes enhancements to the parser for a ‘polyphonic musical word indexer’ to incorporate within document position information when indexing adjacent and concurrent musical words. For retrieval of these ‘overlaying’ musical words, a new proximity-based operator and a ranking function is proposed."
20,Michael Droettboom;Ichiro Fujinaga,Micro-level groundtruthing environment for OMR.,2004,https://doi.org/10.5281/zenodo.1417217,Michael Droettboom+The Johns Hopkins University>USA>education|Digital Knowledge Center>USA>facility;Ichiro Fujinaga+McGill University>CAN>education|CIRMMT>CAN>facility,"A simple framework for evaluating OMR at the symbol level is presented. While a true evaluation of an OMR system requires a high-level analysis, the automation of which is a largely unsolved problem, many high-level errors are correlated to these more tractably-analyzed lower-level errors."
21,Tuomas Eerola;Petri Toiviainen,MIR In Matlab: The MIDI Toolbox.,2004,https://doi.org/10.5281/zenodo.1416234,Tuomas Eerola+University of Jyväskylä>FIN>education;Petri Toiviainen+University of Jyväskylä>FIN>education,"""The MIDI Toolbox is a compilation of functions for analyzing and visualizing MIDI files in the Matlab computing environment. In this article, the basic issues of the Toolbox are summarized and demonstrated with examples ranging from melodic contour, similarity, key-finding, meter-finding to segmentation. The Toolbox is based on symbolic musical data but signal processing methods are applied to cover such aspects of musical behaviour as geometric representations and short-term memory. Besides simple manipulation and filtering functions, the toolbox contains cognitively inspired analytic techniques that are suitable for context-dependent musical analysis, a prerequisite for many music information retrieval applications."""
22,Jana Eggink;Guy J. Brown,Extracting Melody Lines From Complex Audio.,2004,https://doi.org/10.5281/zenodo.1418003,Jana Eggink+University of Sheffield>GBR>education;Guy J. Brown+University of Sheffield>GBR>education,"""We propose a system which extracts the melody line played by a solo instrument from complex audio. At every time frame multiple fundamental frequency (F0) hypotheses are generated, and later processing uses various knowledge sources to choose the most likely succession of F0s. Knowledge sources include an instrument recognition module and temporal knowledge about tone durations and interval transitions, which are integrated in a probabilistic search. The proposed system improved the number of frames with correct F0 estimates by 14% compared to a baseline system which simply uses the strongest F0 at every point in time. The number of spurious tones was reduced to nearly a third compared to the baseline system, resulting in significantly smoother melody lines."""
23,Dan Ellis;John Arroyo,Eigenrhythms: Drum pattern basis sets for classification and generation.,2004,https://doi.org/10.5281/zenodo.1415948,Daniel P. W. Ellis+Columbia University>USA>education;John Arroyo+Columbia University>USA>education,"We took a collection of 100 drum beats from popular music tracks and estimated the measure length and downbeat position of each one. Using these values, we normalized each pattern to form an ensemble of aligned drum patterns. Principal Component Analysis on this data set results in a set of basis ‘patterns’ that can be combined to give approximations and interpolations of all the examples. We use this low-dimension representation of the drum patterns as a space for classification and visualization, and discuss its application to generating continua of rhythms. Our classification results were very modest – about 20% correct on a 10-way genre classification task – but we show that the projection into principal component space reveals aspects of the rhythm that are largely orthogonal to genre but are still perceptually relevant."
24,Slim Essid;Gaël Richard;Bertrand David,Musical instrument recognition based on class pairwise feature selection.,2004,https://doi.org/10.5281/zenodo.1418253,Slim ESSID+GET-ENST (Télécom Paris)>FRA>education;Gaël RICHARD+GET-ENST (Télécom Paris)>FRA>education;Bertrand DAVID+GET-ENST (Télécom Paris)>FRA>education,"In this work, musical instrument recognition is considered on solo music from real world performance. A large sound database is used that consists of musical phrases excerpted from commercial recordings with different instrument instances, different players, and varying recording conditions. The proposed recognition scheme exploits class pairwise feature selection based on inertia ratio maximization. Moreover, new signal processing features based on octave band energy measures are introduced that prove to be useful. Classification is performed using Gaussian Mixture Models in a one vs one fashion in association with a data rescaling procedure as pre-processing. Experimental results show that substantial improvement in recognition success is thus achieved."
25,Klaus Frieler,Beat and meter extraction using gaussified onsets.,2004,https://doi.org/10.5281/zenodo.1417851,Klaus Frieler+University of Hamburg>DEU>education,"Rhythm, beat and meter are key concepts of music in general. Many efforts had been made in the last years to automatically extract beat and meter from a piece of music given either in audio or symbolical representation (see e.g. [11] for an overview). In this paper we propose a new method for extracting beat, meter and phase information from a list of unquantized onset times. The procedure relies on a novel method called ’Gaussiﬁcation’ and adopts correlation techniques combined with findings from music psychology for parameter settings."
26,Emilia Gómez;Perfecto Herrera,Estimating The Tonality Of Polyphonic Audio Files: Cognitive Versus Machine Learning Modelling Strategies.,2004,https://doi.org/10.5281/zenodo.1418007,Emilia Gómez+Universitat Pompeu Fabra>ESP>education;Perfecto Herrera+Universitat Pompeu Fabra>ESP>education,"In this paper we evaluate two methods for key estimation from polyphonic audio recordings. Our goal is to compare between a strategy using a cognition-inspired model and several machine learning techniques to find a model for tonality (mode and key note) determination of polyphonic music from audio files. Both approaches have as an input a vector of values related to the intensity of each of the pitch classes of a chromatic scale. In this study, both methods are explained and evaluated in a large database of audio recordings of classical pieces."
27,Masataka Goto;Katunobu Itou;Koji Kitayama;Tetsunori Kobayashi,Speech-Recognition Interfaces for Music Information Retrieval: 'Speech Completion' and 'Speech Spotter'.,2004,https://doi.org/10.5281/zenodo.1417339,Masataka Goto+National Institute of Advanced Industrial Science and Technology (AIST)>JPN>facility|Waseda University>JPN>education;Katunobu Itou+Nagoya University>JPN>education;Koji Kitayama+National Institute of Advanced Industrial Science and Technology (AIST)>JPN>facility|Waseda University>JPN>education;Tetsunori Kobayashi+National Institute of Advanced Industrial Science and Technology (AIST)>JPN>facility|Waseda University>JPN>education,"This paper describes music information retrieval (MIR) systems featuring automatic speech recognition. Although various interfaces for MIR have been proposed, speech-recognition interfaces suitable for retrieving musical pieces have not been studied. We propose two different speech-recognition interfaces for MIR, speech completion and speech spotter, and describe two MIR-based hands-free jukebox systems that enable a user to retrieve and play back a musical piece by saying its title or the artist’s name. The first is a music-retrieval system with the speech-completion interface that is suitable for music stores and car-driving situations. When a user can remember only part of the name of a musical piece or an artist and utters only a remembered fragment, the system helps the user recall and enter the name by completing the fragment. The second is a background-music playback system with the speech-spotter interface that can enrich human-human conversation. When a user is talking to another person, the system allows the user to enter voice commands for music-playback control by spotting a special voice-command utterance in face-to-face or telephone conversations. Our experimental results from use of these systems have demonstrated the effectiveness of the speech-completion and speech-spotter interfaces."
28,Fabien Gouyon;Simon Dixon,Dance music classification: A tempo-based approach.,2004,https://doi.org/10.5281/zenodo.1416636,Fabien Gouyon+Universitat Pompeu Fabra>ESP>education|Austrian Research Institute for AI>AUT>facility;Simon Dixon+Austrian Research Institute for AI>AUT>facility,"Recent research has studied the relevance of various features for automatic genre classification, showing the particular importance of tempo in dance music classification. We complement this work by considering a domain-specific learning methodology, where the computed tempo is used to select an expert classifier which has been specialized on its own tempo range. This enables the all-class learning task to be reduced to a set of two- and three-class learning tasks. Current results are around 70% classification accuracy (8 ballroom dance music classes, 698 instances, baseline 15.9%)."
29,Maarten Grachten;Josep Lluís Arcos;Ramón López de Mántaras,Melodic Similarity: Looking for a Good Abstraction Level.,2004,https://doi.org/10.5281/zenodo.1417403,Maarten Grachten+IIIA-CSIC - Artificial Intelligence Research Institute>ESP>facility|CSIC - Spanish Council for Scientific Research>ESP>facility;Josep-Lluís Arcos+IIIA-CSIC - Artificial Intelligence Research Institute>ESP>facility|CSIC - Spanish Council for Scientific Research>ESP>facility;Ramon López de Mántaras+IIIA-CSIC - Artificial Intelligence Research Institute>ESP>facility|CSIC - Spanish Council for Scientific Research>ESP>facility,"Computing melodic similarity is a very general problem with diverse musical applications ranging from music analysis to content-based retrieval. Choosing the appropriate level of representation is a crucial issue and depends on the type of application. Our research interest concerns the development of a CBR system for expressive music processing. In that context, a well chosen distance measure for melodies is a crucial issue. In this paper we propose a new melodic similarity measure based on the I/R model for melodic structure and compare it with other existing measures. The experimentation shows that the proposed measure provides a good compromise between discriminatory power and ability to recognize phrases from the same song."
30,Matthias Gruhne;Christian Uhle;Christian Dittmar;Markus Cremer,Extraction of Drum Patterns and their Description within the MPEG-7 High-Level-Framework.,2004,https://doi.org/10.5281/zenodo.1414888,Matthias Gruhne+Fraunhofer IDMT>DEU>facility;Christian Uhle+Fraunhofer IDMT>DEU>facility;Christian Dittmar+Fraunhofer IDMT>DEU>facility;Markus Cremer+Fraunhofer IDMT>DEU>facility,"A number of metadata standards have been published in recent years due to the increasing availability of multimedia content and the resulting issue of sorting and retrieving this content. One of the most recent efforts for a well defined metadata description is the ISO/IEC MPEG-7 standard, which takes a very broad approach towards the definition of metadata. Herein, not merely hand annotated textual information can be transported and stored, but also more signal specific data that can in most cases be automatically retrieved from the multimedia content itself. In this publication an algorithm for the automated transcription of rhythmic (percussive) accompaniment in modern day popular music is described. However, the emphasis here is not a precise transcription, but on capturing the “rhythmic gist” of the piece of music in order to allow a more abstract comparison of musical pieces by their dominant rhythmic patterns. A small-scale evaluation of the algorithm is presented along with an example representation of the thus gained semantically meaningful metadata using description methods currently discussed within MPEG-7."
31,AnYuan Guo;Hava T. Siegelmann,Time-Warped Longest Common Subsequence Algorithm for Music Retrieval.,2004,https://doi.org/10.5281/zenodo.1417165,An Yuan Guo+University of Massachusetts>USA>education;Hava Siegelmann+University of Massachusetts>USA>education,"Recent advances in music information retrieval have enabled users to query a database by singing or humming into a microphone. The queries are often inaccurate versions of the original songs due to singing errors and errors introduced in the music transcription process. In this paper, we present the Time-Warped Longest Common Subsequence algorithm (T-WLCS), which deals with singing errors involving rhythmic distortions. The algorithm is employed on song retrieval tasks, where its performance is compared to the longest common subsequence algorithm."
32,Jin Ha Lee;J. Stephen Downie,"Survey Of Music Information Needs, Uses, And Seeking Behaviours: Preliminary Findings.",2004,https://doi.org/10.5281/zenodo.1417637,Jin Ha Lee+University of Illinois at Urbana-Champaign>USA>education;J. Stephen Downie+University of Illinois at Urbana-Champaign>USA>education,"User studies focusing upon real-life music information needs, uses and seeking behaviours are still very scarce in the music information retrieval (MIR) and music digital library (MDL) fields. We are conducting a multi-group survey in an attempt to acquire information that can help eradicate false assumptions in designing MIR systems. Our goal is to provide an empirical basis for MIR/MDL system development. In this paper, we present our preliminary findings and analyses based on the 427 user responses we have received to date. Two major themes have been uncovered thus far that could have a significant influence the future development of successful MIR/MDL systems. First, people display “public information-seeking” behaviours by making use of collective knowledge and/or opinions of others about music such as reviews, ratings, recommendations, etc. in their music information-seeking. Second, respondents expressed needs for contextual metadata in addition to traditional bibliographic metadata."
33,Pierre Hanna;Nicolas Louis;Myriam Desainte-Catherine;Jenny Benois-Pineau,Audio Features for Noisy Sound Segmentation.,2004,https://doi.org/10.5281/zenodo.1415214,Pierre Hanna+SCRIME - LaBRI>FRA>facility|Université de Bordeaux 1>FRA>education;Nicolas Louis+SCRIME - LaBRI>FRA>facility|Université de Bordeaux 1>FRA>education;Myriam Desainte-Catherine+SCRIME - LaBRI>FRA>facility|Université de Bordeaux 1>FRA>education;Jenny Benois-Pineau+SCRIME - LaBRI>FRA>facility|Université de Bordeaux 1>FRA>education,"Automatic audio classification usually considers sounds as music, speech, silence or noise, but works about the noise class are rare. Audio features are generally specific to speech or music signals. In this paper, we present a new audio feature sets that lead to the definition of four classes: colored, pseudo-periodic, impulsive and sinusoids within noises. This classification relies on works about the perception of noises. This audio feature set is experimented for noisy sound segmentation. Noise-to-noise transitions are characterized by means of statistical decision model based on Bayesian framework. This statistical method has been trained and experimented both on synthetic and real audio corpus. Using proposed feature set increases the discriminant power of Bayesian decision approach compared to a usual feature set."
34,David Hirst,An Analytical Methodology for Acousmatic Music.,2004,https://doi.org/10.5281/zenodo.1415656,David Hirst+University of Melbourne>AUS>education,"This paper presents a procedure for the analysis of acousmatic music which was derived from the synthesis of top-down (knowledge driven) and bottom-up (data-driven) cognitive psychological views. The procedure is also a synthesis of research on primitive auditory scene analysis, combined with the research on acoustic, semantic, and syntactic factors in the perception of everyday environmental sounds. The procedure can be summarized as consisting of a number of steps: Segregation of sonic objects; Horizontal integration and/or segregation; Vertical integration and/or segregation; Assimilation and meaning."
35,Robyn Holmes;Marie-Louise Ayres,MusicAustralia: towards a national music information infrastructure.,2004,https://doi.org/10.5281/zenodo.1418097,Robyn Holmes+National Library of Australia>AUS>facility;Marie-Louise Ayres+National Library of Australia>AUS>facility,"MusicAustralia is a national music discovery service, developed by the National Library of Australia and ScreenSound Australia, National Film and Sound Archive. The service aims to provide seamless access to music and music information resources, in multiple formats, from custodians across all cultural sectors. This paper describes the development of the service, including its architecture, and content base. Service development to date has concentrated on metadata contribution and discovery strategies, together with development of the national digital music collection. In the future, digital content developed to populate the service could be subjected to Music Information Retrieval applications, to further enrich understanding of Australian music. The paper finishes by examining the challenges of achieving these advanced services in an environment where MIR research is relatively undeveloped."
36,Jia-Lien Hsu;Arbee L. P. Chen;Hung-Chen Chen,Finding Approximate Repeating Patterns from Sequence Data.,2004,https://doi.org/10.5281/zenodo.1415530,Jia-Lien Hsu+Fu Jen Catholic University>TWN>education;Arbee L.P. Chen+National Chengchi University>TWN>education;Hung-Chen Chen+National Tsing Hua University>TWN>education,"In this paper, an application of feature extraction from music data is first introduced to motivate our research of finding approximate repeating patterns from sequence data. An approximate repeating pattern is defined as a sequence of symbols which appears more than once under certain approximation types in a data sequence. By using the ‘cut’ and ‘pattern_join’ operators, we develop a level-wise approach to solve the problem of finding approximate repeating patterns."
37,Akinori Ito;Sung-Phil Heo;Motoyuki Suzuki;Shozo Makino,Comparison Of Features For DP-Matching Based Query-by-Humming System.,2004,https://doi.org/10.5281/zenodo.1416178,Akinori Ito+Tohoku University>JPN>education|Korea Telecom Research & Development Group>KOR>company;Sung-Phil Heo+Korea Telecom Research & Development Group>KOR>company|Tohoku University>JPN>education;Motoyuki Suzuki+Tohoku University>JPN>education;Shozo Makino+Tohoku University>JPN>education,"In this paper, we compared three kinds of similarity measures for DP-matching based query-by-humming music retrieval experiments. First, a DP matching-based algorithm is formulated using the similarity between a deltaPitch of an input humming and that of a song in the database. Then the three similarities are introduced: distance-based similarity, quantization-based similarity and fuzzy quantization-based similarity. The three similarities are compared by experiments. From the experimental results, the distance-based one gave the best recall rate. In addition, we examined the combination of distance-based and fuzzy-quantization-based similarities. The experimental result showed that the recall rate was improved by the combination."
38,Peter Jan O. Doets;Reginald L. Lagendijk,Stochastic Model of a Robust Audio Fingerprinting System.,2004,https://doi.org/10.5281/zenodo.1416490,P.J.O. Doets+Delft University of Technology>NLD>education;R.L. Lagendijk+Delft University of Technology>NLD>education,"An audio fingerprint is a compact representation of the perceptually relevant parts of audio content. A suitable audio fingerprint can be used to identify audio files, even if they are severely degraded due to compression or other types of signal processing operations. When degraded, the fingerprint closely resembles the fingerprint of the original, but is not identical. We plan to use a fingerprint not only to identify the song but also to assess the perceptual quality of the compressed content. In order to develop such a fingerprinting scheme, a model is needed to assess the behavior of a fingerprint subject to compression. In this paper we present the initial outlines of a model for an existing robust fingerprinting system to develop a more theoretical foundation. The model describes the stochastic behavior of the system when the input signal is a stationary (stochastic) signal. In this paper the input is assumed to be white noise. Initial theoretical results are reported and validated with experimental data."
39,Tristan Jehan,Perceptual Segment Clustering For Music Description And Time-axis Redundancy Cancellation.,2004,https://doi.org/10.5281/zenodo.1416854,Tristan Jehan+Massachusetts Institute of Technology>USA>education,"Repeating sounds and patterns are widely exploited throughout music. However, although analysis and music information retrieval applications are often concerned with processing speed and music description, they typically discard the benefits of sound redundancy cancellation. We propose a perceptually grounded model for describing music as a sequence of labeled sound segments, for reducing data complexity, and for compressing audio."
40,Steve Jones;Sally Jo Cunningham;Matt Jones 0001,Organizing digital music for use: an examination of personal music collections.,2004,https://doi.org/10.5281/zenodo.1416298,Sally Jo Cunningham+University of Waikato>NZL>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Matt Jones+University of Waikato>NZL>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Steve Jones+University of Waikato>NZL>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown,"Current research on music information retrieval and music digital libraries focuses on providing access to huge, public music collections. In this paper we consider a different, but related, problem: supporting an individual in maintaining and using a personal music collection. We analyze organization and access techniques used to manage personal music collections (primarily CDs and MP3 files), and from these behaviors, to suggest user behaviors that should be supported in a personal music digital library (that is, a digital library of an individual’s personal music collection)."
41,Jürgen Kilian;Holger H. Hoos,MusicBLAST - Gapped Sequence Alignment for MIR.,2004,https://doi.org/10.5281/zenodo.1416984,Jürgen Kilian+Darmstadt University of Technology>DEU>education|University of British Columbia>CAN>education;Holger H. Hoos+University of British Columbia>CAN>education,"We propose an algorithm, MusicBLAST, for approximate pattern search/matching on symbolic musical data. MusicBLAST is based on the BLAST algorithm, one of the most commonly used algorithms for similarity search on biological sequence data. MusicBLAST can be used in combination with an arbitrary similarity measure (e.g., melodic, rhythmic or combined) and retrieves multiple occurrences of a given search pattern and its variations. Different from many other pattern matching techniques, it can find incomplete and imperfect occurrences of a given pattern, and produces a significance measure for the accuracy and quality of its results. Like BLAST — and different from many musical pattern matching approaches — MusicBLAST retrieves heuristically optimised bi-directional alignments searching iteratively in forward and backward direction by starting at a dedicated seed note position of a performance."
42,Peter Knees;Elias Pampalk;Gerhard Widmer,Artist Classification with Web-Based Data.,2004,https://doi.org/10.5281/zenodo.1417189,Peter Knees+Austrian Research Institute for Artificial Intelligence>AUT>facility;Elias Pampalk+Austrian Research Institute for Artificial Intelligence>AUT>facility;Gerhard Widmer+Austrian Research Institute for Artificial Intelligence>AUT>facility|Medical University of Vienna>AUT>education,"Manifold approaches exist for organization of music by genre and/or style. In this paper we propose the use of text categorization techniques to classify artists present on the Internet. In particular, we retrieve and analyze webpages ranked by search engines to describe artists in terms of word occurrences on related pages. To classify artists we primarily use support vector machines. We present 3 experiments in which we address the following issues. First, we study the performance of our approach compared to previous work. Second, we investigate how daily fluctuations in the Internet affect our approach. Third, on a set of 224 artists from 14 genres we study (a) how many artists are necessary to define the concept of a genre, (b) which search engines perform best, (c) how to formulate search queries best, (d) which overall performance we can expect for classification, and finally (e) how our approach is suited as a similarity measure for artists."
43,Ian Knopke,"Sound, Music and Textual Associations on the World Wide Web.",2004,https://doi.org/10.5281/zenodo.1416144,Ian Knopke+McGill University>CAN>education,"Sound files on the World Wide Web are accessed from web pages. To date, this relationship has not been explored extensively in the MIR literature. This paper details a series of experiments designed to measure the similarity between the public text visible on a web page and the linked sound files, the name of which is normally unseen by the user. A collection of web pages was retrieved from the web using a specially-constructed crawler. Sound file information and associated text were parsed from the pages and analyzed for similarity using common IR techniques such as TFIDF cosine measures. The results are intended to be used in the improvement of a web crawler for audio and music, as well as for MIR purposes in general."
44,Arvindh Krishnaswamy,Melodic Atoms for Transcribing Carnatic Music.,2004,https://doi.org/10.5281/zenodo.1417859,Arvindh Krishnaswamy+Center for Computer Research in Music and Acoustics>USA>facility,"We had introduced a set of 2D melodic units to transcribe Carnatic music previously, and we now provide some illustrative examples using real pitch tracks to further our discussion on this topic."
45,Pedro Kröger,CsoundXML: a meta-language in XML for sound synthesis.,2004,https://doi.org/10.5281/zenodo.1415652,Pedro Kröger+Federal University at Bahia>BRA>education,"The software sound synthesis is closely related to the Music N programs started with Music I in 1957. Although Music N has many advantages such as unit generators and a flexible score language, it presents a few problems like limitations on instrument reuse, inflexibility of use of parameters, lack of a built-in graphical interface, and usually only one paradigm for scores. Some solutions concentrate in new from-scratch Music N implementations, while others focus in building user tools like pre-processors and graphical utilities. Nevertheless, new implementations in general focus in specific groups of problems leaving others unsolved. The user tools solve only one problem with no connection with others. In this paper we investigate the problem of creating a meta-language for sound synthesis. This constitutes an elegant solution for the above cited problems, without the need of a yet new acoustic compiler implementation, allowing a tight integration which is difficult to obtain with the present user tools."
46,Frank Kurth;Meinard Müller;Andreas Ribbrock;Tido Röder;David Damm;Christian Fremerey,A Prototypical Service for Real-Time Access to Local Context-Based Music Information.,2004,https://doi.org/10.5281/zenodo.1414926,Frank Kurth+University of Bonn>DEU>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Meinard Müller+University of Bonn>DEU>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Andreas Ribbrock+University of Bonn>DEU>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Tido Röder+University of Bonn>DEU>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;David Damm+University of Bonn>DEU>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown;Christian Fremerey+University of Bonn>DEU>education|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown|Unknown>Unknown>Unknown,"In this contribution we propose a generic service for real-time access to context-based music information such as lyrics or score data. In our web-based client-server scenario, a client application plays back a particular (waveform) audio recording. During playback, the client connects to a server which in turn identifies the particular piece of audio as well as the current playback position. Subsequently, the server delivers local, i.e., position specific, context-based information on the audio piece to the client. The client then synchronously displays the received information during acoustic playback. We demonstrate how such a service can be established using recent MIR (Music Information Retrieval) techniques such as audio identification and synchronization and present two particular application scenarios."
47,Mika Kuuskankare;Mikael Laurson,Expressive Notation Package - an Overview.,2004,https://doi.org/10.5281/zenodo.1415084,Mika Kuuskankare+Sibelius Academy>FIN>education;Mikael Laurson+Sibelius Academy>FIN>education,The purpose of this paper is to give the reader a concise overview of Expressive Notation Package 2.0 (henceforward ENP). ENP is music notation program that belongs to a family of music and sound related software packages developed at Sibelius Academy in Finland. ENP has been used in various research projects during the past several years.
48,Olivier Lartillot,A multi-parametric and redundancy-filtering approach to pattern identification.,2004,https://doi.org/10.5281/zenodo.1416426,Olivier Lartillot+University of Jyväskylä>FIN>education,"This paper presents the principles of a new approach aimed at automatically discovering motivic patterns in monodies. It is shown that, for the results to agree with the listener’s understanding, computer modelling needs to follow as closely as possible the strategies undertaken during the listening process. Motivic patterns, which may progressively follow different musical dimensions, are discovered through an adaptive incremental identification in a multi-dimensional parametric space. The combinatorial redundancy that would logically result from the model is carefully limited with the help of particular heuristics. In particular, a notion of specificity relation between pattern descriptions is defined, unifying suffix relation – between patterns – and inclusion relation – between the multi-parametric descriptions of patterns. This enables to discard redundant patterns, whose descriptions are less specific than other patterns and whose occurrences are included in the occurrences of the more specific patterns. Resulting analyzes come close to the structures actually perceived by the listener."
49,Tin Lay Nwe;Ye Wang,Automatic Detection Of Vocal Segments In Popular Songs.,2004,https://doi.org/10.5281/zenodo.1417846,Tin Lay Nwe+National University of Singapore>SGP>education;Ye Wang+National University of Singapore>SGP>education,"This paper presents a technique for the automatic classification of vocal and non-vocal regions in an acoustic musical signal. The proposed technique uses acoustic features which are suitable to distinguish vocal and non-vocal signals. We employ the Hidden Markov Model (HMM) classifier for vocal and non-vocal classification. In contrast to conventional HMM training methods which employ one model for each class, we create an HMM model space (multi-model HMMs) for segmentation with improved accuracy. In addition, we employ an automatic bootstrapping process which adapts the test song’s own models for better classification accuracy. Experimental evaluations conducted on a database of 20 popular music songs show the validity of the proposed approach."
50,Micheline Lesaffre;Marc Leman;Bernard De Baets;Jean-Pierre Martens,Methodological Considerations Concerning Manual Annotation Of Musical Audio In Function Of Algorithm Development.,2004,https://doi.org/10.5281/zenodo.1414874,Micheline Lesaffre+Ghent University>BEL>education;Marc Leman+Ghent University>BEL>education;Bernard De Baets+Ghent University>BEL>education;Jean-Pierre Martens+Ghent University>BEL>education,"In research on musical audio-mining, annotated music databases are needed which allow the development of computational tools that extract from the musical audio stream the kind of high-level content that users can deal with in Music Information Retrieval (MIR) contexts. The notion of musical content, and therefore the notion of annotation, is ill-defined, however, both in the syntactic and semantic sense. As a consequence, annotation has been approached from a variety of perspectives (but mainly linguistic-symbolic oriented), and a general methodology is lacking. This paper is a step towards the definition of a general framework for manual annotation of musical audio in function of a computational approach to musical audio-mining that is based on algorithms that learn from annotated data."
51,Ming Li;Ronan Sleep,Improving Melody Classification by Discriminant Feature Extraction and Fusion.,2004,https://doi.org/10.5281/zenodo.1416728,Ming Li+University of East Anglia>GBR>education;Ronan Sleep+University of East Anglia>GBR>education,"We propose a general approach to discriminant feature extraction and fusion, built on an optimal feature transformation for discriminant analysis. Our experiments indicate that our approach can dramatically reduce the dimensionality of original feature space whilst improving its discriminant power. Our feature fusion method can be carried out in the reduced lower-dimensional subspace, resulting in a further improvement in accuracy. Our experiments concern the classification of music styles based only on the pitch sequence derived from monophonic melodies."
52,Beth Logan,Music Recommendation from Song Sets.,2004,https://doi.org/10.5281/zenodo.1416658,Beth Logan+Hewlett Packard Labs>USA>company,"We motivate the problem of music recommendation based solely on acoustics from groups of related songs or ‘song sets’. We propose four solutions which can be used with any acoustic-based similarity measure. The first builds a model for each song set and recommends new songs according to their distance from this model. The next three approaches recommend songs according to the average, median and minimum distance to songs in the song set. For a similarity measure based on K-means models of MFCC features, experiments on a database of 18647 songs indicated that the minimum distance technique is the most effective, returning a valid recommendation as one of the top 5 32.5% of the time. The approach based on the median distance was the next best, returning a valid recommendation as one of the top 5 29.5% of the time."
53,Maurício A. Loureiro;Hugo Bastos de Paula;Hani C. Yehia,Timbre Classification Of A Single Musical Instrument.,2004,https://doi.org/10.5281/zenodo.1416320,Mauricio A. Loureiro+Federal University of Minas Gerais>BRA>education;Hugo B. de Paula+Federal University of Minas Gerais>BRA>education;Hani C. Yehia+Federal University of Minas Gerais>BRA>education,"In order to map the spectral characteristics of the large variety of sounds a musical instrument may produce, different notes were performed and sampled in several intensity levels across the whole extension of a clarinet. Amplitude and frequency time-varying curves of partials were measured by Discrete Fourier Transform. A limited set of orthogonal spectral bases was derived by Principal Component Analysis techniques. These bases defined spectral sub-spaces capable of representing all tested sounds and of grouping them according to the distance metrics of the representation. A clustering algorithm was used to infer timbre classes. Preliminary tests with resynthesized sounds with normalized pitch showed a strong relation between the perceived timbre and the cluster label to which the notes were assigned. Self-Organizing Maps lead to results similar to those obtained by PCA representation and K-means clustering algorithm."
54,Anna Lubiw;Luke Tanur,Pattern Matching in Polyphonic Music as a Weighted Geometric Translation Problem.,2004,https://doi.org/10.5281/zenodo.1417969,Anna Lubiw+University of Waterloo>CAN>education|University of Waterloo>CAN>education;Luke Tanur+University of Waterloo>CAN>education|University of Waterloo>CAN>education,"We consider the music pattern matching problem—to find occurrences of a small fragment of music called the “pattern” in a larger body of music called the “score”—as a problem of translating a set of horizontal line segments in the plane to find the best match in a larger set of horizontal line segments. Our contribution is that we use fairly general weight functions to measure the quality of a match, thus enabling approximate pattern matching. We give an algorithm with running time O(nm log m), where n is the size of the score and m is the size of the pattern. We show that the problem, in this geometric formulation, is unlikely to have a significantly faster algorithm because it is at least as hard as a basic problem called 3-SUM that is conjectured to have no subquadratic algorithm. We present some examples to show the potential of this method for finding minor variations of a theme, and for finding polyphonic musical patterns in a polyphonic score."
55,Matija Marolt,Gaussian Mixture Models For Extraction Of Melodic Lines From Audio Recordings.,2004,https://doi.org/10.5281/zenodo.1416576,Matija Marolt+University of Ljubljana>SVN>education,"The presented study deals with extraction of melodic line(s) from polyphonic audio recordings. We base our work on the use of expectation maximization algorithm, which is employed in a two-step procedure that finds melodic lines in audio signals. In the first step, EM is used to find regions in the signal with strong and stable pitch (melodic fragments). In the second step, these fragments are grouped into clusters according to their properties (pitch, loudness...). The obtained clusters represent distinct melodic lines. Gaussian Mixture Models, trained with EM are used for clustering. The paper presents the entire process in more detail and gives some initial results."
56,Cory McKay;Ichiro Fujinaga,Automatic Genre Classification Using Large High-Level Musical Feature Sets.,2004,https://doi.org/10.5281/zenodo.1416158,Cory McKay+McGill University>CAN>education;Ichiro Fujinaga+McGill University>CAN>education,"This paper presents a system that extracts 109 musical features from symbolic recordings (MIDI, in this case) and uses them to classify the recordings by genre. The features used here are based on instrumentation, texture, rhythm, dynamics, pitch statistics, melody and chords. The classification is performed hierarchically using different sets of features at different levels of the hierarchy. Which features are used at each level, and their relative weightings, are determined using genetic algorithms. Classification is performed using a novel ensemble of feedforward neural networks and k-nearest neighbour classifiers. Arguments are presented emphasizing the importance of using high-level musical features, something that has been largely neglected in automatic classification systems to date in favour of low-level features. The effect on classification performance of varying the number of candidate features is examined in order to empirically demonstrate the importance of using a large variety of musically meaningful features. Two differently sized hierarchies are used in order to test the performance of the system under different conditions. Very encouraging classification success rates of 98% for root genres and 90% for leaf genres are obtained for a hierarchical taxonomy consisting of 9 leaf genres."
57,Martin F. McKinney;Dirk Moelants,Extracting the perceptual tempo from music.,2004,https://doi.org/10.5281/zenodo.1415146,Martin F. McKinney+Philips Research Laboratories>NLD>company;Dirk Moelants+Ghent University>BEL>education,The study presented here outlines a procedure for measuring and quantitatively representing the perceptual tempo of a musical excerpt. We also present a method for applying such measures of perceptual tempo to the design of automatic tempo-trackers in order to more accurately represent the perceived beat in music.
58,R. Mitchell;Irfan A. Essa,Feature Weighting for Segmentation.,2004,https://doi.org/10.5281/zenodo.1414976,R. Mitchell Parry+Georgia Institute of Technology>USA>education;Irfan Essa+Georgia Institute of Technology>USA>education,"This paper proposes the use of feature weights to reveal the hierarchical nature of music audio. Feature weighting has been exploited in machine learning, but has not been applied to music audio segmentation. We describe both a global and a local approach to automatic feature weighting. The global approach assigns a single weighting to all features in a song. The local approach uses the local separability directly. Both approaches reveal structure that is obscured by standard features, and emphasize segments of a particular size."
59,Daniel Müllensiefen;Klaus Frieler,Optimizing Measures Of Melodic Similarity For The Exploration Of A Large Folk Song Database.,2004,https://doi.org/10.5281/zenodo.1418031,Daniel Müllensiefen+University of Hamburg>DEU>education|University of Hamburg>DEU>education;Klaus Frieler+University of Hamburg>DEU>education|University of Hamburg>DEU>education,"This investigation aims at finding an optimal way of measuring the similarity of melodies. The applicability for an automated analysis and classification was tested on a folk song collection from Luxembourg that had been thoroughly analysed by an expert ethnomusicologist. Firstly a systematization of the currently available approaches to similarity measurements of melodies was done. About 50 similarity measures were implemented which differ in the way of transforming musical data and in the computational algorithms. Three listener experiments were conducted to compare the performance of the different measures to human experts’ ratings. Then an optimized model was obtained by using linear regression, which combines the output of several measures representing different musical dimensions. The performance of this optimized measure was compared with the classification work of a human ethnomusicologist on a collection of 577 Luxembourg folksongs."
60,Meinard Müller;Frank Kurth;Tido Röder,Towards an Efficient Algorithm for Automatic Score-to-Audio Synchronization.,2004,https://doi.org/10.5281/zenodo.1416302,Meinard Müller+Universität Bonn>DEU>education;Frank Kurth+Universität Bonn>DEU>education;Tido Röder+Universität Bonn>DEU>education,"In the last few years, several algorithms for the automatic alignment of audio and score data corresponding to the same piece of music have been proposed. Among the major drawbacks to these approaches are the long running times as well as the large memory requirements. In this paper we present an algorithm, which solves the synchronization problem accurately and efficiently for complex, polyphonic piano music. In a first step, we extract from the audio data stream a set of highly expressive features encoding note onset candidates separately for all pitches. This makes computations efficient since only a small number of such features is sufficient to solve the synchronization task. Based on a suitable matching model, the best match between the score and the feature parameters is computed by dynamic programming (DP). To further cut down the computational cost in the synchronization process, we introduce the concept of anchor matches, matches which can be easily established. Then the DP-based technique is locally applied between adjacent anchor matches. Evaluation results have been obtained on complex polyphonic piano pieces including Chopin’s Etudes Op. 10."
61,Tomoyasu Nakano;Jun Ogata;Masataka Goto;Yuzuru Hiraga,A Drum Pattern Retrieval Method by Voice Percussion.,2004,https://doi.org/10.5281/zenodo.1417569,Tomoyasu Nakano+University of Tsukuba>JPN>education;Jun Ogata+University of Tsukuba>JPN>education;Masataka Goto+National Institute of Advanced Industrial Science and Technology (AIST)>JPN>facility;Yuzuru Hiraga+University of Tsukuba>JPN>education,"This paper presents a method for voice percussion recognition and its application to drum pattern retrieval. Recognition of voice percussion (verbalized expression of drum sound by voice) requires an approach that is different from existing methods. Individual differences in both vocal characteristics and the kinds of verbal expressions used add further complication to the task. The approach taken in this study uses onomatopoeia as internal representation of drum sounds, and combines the recognition of voice percussion with the retrieval of intended drum patterns. This scheme is intended to deal with the two types of individual differences mentioned above. In a recognition experiment with 200 utterances of voice percussion, our method achieved a recognition rate of 91.0% for the highest-tuned setting."
62,Andrew Nesbit;Lloyd Hollenberg;Anthony Senyard,Towards Automatic Transcription of Australian Aboriginal Music.,2004,https://doi.org/10.5281/zenodo.1416874,Andrew Nesbit+University of Melbourne>AUS>education;Lloyd Hollenberg+University of Melbourne>AUS>education;Anthony Senyard+University of Melbourne>AUS>education,"We describe a system designed for automatic extraction and segmentation of didjeridu and clapsticks from certain styles of traditional Aboriginal Australian music. For didjeridu, we locate the start of notes using a complex-domain note onset detection algorithm, and use the detected onsets as cues for determining the harmonic series of sinusoids belonging to the didjeridu. The harmonic series is hypothesised, based on prior knowledge of the fundamental frequency of the didjeridu, and the most likely hypothesis is assumed. For clapsticks, we use independent subspace analysis to split the signal into harmonic and percussive components, followed by classification of the independent components. Finally, we identify areas in which the system can be enhanced to improve accuracy and also to extract a wider range of musically-relevant features. These include algorithms such as high frequency content techniques, and also computing the morphology of the didjeridu."
63,Giovanna Neve;Nicola Orio,Indexing and Retrieval of Music Documents through Pattern Analysis and Data Fusion Techniques.,2004,https://doi.org/10.5281/zenodo.1416372,Giovanna Neve+University of Padova>ITA>education|University of Padova>ITA>education;Nicola Orio+University of Padova>ITA>education|University of Padova>ITA>education,"""One of the challenges of music information retrieval is the automatic extraction of effective content descriptors of music documents, which can be used at indexing and at retrieval time to match queries with documents. In this paper it is proposed to index music documents with frequent musical patterns. A musical pattern is a sequence of features in the score that is repeated at least twice: features can regard perceptually relevant characteristics, such as rhythm, pitch, or both. Data fusion techniques are applied to merge the results obtained using different features. A set of experimental tests has been carried out on retrieval effectiveness, robustness to query errors, and dependency on query length on a collection of Beatles’ songs using a set of queries. The proposed approach gave good results, both using single features and, in particular, merging the rank lists obtained by different features with a data fusion approach."""
64,François Pachet;Aymeric Zils,Automatic extraction of music descriptors from acoustic signals.,2004,https://doi.org/10.5281/zenodo.1416106,François Pachet+Sony CSL Paris>FRA>company;Aymeric Zils+Sony CSL Paris>FRA>company,"High-Level music descriptors are key ingredients for music information retrieval systems. Although there is a long tradition in extracting information from acoustic signals, the field of music information extraction is largely heuristic in nature. We present here a heuristic-based generic approach for extracting automatically high-level music descriptors from acoustic signals. This approach is based on Genetic Programming, used to build relevant features as functions of mathematical and signal processing operators. The search of relevant features is guided by specialized heuristics that embody knowledge about the signal processing functions built by the system. Signal processing patterns are used in order to control the general processing methods. In addition, rewriting rules are introduced to simplify overly complex expressions, and a caching system further reduces the computing cost of each cycle. Finally, the features build by the system are combined into an optimized machine learning descriptor model, and an executable program is generated to compute the model on any audio signal. In this paper, we describe the overall system and compare its results against traditional approaches in musical feature extraction à la Mpeg7."
65,Elias Pampalk,A Matlab Toolbox to Compute Music Similarity from Audio.,2004,https://doi.org/10.5281/zenodo.1418077,Elias Pampalk+Austrian Research Institute for Artificial Intelligence>AUT>facility,"A Matlab toolbox implementing music similarity measures for audio is presented. The implemented measures focus on aspects related to timbre and periodicities in the signal. This paper gives an overview of the implemented functions. In particular, the basics of the similarity measures are reviewed and some visualizations are discussed."
66,Bryan Pardo,Tempo Tracking with a Single Oscillator.,2004,https://doi.org/10.5281/zenodo.1415090,Bryan Pardo+Northwestern University>USA>education,"I describe a simple on-line tempo tracker, based on phase and period locking a single oscillator to performance event timings. The tracker parameters are optimized on a corpus of solo piano performances by twelve musicians. The tracker is then tested on a second corpus of performances, played by the same twelve musicians. The performance of this tracker is compared to previously published results for a tempo tracker based on combining a tempogram and Kalman filter."
67,Steffen Pauws,Musical key extraction from audio.,2004,https://doi.org/10.5281/zenodo.1416326,Steffen Pauws+Philips Research Laboratories Eindhoven>NLD>company,"The realisation and evaluation of a musical key extraction algorithm that works directly on raw audio data is presented. Its implementation is based on models of human auditory perception and music cognition. It is straightforward and has minimal computing requirements. First, it computes a chromagram from non-overlapping 100 msecs time frames of audio; a chromagram represents the likelihood of the chroma occurrences in the audio. This chromagram is correlated with Krumhansl’s key profiles that represent the perceived stability of each chroma within the context of a particular musical key. The key profile that has maximum correlation with the computed chromagram is taken as the most likely key. An evaluation with 237 CD recordings of classical piano sonatas indicated a classification accuracy of 75.1%. By considering the exact, relative, dominant, sub-dominant and parallel keys as similar keys, the accuracy is even 94.1%."
68,Jose Pedro;Vadim Tarasov;Eloi Batlle;Enric Guaus;Jaume Masip,Industrial audio fingerprinting distributed system with CORBA and Web Services.,2004,https://doi.org/10.5281/zenodo.1414792,Jose P. G. Mahedero+Universitat Pompeu Fabra>ESP>education;Vadim Tarasov+Universitat Pompeu Fabra>ESP>education;Eloi Batlle+Universitat Pompeu Fabra>ESP>education;Enric Guaus+Universitat Pompeu Fabra>ESP>education;Jaume Masip+Universitat Pompeu Fabra>ESP>education,"With digital technologies, music content providers face serious challenges to protect their rights. Due to the widespread nature of music sources, it is very difficult to centralize the audio management. Audio fingerprinting allows the identification of audio content regardless of the audio format and without the need of additional metadata. Monitoring the audio being broadcasted by the TV and radio stations of a country requires the design and implementation of a scalable, robust and modular framework. We have chosen CORBA as distributed environment. The whole functionality needs to be decoupled from clients. To do so, Web services have been deployed. The audio identification core uses a Hidden Markov Model-based audio fingerprinting technology. The paper discusses the design and implementation issues of a complete distributing system that automatically monitors audio content, specifically music and commercials. Today, a working prototype of such a system already exists, and is dedicated to monitoring several radio and tv stations in Spain."
69,Anna Pienimäki;Kjell Lemström,Clustering Symbolic Music Using Paradigmatic and Surface Level Analyses.,2004,https://doi.org/10.5281/zenodo.1417447,Anna Pienimäki+University of Helsinki>FIN>education;Kjell Lemström+University of Helsinki>FIN>education,"In this paper, we describe a novel automatic cluster analy-
sis method for symbolic music. The method contains both
a surface level and a paradigmatic level analysing block
and works in two phases. In the first phase, each music
document of a collection is analysed separately: They are
first divided into phrases that are consequently fed on a
harmonic analyser. The paradigmatic structure of a given
music document is achieved comparing both the melodic
and the harmonic similarities among its phrases. In the
second phase, the collection of music documents is clus-
tered on the ground of their paradigmatic structures and
surface levels.
Our experimental results show that the
novel method finds some interesting, underlying similari-
ties that cannot be found using only surface level analysis."
70,Aggelos Pikrakis;Iasonas Antonopoulos;Sergios Theodoridis,Music meter and tempo tracking from raw polyphonic audio.,2004,https://doi.org/10.5281/zenodo.1416348,Aggelos Pikrakis+University of Athens>GRC>education;Iasonas Antonopoulos+University of Athens>GRC>education;Sergios Theodoridis+University of Athens>GRC>education,"This paper presents a method for the extraction of music meter and tempo from raw polyphonic audio recordings, assuming that music meter remains constant throughout the recording. Although this assumption can be restrictive for certain musical genres, it is acceptable for a large corpus of folklore eastern music styles, including Greek traditional dance music. Our approach is based on the self-similarity analysis of the audio recording and does not assume the presence of percussive instruments. Its novelty lies in the fact that music meter and tempo are jointly determined. The method has been applied to a variety of musical genres, in the context of Greek traditional music where music meter can be 2/4, 3/4, 4/4, 5/4, 7/8, 9/8, 12/8 and tempo ranges from 40bpm to 330bpm. Experiments have, so far, demonstrated the efficiency of our method (music meter and tempo were successfully extracted for over 95% of the recordings)."
71,Christopher Raphael,A Hybrid Graphical Model for Aligning Polyphonic Audio with Musical Scores.,2004,https://doi.org/10.5281/zenodo.1416500,Christopher Raphael+Indiana University>USA>education,"We present a new method for establishing an alignment between a polyphonic musical score and a corresponding sampled audio performance. The method uses a graphical model containing both discrete variables, corresponding to score position, as well as a continuous latent tempo process. We use a simple data model based only on the pitch content of the audio signal. The data interpretation is defined to be the most likely configuration of the hidden variables, given the data, and we develop computational methodology for this task using a variant of dynamic programming involving parametrically represented continuous variables. Experiments are presented on a 55-minute hand-marked orchestral test set."
72,Christopher Raphael,Demonstration of 'Music Plus One'--- a System for Orchestral Musical Accompanimen.,2004,https://doi.org/10.5281/zenodo.1417899,Christopher Raphael+Indiana University>USA>education,""""""
73,Josh Reiss;Mark B. Sandler,Audio Issues In MIR Evaluation.,2004,https://doi.org/10.5281/zenodo.1415840,"Josh Reiss+Queen Mary, University of London>GBR>education;Mark Sandler+Queen Mary, University of London>GBR>education","Several projects are underway to create music testbeds to suit the needs of the music analysis and music information retrieval (MIR) communities. There are also plans to unify testbeds into a distributed grid. Thus the issue of audio file formats has come to the forefront. The creators of a music library or MIR testbed are confronted with many questions pertaining to file formats, their quality, metadata, and copyright issues. We discuss the various formats, their advantages and disadvantages, and give a set of guidelines and recommendations. This document is a positional paper. It is intended to foster discussion and not as a definitive statement. Nevertheless, it is hoped that the proposals put forth here may serve as a guideline to use in construction of an MIR evaluation testbed."
74,Vegard Sandvold;Fabien Gouyon;Perfecto Herrera,Drum sound classification in polyphonic audio recordings using localized sound models.,2004,https://doi.org/10.5281/zenodo.1415808,Vegard Sandvold+University of Oslo>NOR>education|Universitat Pompeu Fabra>ESP>education|Universitat Pompeu Fabra>ESP>education;Fabien Gouyon+Universitat Pompeu Fabra>ESP>education|Universitat Pompeu Fabra>ESP>education;Perfecto Herrera+Universitat Pompeu Fabra>ESP>education|Universitat Pompeu Fabra>ESP>education,"This paper deals with automatic percussion classification in polyphonic audio recordings, focusing on kick, snare and cymbal sounds. We present a feature-based sound modeling approach that combines general, prior knowledge about the sound characteristics of percussion instrument families (general models) with on-the-fly acquired knowledge of recording-specific sounds (localized models). This way, high classification accuracy can be obtained with remarkably simple sound models. The accuracy is on average around 20% higher than with general models alone."
75,Ryan Scherle;Donald Byrd,The Anatomy of a Bibliographic Search System for Music.,2004,https://doi.org/10.5281/zenodo.1417789,Ryan Scherle+Indiana University>USA>education;Donald Byrd+Indiana University>USA>education,"Traditional library catalog systems have been effective in providing access to collections of books, films, and other material. However, they have many limitations when it comes to finding musical information, which has significantly different, and in many ways more complex, structure. The Variations2 search system is an alternative designed specifically to aid users in searching for music. It leverages a rich set of bibliographic data records, expressing relationships between creators of music and their creations. These records enable musicians to search for music using familiar terms and relationships, rather than trying to decipher the methods libraries typically use to organize musical items. This paper describes the design and implementation of the system that makes these searches possible."
76,Shai Shalev-Shwartz;Joseph Keshet;Yoram Singer,Learning to Align Polyphonic Music.,2004,https://doi.org/10.5281/zenodo.1416546,Shai Shalev-Shwartz+The Hebrew University>ISR>education;Joseph Keshet+The Hebrew University>ISR>education;Yoram Singer+The Hebrew University>ISR>education,"We describe an efficient learning algorithm for aligning a symbolic representation of a musical piece with its acoustic counterpart. Our method employs a supervised learning approach by using a training set of aligned symbolic and acoustic representations. The alignment function we devise is based on mapping the input acoustic-symbolic representation along with the target alignment into an abstract vector-space. Building on techniques used for learning support vector machines (SVM), our alignment function distills to a classifier in the abstract vector-space which separates correct alignments from incorrect ones. We describe a simple iterative algorithm for learning the alignment function and discuss its formal properties. We use our method for aligning MIDI and MP3 representations of polyphonic recordings of piano music. We also compare our discriminative approach to a generative method based on a generalization of hidden Markov models. In all of our experiments, the discriminative method outperforms the HMM-based method."
77,Prarthana Shrestha;Ton Kalker,Audio Fingerprinting In Peer-to-peer Networks.,2004,https://doi.org/10.5281/zenodo.1417457,Prarthana Shrestha+Eindhoven University of Technology>NLD>education;Ton Kalker+Eindhoven University of Technology>NLD>education,"Despite the immense potential of Peer-to-Peer (P2P) networks in facilitating collaborative applications, they have become largely known as a free haven for pirated music swapping. In this paper, we present an approach wherein the collective computational power of the P2P networks is exploited to combat the problem of unauthorized music file sharing. We propose a distributed system based on audio fingerprinting, that makes it possible to recognize the music content present in the network. When the contents are identified, the network can take special measures against the use or sharing of unauthorized music. This proposed system is self-adapting, and robust. The foregoing properties make the system particularly suitable for use in dynamic and heterogeneous environment of P2P networks. In order to investigate the behavior of the proposed system, a system-level model has been created using the Parallel Object Oriented Specification Language (POOSL). This model was used to investigate an optimal system configuration that maximizes the identification of the content."
78,Jane Singer,Creating a nested melodic representation: competition and cooperation among bottom-up and top-down Gestalt principles.,2004,https://doi.org/10.5281/zenodo.1417965,Jane Singer+The Hebrew University of Jerusalem>ISR>education,"A set of principles (based on Gestalt theory) governing how we group notes into meaningful groups has been widely accepted in the literature. Based on these principles, many divergent theories of melodic segmentation and representation have been proposed. However, these theories have not succeeded in achieving a comprehensive and verifiable representation of melody. This is largely due to the fact that multiple competing segmenting factors produce, for any single melody, a large number of possible segmentations and therefore representations. Here a model is proposed, which incorporates widely accepted principles of segmentation. These rules govern three types of factors: (1) changes in proximity (for producing disjunctive segmentation), (2) changes in overall contour and intervallic texture and (3) patterns and periodicity that create parallelism among segments. Because of the nature of the segmentation rules, these same rules establish the attributes of the groups they produce. Based on original research in Singer 2004, principles for establishing preferences among competing rules are formulated in order to create a few preferred representations for approximately 1,000 monophonic folksongs."
79,J. Stephen Downie;Joe Futrelle;David K. Tcheng,"The International Music Information Retrieval Systems Evaluation Laboratory: Governance, Access and Security.",2004,https://doi.org/10.5281/zenodo.1415120,J. Stephen Downie+University of Illinois at Urbana-Champaign>USA>education;Joe Futrelle+University of Illinois at Urbana-Champaign>USA>education;David Tcheng+University of Illinois at Urbana-Champaign>USA>education,"The IMIRSEL (International Music Information Retrieval Systems Evaluation Laboratory) project provides an unprecedented platform for evaluating Music Information Retrieval (MIR) and Music Digital Library (MDL) techniques, by bringing together large corpora and significant computational resources with the necessary rights management and technical infrastructure to support a variety of MIR/MDL research areas. The standardized research collection being deployed represents a large and diverse corpus of musical examples, which we are hosting in our secure environment for use in evaluating MIR/MDL algorithms. Grid services and NCSA's D2K machine learning environment provide a powerful, high-performance, and secure framework for designing, optimising, and executing complex MIR/MDL evaluation applications. IMIRSEL provides a community resource for researchers who would otherwise not be able to afford the content rights and computational resources to carry out large-scale MIR/MDL evaluations."
80,Josh Stoddard;Christopher Raphael;Paul E. Utgoff,Well-Tempered Spelling: A Key Invariant Pitch Spelling Algorithm.,2004,https://doi.org/10.5281/zenodo.1414762,Joshua Stoddard+University of Massachusetts Amherst>USA>education;Christopher Raphael+University of Massachusetts Amherst>USA>education;Paul E. Utgoff+University of Massachusetts Amherst>USA>education,"In this paper is described a data-driven algorithm for the functionally correct spelling of MIDI pitch values in terms of Western musical notation. Input is in the form of MIDI files containing accurate pitch and rhythmic information with corresponding ground-truth spelling information for training and evaluation. The algorithm recovers harmonic information from the MIDI data and spells pitches according to their relation to the local tonic. The algorithm achieved 94.98% accuracy on the pitches that required accidentals in the local key and 99.686% overall. Voice-leading resolution was found to be the best feature of those used to infer the correct spelling. Also, this paper outlines great potential for improvement under this model."
81,Craig Stuart Sapp;Yi-Wen Liu;Eleanor Selfridge-Field,Search Effectiveness Measures for Symbolic Music Queries in Very Large Databases.,2004,https://doi.org/10.5281/zenodo.1417913,Craig Stuart Sapp+Stanford University>USA>education;Yi-Wen Liu+Stanford University>USA>education;Eleanor Selfridge-Field+Stanford University>USA>education,"In the interest of establishing robust benchmarks for search efficiency, we conducted a series of tests on symbolic databases of musical incipits and themes taken from several diverse repertories. The results we report differ from existing studies in four respects: (1) the data quantity is much larger (c. 100,000 entries); (2) the levels of melodic and rhythmic precision are more refined; (3) anchored and unanchored searches were differentiated; and (4) results from joint pitch-and-rhythm searches were compared with those for pitch-only searches. The search results were evaluated using a theoretical approach which seeks to rank the number of symbols required to achieve “sufficient uniqueness”. How far into a melody must a search go in order to find an item which is unmatched by any other of the available items? How much does the answer depend on the specificity of the query? How much does anchoring the query matter? How much does the result depend on the nature of the repertory? We offer experimental results for these questions."
82,Iman S. H. Suyoto;Alexandra L. Uitdenbogerd,Exploring Microtonal Matching.,2004,https://doi.org/10.5281/zenodo.1416656,Iman S. H. Suyoto+RMIT University>AUS>education;Alexandra L. Uitdenbogerd+RMIT University>AUS>education,"Most research into music information retrieval thus far has only examined music from the western tradition. However, music of other origins often conforms to different tuning systems. Therefore there are problems both in representing this music as well as finding matches to queries from these diverse tuning systems. We discuss the issues associated with microtonal music retrieval and present some preliminary results from an experiment in applying scoring matrices to microtonal matching."
83,Sara Taheri-Panah;Andrew MacFarlane 0001,Music Information Retrieval systems: why do individuals use them and what are their needs?.,2004,https://doi.org/10.5281/zenodo.1416334,S. Taheri-Panah+City University>GBR>education;A. MacFarlane+City University>GBR>education,"To date there has been very little research conducted on the behaviour of music information retrieval (MIR) users, in spite of the immense popularity of free music retrieval systems available on the Internet. In this study we examine the issue of music seeking behaviour through the examination of users life style effect of three different age groups using questionnaires. It was found that lifestyles had a significant impact on users need for music and hence their music seeking behaviour. The importance of social networks in music information seeking was reinforced in this study. An experiment was conducted with three different types of search on the Kazaa MIR system and the participants interviewed in order to collect data. Users found the Kazaa system intuitive and easy to use. Searchers used both song titles and lyrics for finding relevant music items. The insights provided by this study can be of assistance in the development of user focused Internet MIR systems."
84,Haruto Takeda;Takuya Nishimoto;Shigeki Sagayama,Rhythm and Tempo Recognition of Music Performance from a Probabilistic Approach.,2004,https://doi.org/10.5281/zenodo.1418209,Haruto Takeda+The University of Tokyo>JPN>education;Takuya Nishimoto+The University of Tokyo>JPN>education;Shigeki Sagayama+The University of Tokyo>JPN>education,"This paper concerns both rhythm recognition and tempo analysis of expressive music performance based on a probabilistic approach. In rhythm recognition, the modern continuous speech recognition technique is applied to find the most likely intended note sequence from the given sequence of fluctuating note durations in the performance. Combining stochastic models of note durations deviating from the nominal lengths and a probabilistic grammar representing possible sequences of notes, the problem is formulated as a maximum a posteriori estimation that can be implemented using efficient search based on the Viterbi algorithm. With this, significant improvements compared with conventional “quantization” techniques were found. Tempo analysis is performed by fitting the observed tempo with parametric tempo curves in order to extract tempo dynamics and characteristics of performance to use. Tempo-change timings and parameter values in tempo curve models are estimated through the segmental k-means algorithm. Experimental results of rhythm recognition and tempo analysis applied to classical and popular music performances are also demonstrated."
85,Richard Terrat,Pregroup Grammars for Chords.,2004,https://doi.org/10.5281/zenodo.1416702,Richard G. Terrat+LIRMM/CNRS>FRA>facility|IRCAM>FRA>facility,"Pregroups had been conceived as an algebraic tool to recognize grammatically well-formed sentences in natural languages [3]. Here we wish to use pregroups to recognize well-formed chords of pitches, for a given definition of those chords. We show how a judicious choice of basic and simple types allows a context-free grammatical description. Then we use the robustness property to extend the set of well-formed chords in a simple way. Finally we argue in favor of an utilization of pregroups grammars for the recognition and classification of chord sequences."
86,Adam R. Tindale;Ajay Kapur;George Tzanetakis;Ichiro Fujinaga,Retrieval of percussion gestures using timbre classification techniques.,2004,https://doi.org/10.5281/zenodo.1416612,Adam Tindale+McGill University>CAN>education;Ajay Kapur+University of Victoria>CAN>education;George Tzanetakis+University of Victoria>CAN>education;Ichiro Fujinaga+McGill University>CAN>education,"Musicians are able to recognise the subtle differences in timbre produced by different playing techniques on an instrument, yet there has been little research into achieving this with a computer. This paper will demonstrate an automatic system that can successfully recognise different timbres produced by different performance techniques and classify them using signal processing and classification tools. Success rates over 90% are achieved when classifying snare drum timbres produced by different playing techniques."
87,Marc Torrens;Patrick Hertzog;Josep Lluís Arcos,Visualizing and Exploring Personal Music Libraries.,2004,https://doi.org/10.5281/zenodo.1414746,"Marc Torrens+MusicStrands Inc.>USA>company;Patrick Hertzog+EPFL>CHE>education;Josep-Lluís Arcos+IIIA, CSIC>ESP>facility","Nowadays, music fans are beginning to massively use mobile digital music players and dedicated software to organize and play large collections of music. In this context, users deal with huge music libraries containing thousands of tracks. Such a huge volume of music easily overwhelms users when selecting the music to listen or when organizing their collections. Music player software with visualizations based on textual lists and organizing features such as smart playlists are not really enough for helping users to efficiently manage their libraries. Thus, we propose new graphical visualizations and their associated features to allow users to better organize their personal music libraries and therefore also to ease selection later on."
88,Godfried T. Toussaint,A Comparison of Rhythmic Similarity Measures.,2004,https://doi.org/10.5281/zenodo.1416812,Godfried T. Toussaint+McGill University>CAN>education,"Traditionally, rhythmic similarity measures are compared according to how well rhythms may be recognized with them, how efficiently they can be retrieved from a database, or how well they model human perception and cognition. In contrast, here similarity measures are compared on the basis of how much insight they provide about the structural inter-relationships that exist within families of rhythms, when phylogenetic trees and graphs are computed from the distance matrices determined by these similarity measures. Phylogenetic analyses yield insight into the evolution of rhythms and may uncover interesting ancestral rhythms."
89,Ken'ichi Toyoda;Kenzi Noike;Haruhiro Katayose,Utility System For Constructing Database Of Performance Deviations.,2004,https://doi.org/10.5281/zenodo.1417953,Ken’ichi Toyoda+Kwansei Gakuin University>JPN>education;Kenzi Noike+Kwansei Gakuin University>JPN>education;Haruhiro Katayose+Kwansei Gakuin University>JPN>education,"Demand for music databases is increasing for the studies of musicology and music informatics. Our goal is to construct databases that contain deviations of tempo, and dynamics, start-timing, and duration of each note. This paper describes a procedure based on hybrid use of DP Matching and HMM that efficiently extracts deviations from MIDI-formatted expressive human performances. The algorithm of quantizing the start-timing of the notes has been successfully tested on a database of ten expressive piano performances. It gives an accuracy of 92.9% when one note per bar is given as the guide. This paper also introduces tools provided so that the public can make use of our database on the web."
90,Wei-Ho Tsai;Hsin-Min Wang,Towards Automatic Identification Of Singing Language In Popular Music Recordings.,2004,https://doi.org/10.5281/zenodo.1417511,Wei-Ho Tsai+Academia Sinica>TWN>education|Institute of Information Science>Unknown>Unknown;Hsin-Min Wang+Academia Sinica>TWN>education|Institute of Information Science>Unknown>Unknown,"The automatic analysis of singing from music is an important and challenging issue within the research target of content-based retrieval of music information. As part of this research target, this study presents a first attempt to automatically identify the language sung in a music recording. It is assumed that each language has its own set of constraints that specify which of the basic linguistic events present in a singing process are allowed to follow another. The acoustic structure of individual languages may, thus, be characterized by statistically modeling those constraints. To this end, the proposed method employs vector clustering to convert a singing signal from its spectrum-based feature representation into a sequence of smaller basic phonological units. The dynamic characteristics of the sequence are then analyzed by using bigram language models. Since the vector clustering is performed in an unsupervised manner, the resulting system does not use sophisticated linguistic knowledge and, thus, is easily portable to new language sets. In addition, to eliminate the interference of background music, we leverage the statistical estimation of a piece’s music background so that the vector clustering is relevant to the solo singing voices in the accompanied signals."
91,Rainer Typke;Frans Wiering;Remco C. Veltkamp,A search method for notated polyphonic music with pitch and tempo fluctuations.,2004,https://doi.org/10.5281/zenodo.1417947,Rainer Typke+Utrecht University>NLD>education;Frans Wiering+Utrecht University>NLD>education;Remco C. Veltkamp+Utrecht University>NLD>education,"We compare two methods of measuring melodic similarity for symbolically represented polyphonic music. Both exploit advantages of transportation distances such as continuity and partial matching in the pitch dimension. By segmenting queries and database documents, one of them also offers partial matching in the time dimension. This method can find short queries in long database documents and is more robust against pitch and tempo fluctuations in the queries or database documents than the method that uses transportation distances alone. We compare the use of transportation distances with and without segmentation for the RISM A/II collection and find that segmentation improves recall and precision. With everything else being equal, the segmented search found 80 out of 114 relevant documents, while the method relying solely on transportation distances found only 60."
92,George Tzanetakis;Ajay Kapur;Manj Benning,Query-by-Beat-Boxing: Music Retrieval For The DJ.,2004,https://doi.org/10.5281/zenodo.1418033,Ajay Kapur+University of Victoria>CAN>education;Manj Benning+University of Victoria>CAN>education;George Tzanetakis+University of Victoria>CAN>education,"BeatBoxing is a type of vocal percussion, where musicians use their lips, cheeks, and throat to create different beats. It is commonly used by hiphop and rap artists. In this paper, we explore the use of BeatBoxing as a query mechanism for music information retrieval and more specifically the retrieval of drum loops. A classification system that automatically identifies the individual beat boxing sounds and can map them to corresponding drum sounds has been developed. In addition, the tempo of BeatBoxing is automatically detected and used to dynamically browse a database of music. We also describe some experiments in extracting structural representations of rhythm and their use for style classification of drum loops."
93,Fabio Vignoli,Digital Music Interaction Concepts: A User Study.,2004,https://doi.org/10.5281/zenodo.1414994,Fabio Vignoli+Philips Research Laboratories>NLD>company,The popularity of digital music has recently rapidly increased. The widespread use on computers and portable players and its availability through the Internet have modified the interaction issues from availability towards choice. The user is confronted daily with an enormous amount of music. This situation shapes the need for the development of new user interfaces to access and retrieve music that takes full advantage of the music being digital. This paper reports the results of various user tests aimed at investigating how music listeners organize and access their digital music collection. The aim of the study is to investigate novel interaction concepts to access and retrieve music from large personal collections. The outcome of these studies was an interaction concept based on the notion of similarity of music items (artists and songs). This concept was further refined and developed into a demonstrator eventually tested with users.
94,Fabio Vignoli;Rob van Gulik;Huub van de Wetering,"Mapping Music In The Palm Of Your Hand, Explore And Discover Your Collection.",2004,https://doi.org/10.5281/zenodo.1416960,Rob van Gulik+Technische Universiteit Eindhoven>NLD>education|Philips Research Laboratories>Unknown>company;Fabio Vignoli+Technische Universiteit Eindhoven>NLD>education|Philips Research Laboratories>Unknown>company;Huub van de Wetering+Technische Universiteit Eindhoven>NLD>education,"The trends of miniaturization and increasing storage capabilities for portable music players made it possible to carry increasingly more music on small portable devices, but it also introduced negative consequences for the user interface and navigation. Finding music in large collections can be hard if one does not know exactly what to look for. In this paper a novel user interface to browse and navigate through music on small devices is proposed, together with the enabling algorithms. The goal of this interface is to enable the users to explore and discover their entire collection and to support non-specific searches. To this end, a new way to visualize and navigate through music is introduced: the artist map. The artist map is designed to provide an overview of an entire music collection, or a subset thereof, by clearly visualizing the similarity between artists, computed from the music itself. Contextual information (e.g. mood, genre) is added by coloring and by attribute magnets. The artist map is implemented by a graph-drawing algorithm, which uses an improved energy model. The proposed algorithm and interface have been implemented in a prototype and will be tested with ‘real’ users."
95,Emmanuel Vincent;Xavier Rodet,Instrument identification in solo and ensemble music using Independent Subspace Analysis.,2004,https://doi.org/10.5281/zenodo.1416524,Emmanuel Vincent+IRCAM>FRA>facility|Unknown>Unknown>Unknown;Xavier Rodet+IRCAM>FRA>facility|Unknown>Unknown>Unknown,"We investigate the use of Independent Subspace Analysis (ISA) for instrument identification in musical recordings. We represent short-term log-power spectra of possibly polyphonic music as weighted non-linear combinations of typical note spectra plus background noise. These typical note spectra are learnt either on databases containing isolated notes or on solo recordings from different instruments. We show that this model has some theoretical advantages over methods based on Gaussian Mixture Models (GMM) or on linear ISA. Preliminary experiments with five instruments and test excerpts taken from commercial CDs give promising results. The performance on clean solo excerpts is comparable with existing methods and shows limited degradation under reverberant conditions. Applied to a difficult duo excerpt, the model is also able to identify the right pair of instruments and to provide an approximate transcription of the notes played by each instrument."
96,Kristopher West;Stephen Cox,Features and classifiers for the automatic classification of musical audio signals.,2004,https://doi.org/10.5281/zenodo.1418025,Kris West+University of East Anglia>GBR>education;Stephen Cox+University of East Anglia>GBR>education,"Several factors affecting the automatic classification of musical audio signals are examined. Classification is performed on short audio frames and results are reported as “bag of frames” accuracies, where the audio is segmented into 23ms analysis frames and a majority vote is taken to decide the final classification. The effect of different parameterisations of the audio signal is examined. The effect of the inclusion of information on the temporal variation of these features is examined and finally, the performance of several different classifiers trained on the data is compared. A new classifier is introduced, based on the unsupervised construction of decision trees and either linear discriminant analysis or a pair of single Gaussian classifiers. The classification results show that the topology of the new classifier gives it a significant advantage over other classifiers, by allowing the classifier to model much more complex distributions within the data than Gaussian schemes do."
97,Tillman Weyde,The Influence of Pitch on Melodic Segmentation.,2004,https://doi.org/10.5281/zenodo.1415556,Tillman Weyde+University of Osnabrück>DEU>education,"Melodic segmentation is an important topic for music information retrieval, because it divides melodies into musically relevant units. Most influential theories on melodic segmentation of the last decades have stressed the role of pitch for melodic segmentation. The general assumption was, that relatively large changes or distances in any musical parameter like pitch, time, dynamics, or melodic movement mark segment boundaries. This has generally been accepted despite the lack of empirical studies. Here an empirical study is presented, that investigates the influence of inter-onset-intervals (IOI), intensity accents, pitch intervals, and pitch interval direction changes. The results show a significant influence only for IOIs and intensity, but neither for pitch intervals nor for changes in interval direction. The validity of the results and possible explanations are discussed and directions of further investigations are outlined."
98,Brian Whitman;Dan Ellis,Automatic Record Reviews.,2004,https://doi.org/10.5281/zenodo.1416646,Brian Whitman+MIT Media Lab>USA>education|Columbia University>USA>education;Daniel P. W. Ellis+LabROSA>USA>company,"Record reviews provide a unique and focused source of linguistic data that can be related to musical recordings, to provide a basis for computational music understanding systems with applications in similarity, recommendation and classification. We analyze a large testbed of music and a corpus of reviews for each work to uncover patterns and develop mechanisms for removing reviewer bias and extraneous non-musical discussion. By building upon work in grounding free text against audio signals we invent an “automatic record review” system that labels new music audio with maximal semantic value for future retrieval tasks. In effect, we grow an unbiased music editor trained from the consensus of the online reviews we have gathered."
99,Gavin Wood;Simon O'Keefe,A Case Study of Distributed Music Audio Analysis Using the Geddei Processing Framework.,2004,https://doi.org/10.5281/zenodo.1414810,Gavin Wood+University of York>GBR>education;Simon O'Keefe++University of York>GBR>education,"Audio signal processing and refinement is an important part of a content-based music information retrieval system. As the our repertoire of techniques becomes more varied, there are greater requirements of computation power. Distributed storage techniques have become widespread and almost invisible with the advent of file-sharing systems, online digital music stores and online storage services. Even discounting data with potential copyright entanglements, there is a vast amount that is ripe for analysis, and thus parallelised and distributed processing techniques seem increasingly appropriate. Existing frameworks are already capable of a significant amount of audio analysis for music information retrieval. However they are by and large ignorant of distribution and parallelisation. There are middleware libraries to help with aspects of distributed computing, but combining the two can be cumbersome and inefficient. This paper provides a brief description of a software framework that can process audio in a scalable and distributed manner: Geddei. The paper then takes an interesting and relevant signal analysis task often used for music information retrieval and implements it under the Geddei framework. The ease of use is discussed and various measurements taken of Geddei, both in comparison to itself under different circumstances, and ‘reference code’ that was used in a previous study. We discuss the problems with the distribution of the task with Geddei and offer some possible solutions."
100,Otto Wüst;Òscar Celma,An MPEG-7 Database System and Application for Content-Based Management and Retrieval of Music.,2004,https://doi.org/10.5281/zenodo.1418375,Otto Wust+Universitat Pompeu Fabra>ESP>education|Music Technology Group>Unknown>Unknown;Oscar Celma+Universitat Pompeu Fabra>ESP>education|Music Technology Group>Unknown>Unknown,"Computer users are gaining access to and are starting to accumulate moderately large collections of multimedia files, in particular of audio content, and therefore demand new applications and systems capable of effectively retrieving and manipulating these multimedia objects. Content-based retrieval of multimedia files is typically based on searching within a feature space, defined as a collection of parameters that have been extracted from the content and which describe it in a relevant way for that particular retrieval application. The MPEG-7 standard offers tools to model these metadata in an interoperable and extensible way, and can therefore be considered as a framework for building content-based audio retrieval systems. This paper highlights the most relevant aspects considered during the design and implementation of a DBMS-driven MPEG-7 layer on top of which a content-based music retrieval system has been built. A particular focus is set on the data modeling and database architecture issues."
101,Dan Yang 0002;Won-Sook Lee,Disambiguating Music Emotion Using Software Agents.,2004,https://doi.org/10.5281/zenodo.1415272,Dan Yang+University of Ottawa>CAN>education;Won Sook Lee+University of Ottawa>CAN>education,"Annotating music poses a cognitive load on listeners and this potentially interferes with the emotions being reported. One solution is to let software agents learn to make the annotator’s task easier and more efficient. Emo is a music annotation prototype that combines inputs from both human and software agents to better study human listening. A compositional theory of musical meaning provides the overall heuristics for the annotation process, with the listener drawing upon different influences such as acoustics, lyrics and cultural metadata to focus on a specific musical mood. Software agents track the way these choices are made from the influences available. A functional theory of human emotion provides the basis for introducing necessary bias into the machine learning agents. Conflicting positive and negative emotions can be separated on the basis of their different function (reward-approach and threat-avoidance) or dysfunction (psychotic). Negative emotions have strong ambiguity and these are the focus of the experiment. The results of mining psychological features of lyrics are promising, recognisable in terms of common sense ideas of emotion and in terms of accuracy. Further ideas for deploying agents in this model of music annotation are presented."
102,Kazuyoshi Yoshii;Masataka Goto;Hiroshi G. Okuno,Automatic Drum Sound Description for Real-World Music Using Template Adaptation and Matching Methods.,2004,https://doi.org/10.5281/zenodo.1415958,Kazuyoshi Yoshii+Kyoto University>JPN>education|National Institute of Advanced Industrial Science and Technology (AIST)>JPN>facility;Masataka Goto+National Institute of Advanced Industrial Science and Technology (AIST)>JPN>facility;Hiroshi G. Okuno+Kyoto University>JPN>education,"This paper presents an automatic description system of drum sounds for real-world musical audio signals. Our system can represent onset times and names of drums by means of drum descriptors defined in the context of MPEG-7. For their automatic description, drum sounds must be identified in such polyphonic signals. The problem is that acoustic features of drum sounds vary with each musical piece and precise templates for them cannot be prepared in advance. To solve this problem, we propose new template-adaptation and template-matching methods. The former method adapts a single seed template prepared for each kind of drums to the corresponding drum sound appearing in an actual musical piece. The latter method then can detect all the onsets of each drum by using the corresponding adapted template. The onsets of bass and snare drums in any piece can thus be identified. Experimental results showed that the accuracy of identifying bass and snare drums in popular music was about 90%. Finally, we define drum descriptors in the MPEG-7 format and demonstrate an example of the automatic drum sound description for a piece of popular music."
103,Takuya Yoshioka;Tetsuro Kitahara;Kazunori Komatani;Tetsuya Ogata;Hiroshi G. Okuno,Automatic Chord Transcription with Concurrent Recognition of Chord Symbols and Boundaries.,2004,https://doi.org/10.5281/zenodo.1415068,Takuya Yoshioka+Kyoto University>JPN>education;Tetsuro Kitahara+Kyoto University>JPN>education;Kazunori Komatani+Kyoto University>JPN>education;Tetsuya Ogata+Kyoto University>JPN>education;Hiroshi G. Okuno+Kyoto University>JPN>education,"This paper describes a method that recognizes musical chords from real-world audio signals in compact-disc recordings. The automatic recognition of musical chords is necessary for music information retrieval (MIR) systems, since the chord sequences of musical pieces capture the characteristics of their accompaniments. None of the previous methods can accurately recognize musical chords from complex audio signals that contain vocal and drum sounds. The main problem is that the chord-boundary-detection and chord-symbol-identification processes are inseparable because of their mutual dependency. In order to solve this mutual dependency problem, our method generates hypotheses about tuples of chord symbols and chord boundaries, and outputs the most plausible one as the recognition result. The certainty of a hypothesis is evaluated based on three cues: acoustic features, chord progression patterns, and bass sounds. Experimental results show that our method successfully recognized chords in seven popular music songs; the average accuracy of the results was around 77%."
104,Mark Zadel;Ichiro Fujinaga,Web Services for Music Information Retrieval.,2004,https://doi.org/10.5281/zenodo.1417069,Mark Zadel+McGill University>CAN>education|Unknown>Unknown>Unknown;Ichiro Fujinaga+McGill University>CAN>education|Unknown>Unknown>Unknown,"In the emerging world of networked and distributed digital libraries, the Web services framework will be a key to facilitating simple inter-application communication between them. Yet, despite the popularity of Web services in the business sector and their seemingly obvious applicability to the digital library domain, and to MIR in particular, the adoption of these new protocols has not been widespread. To demonstrate the tremendous potential of Web services for MIR, this paper presents an application using the Google and Amazon.com databases to generate clusters of related musical artists based on cultural metadata. The use of cultural metadata to determine artist relatedness is valuable and interesting because it captures emergent popular opinion about music. Starting from an initial seed artist, Amazon Listmania! lists are traversed to find potentially related artists. Google is used to determine which of these candidates are in fact related by assessing the co-occurrence of the two artists’ names on Internet web pages. A list of artists related to the seed is returned once a given number of artists is found. The positive results generated by the system illustrate the use of Web services for exploiting the vast amount of untapped data that are available today and highlight their importance for the future, when even more musical data will become available."
