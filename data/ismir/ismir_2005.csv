Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,Jin Ha Lee;J. Stephen Downie;Sally Jo Cunningham,Challenges in Cross-Cultural/Multilingual Music Information Seeking.,2005,https://doi.org/10.5281/zenodo.1416706,"Jin Ha Lee, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;Sally Jo Cunningham, University of Waikato, NZL, education","""Understanding and meeting the needs of a broad range of music users across different cultures and languages are central in designing a global music digital library. This exploratory study examines cross-cultural/multilingual music information seeking behaviors and reveals some important characteristics of these behaviors by analyzing 107 authentic music information queries from a Korean knowledge search portal Naver 지식 (knowledge) iN and 150 queries from Google Answers website. We conclude that new sets of access points must be developed to accommodate music queries that cross cultural or language boundaries."""
1,Cynthia M. Grund,"Music Information Retrieval, Memory and Culture: Some Philosohpical Remarks.",2005,https://doi.org/10.5281/zenodo.1415626,"Cynthia M. Grund, University of Southern Denmark, DNK, education","The burgeoning field of Music Information Retrieval (MIR) raises issues which are of interest within traditional areas of discussion in philosophy of music and of philosophy of culture in general. The purpose of this paper is twofold: the first goal is to highlight and briefly discuss a selection of these issues, while the second is to make a case for increased mutual awareness of each other on the parts of MIR and of humanistic research. Many traditional debates within the latter receive infusions of new perspectives from MIR, while research within MIR could be fruitfully pointed in directions suggested by questions of interest within traditional research in the humanities, e.g. the relationship of individual memory to cultural memory, issues regarding cross-cultural understanding and the importance of authenticity in artistic contexts."
2,Noris Mohd. Norowi;Shyamala Doraisamy;Rahmita Wirza O. K. Rahmat,Factors Affecting Automatic Genre Classification: An Investigation Incorporating Non-Western Musical Forms.,2005,https://doi.org/10.5281/zenodo.1418067,"Noris Mohd Norowi, University Putra Malaysia, MYS, education;Shyamala Doraisamy, University Putra Malaysia, MYS, education;Rahmita Wirza, University Putra Malaysia, MYS, education","The number of studies investigating automated genre classification is growing following the increasing amounts of digital audio data available. The underlying techniques to perform automated genre classification in general include feature extraction and classification. In this study, MARSYAS was used to extract audio features and the suite of tools available in WEKA was used for the classification. This study investigates the factors affecting automated genre classification. As for the dataset, most studies in this area work with western genres and traditional Malay music is incorporated in this study. Eight genres were introduced; Dikir Barat, Etnik Sabah, Inang, Joget, Keroncong, Tumbuk Kalang, Wayang Kulit, and Zapin.  A total of 417 tracks from various Audio Compact Discs were collected and used as the dataset. Results show that various factors such as the musical features extracted, classifiers employed, the size of the dataset, excerpt length, excerpt location and test set parameters improve classification results.  "
3,Markus Schedl;Peter Knees;Gerhard Widmer,Discovering and Visualizing Prototypical Artists by Web-Based Co-Occurrence Analysis.,2005,https://doi.org/10.5281/zenodo.1418315,"Markus Schedl, Johannes Kepler University (JKU), AUT, education, Austrian Research Institute for Artificial Intelligence (ÖFAI), AUT, facility;Peter Knees, Johannes Kepler University (JKU), AUT, education;Gerhard Widmer, Johannes Kepler University (JKU), AUT, education, Austrian Research Institute for Artificial Intelligence (ÖFAI), AUT, facility","Detecting artists that can be considered as prototypes for particular genres or styles of music is an interesting task. In this paper, we present an approach that ranks artists according to their prototypicality. To calculate such a ranking, we use asymmetric similarity matrices obtained via co-occurrence analysis of artist names on web pages. We demonstrate our approach on a data set containing 224 artists from 14 genres and evaluate the results using the rank correlation between the prototypicality ranking and a ranking obtained by page counts of search queries to Google that contain artist and genre. High positive rank correlations are achieved for nearly all genres of the data set. Furthermore, we elaborate a visualization method that illustrates similarities between artists using the prototypes of all genres as reference points. On the whole, we show how to create a prototypicality ranking and use it, together with a similarity matrix, to visualize a music repository."
4,Ian Knopke,Geospatial Location of Music and Sound Files for Music Information Retrieval.,2005,https://doi.org/10.5281/zenodo.1417765,"Ian Knopke, McGill Music Technology, CAN, education","A relatively new avenue of Web-based information re-
trieval research, intended to semantically improve infor-
mation extraction, is the idea of using geographical infor-
mation to accurately locate resources. This paper intro-
duces a technique for locating sound and music ﬁles ge-
ographically. It uses information extracted from the Web
relating to audio resources and combines it with geospa-
tial location data to provide new information about audio
usage in various countries. The results presented here il-
lustrate the enormous potential for MIR to use the vast
amount of audio materials on the Web within a physical
and geographical context. Statistics of audio usage around
the world are provided, as well as examples of other ap-
plications of these techniques."
5,Thomas Lidy;Andreas Rauber,Evaluation of Feature Extractors and Psycho-Acoustic Transformations for Music Genre Classification.,2005,https://doi.org/10.5281/zenodo.1416856,"Thomas Lidy, Vienna University of Technology, AUT, education;Andreas Rauber, Vienna University of Technology, AUT, education","We present a study on the importance of psycho-acoustic transformations for effective audio feature calculation. From the results, both crucial and problematic parts of the algorithm for Rhythm Patterns feature extraction are identiﬁed. We furthermore introduce two new feature rep- resentations in this context: Statistical Spectrum Descrip- tors and Rhythm Histogram features. Evaluation on both the individual and combined feature sets is accomplished through a music genre classiﬁcation task, involving 3 ref- erence audio collections. Results are compared to pub- lished measures on the same data sets. Experiments con- ﬁrmed that in all settings the inclusion of psycho-acoustic transformations provides signiﬁcant improvement of clas- siﬁcation accuracy."
6,Cory McKay;Rebecca Fiebrink;Daniel McEnnis;Beinan Li;Ichiro Fujinaga,ACE: A Framework for Optimizing Music Classification.,2005,https://doi.org/10.5281/zenodo.1415720,"Cory McKay, McGill University, CAN, education;Rebecca Fiebrink, McGill University, CAN, education;Daniel McEnnis, McGill University, CAN, education;Beinan Li, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","""This paper presents ACE (Autonomous Classification Engine), a framework for using and optimizing classifiers. Given a set of feature vectors, ACE experiments with a variety of classifiers, classifier parameters, classifier ensembles and dimensionality reduction techniques in order to arrive at a good configuration for the problem at hand. In addition to evaluating classification methodologies in terms of success rates, functionality is also being incorporated into ACE allowing users to specify constraints on training and classification times as well as on the amount of time that ACE has to arrive at a solution. ACE is designed to facilitate classification for those new to pattern recognition as well as provide flexibility for those with more experience. ACE is packaged with audio and MIDI feature extraction software, although it can certainly be used with existing feature extractors. This paper includes a discussion of ways in which existing general-purpose classification software can be adapted to meet the needs of music researchers and shows how these ideas have been implemented in ACE. A standardized XML format for communicating features and other information to classifiers is proposed. A special emphasis is placed on the potential of classifier ensembles, which have remained largely untapped by the MIR community to date. A brief theoretical discussion of ensemble classification is presented in order to promote this powerful approach."""
7,Koen Tanghe;Micheline Lesaffre;Sven Degroeve;Marc Leman;Bernard De Baets;Jean-Pierre Martens,Collecting Ground Truth Annotations for Drum Detection in Polyphonic Music.,2005,https://doi.org/10.5281/zenodo.1417715,"Koen Tanghe, Ghent University, BEL, education;Micheline Lesaffre, Ghent University, BEL, education;Sven Degroeve, Ghent University, BEL, education;Marc Leman, Ghent University, BEL, education;Bernard De Baets, Ghent University, BEL, education;Jean-Pierre Martens, Ghent University, BEL, education","""In order to train and test algorithms that can automatically detect drum events in polyphonic music, ground truth data is needed. This paper describes a setup used for gathering manual annotations for 49 real-world music fragments containing different drum event types. Apart from the drum events, the beat was also annotated. The annotators were experienced drummers or percussionists. This paper is primarily aimed towards other drum detection researchers, but might also be of interest to others dealing with automatic music analysis, manual annotation and data gathering. Its purpose is threefold: providing annotation data for algorithm training and evaluation, describing a practical way of setting up a drum annotation task, and reporting issues that came up during the annotation sessions while at the same time providing some thoughts on important points that could be taken into account when setting up similar tasks in the future."""
8,Gavin Wood;Simon O'Keefe,On Techniques for Content-Based Visual Annotation to Aid Intra-Track Music Navigation.,2005,https://doi.org/10.5281/zenodo.1417401,"Gavin Wood, University of York, GBR, education;Simon O’Keefe, University of York, GBR, education","Despite the fact that people are increasingly listening to music electronically, the core interface of the common tools for playing the music have had very little improvement. In particular the tools for intra-track navigation have remained basically static, not taking advantage of recent studies into the field of audio jisting, summarising and segmentation. We introduce a novel mechanism for musical audio linear summarisation and modify a widely used open source media player to utilise several music information retrieval techniques directly in the graphical user interface. With a broad range of music, we provide a qualitative discussion on several techniques used for content-based music information retrieval and perform quantitative investigation to their usefulness."
9,Christopher Harte;Mark B. Sandler;Samer A. Abdallah;Emilia Gómez,Symbolic Representation of Musical Chords: A Proposed Syntax for Text Annotations.,2005,https://doi.org/10.5281/zenodo.1415114,"Christopher Harte, Queen Mary, University of London, GBR, education;Mark Sandler, Queen Mary, University of London, GBR, education;Samer Abdallah, Queen Mary, University of London, GBR, education;Emilia Gómez, Universitat Pompeu Fabra, ESP, education","In this paper we propose a text represention for musical chord symbols that is simple and intuitive for musically trained individuals to write and understand, yet highly structured and unambiguous to parse with computer programs."
10,Mika Kuuskankare;Mikael Laurson,Annotating Musical Scores in ENP.,2005,https://doi.org/10.5281/zenodo.1417805,"Mika Kuuskankare, Sibelius Academy, Finland, education;Mikael Laurson, Sibelius Academy, Finland, education","""The focus of this paper is on ENP-expressions that can be used for annotating ENP scores with user deﬁnable information. ENP is a music notation program written in Lisp and CLOS with a special focus on compositional and music analytical applications. We present number of built-in expressions suitable for visualizing, for example, music analytical information as a part of music notation. A Lisp and CLOS based system for creating user-deﬁnable annotation information is also presented along with some sample algorithms. Finally, our system for automatically analyzing and annotating an ENP score is illustrated through several examples including some dealing with music information retrieval."""
11,Perfecto Herrera;Òscar Celma;Jordi Massaguer;Pedro Cano;Emilia Gómez;Fabien Gouyon;Markus Koppenberger,MUCOSA: A Music Content Semantic Annotator.,2005,https://doi.org/10.5281/zenodo.1415980,"Perfecto Herrera, Universitat Pompeu Fabra, ESP, education;Òscar Celma, Universitat Pompeu Fabra, ESP, education;Jordi Massaguer, Universitat Pompeu Fabra, ESP, education;Pedro Cano, Universitat Pompeu Fabra, ESP, education;Emilia Gómez, Universitat Pompeu Fabra, ESP, education;Fabien Gouyon, Universitat Pompeu Fabra, ESP, education;Markus Koppenberger, Universitat Pompeu Fabra, ESP, education;David García, Universitat Pompeu Fabra, ESP, education;José-Pedro García, Universitat Pompeu Fabra, ESP, education;Nicolas Wack, Universitat Pompeu Fabra, ESP, education","MUCOSA (Music Content Semantic Annotator) is an environment for the annotation and generation of music metadata at different levels of abstraction. It is composed of three tiers: an annotation client that deals with micro-annotations (i.e. within-file annotations), a collection tagger, which deals with macro-annotations (i.e. across-files annotations), and a collaborative annotation subsystem, which manages large-scale annotation tasks that can be shared among different research centres. The annotation client is an enhanced version of WaveSurfer, a speech annotation tool. The collection tagger includes tools for automatic generation of unary descriptors, invention of new descriptors, and propagation of descriptors across sub-collections or playlists. Finally, the collaborative annotation subsystem, based on Plone, makes possible to share the annotation chores and results between several research institutions. A collection of annotated songs is available, as a “starter pack” to all the individuals or institutions that are eager to join this initiative."
12,Shoichiro Saito;Hirokazu Kameoka;Takuya Nishimoto;Shigeki Sagayama,Specmurt Analysis of Multi-Pitch Music Signals with Adaptive Estimation of Common Harmonic Structure .,2005,https://doi.org/10.5281/zenodo.1417707,"Shoichiro Saito, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Hirokazu Kameoka, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Takuya Nishimoto, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Shigeki Sagayama, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education","This paper describes a multi-pitch analysis method using specmurt analysis with iterative estimation of the quasi-optimal common harmonic structure function. Specmurt analysis (Sagayama et al., 2004) is based upon the idea that superimposed harmonic structure pattern can be expressed as a convolution of two components, a fundamental frequency distribution and a ‘common harmonic structure’ function if each underlying tone component has similar harmonic structure pattern. As proved in our previous work (Sagayama et al., 2004) inappropriate common structure function leads to inaccurate analysis results. The iterative algorithm proposed in this paper automatically chooses a proper structure, which results in finding concurrent multiple fundamental frequencies and reduces the dependency on heuristically chosen initial common harmonic structure. The experimental evaluation showed promising results."
13,Olivier Gillet;Gaël Richard,Drum Track Transcription of Polyphonic Music Using Noise Subspace Projection.,2005,https://doi.org/10.5281/zenodo.1415606,"Olivier Gillet, GET / T´el´ecom Paris, CNRS LTCI, France, education;Ga¨el Richard, GET / T´el´ecom Paris, CNRS LTCI, France, education","""This paper presents a novel drum transcription system for polyphonic music. The use of a band-wise harmonic/noise decomposition allows the suppression of the deterministic part of the signal, which is mainly contributed by non-rhythmic instruments. The transcription is then performed on the residual noise signal, which contains most of the rhythmic information. This signal is segmented, and the events associated to each onset are classiﬁed by support vector machines (SVM) with probabilistic outputs. The features used for classiﬁcation are directly extracted from the sub-band signals. An additional pre-processing stage in which the instances are reclassiﬁed using a localized model was also tested. This transcription method is evaluated on ten test sequences, each of them being performed by two drummers and being available with different mixing settings. The whole system achieves precision and recall rates of 84% for the bass drum and snare drum detection tasks."""
14,Nick Collins,Using a Pitch Detector for Onset Detection.,2005,https://doi.org/10.5281/zenodo.1417309,"Nick Collins, University of Cambridge, Centre for Music and Science, UK, education","A segmentation strategy is explored for monophonic in- strumental pitched non-percussive material (PNP) which proceeds from the assertion that human-like event analy- sis can be founded on a notion of stable pitch percept. A constant-Q pitch detector following the work of Brown and Puckette provides pitch tracks which are post pro- cessed in such a way as to identify likely transitions be- tween notes. A core part of this preparation of the pitch detector signal is an algorithm for vibrato suppression. An evaluation task is undertaken on slow attack and high vi- brato PNP source ﬁles with human annotated onsets, ex- emplars of a difﬁcult case in monophonic source segmen- tation. The pitch track onset detection algorithm shows an improvement over the previous best performing algorithm from a recent comparison study of onset detectors. Whilst further timbral cues must play a part in a general solution, the method shows promise as a component of a note event analysis system."
15,Parag Chordia,Segmentation and Recognition of Tabla Strokes.,2005,https://doi.org/10.5281/zenodo.1416000,"Parag Chordia, CCRMA, Stanford University, USA, education","A system that segments and labels tabla strokes from real performances is described. Performance is evaluated on a large database taken from three performers under different recording conditions, containing a total of 16,834 strokes. The current work extends previous work by Gillet and Richard (2003) on categorizing tabla strokes, by using a larger, more diverse database that includes their data as a benchmark, and by testing neural networks and tree-based classification methods. First, the time-domain signal was segmented using complex-domain thresholding that looked for sudden changes in amplitude and phase discontinuities. At the optimal point on the ROC curve, false positives were less than 1% and false negatives were less than 2%. Then, classification was performed using a multivariate Gaussian model (mv gauss) as well as non-parametric techniques such as probabilistic neural networks (pnn), feed-forward neural networks (ffnn), and tree-based classifiers. Two evaluation protocols were used. The first used 10-fold cross validation. The recognition rate averaged over several experiments that contained 10-15 classes was 92% for the mv gauss, 94% for the ffnn and pnn, and 84% for the tree based classifier. To test generalization, a more difficult independent evaluation was undertaken in which no test strokes came from the same recording as the training strokes. The average recognition rate over a wide variety of test conditions was 76% for the mv gauss, 83% for the ffnn, 76% for the pnn, and 66% for the tree classifier."
16,Hirokazu Kameoka;Takuya Nishimoto;Shigeki Sagayama,Harmonic-Temporal Clustering via Deterministic Annealing EM Algorithm for Audio Feature Extraction.,2005,https://doi.org/10.5281/zenodo.1417629,"Hirokazu Kameoka, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Takuya Nishimoto, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Shigeki Sagayama, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education","""This paper proposes “harmonic-temporal structured clus-
tering (HTC) method”, that allows simultaneous estima-
tion of pitch, intensity, onset, duration, etc., of each under-
lying source in multi-stream audio signal, which we ex-
pect to be an effective feature extraction for MIR systems.
STC decomposes the energy patterns diffused in time-
frequency space, i.e., a time series of power spectrum, into
distinct clusters such that each of them is originated from
a single sound stream. It becomes clear that the problem
is equivalent to geometrically approximating the observed
time series of power spectrum by superimposed harmonic-
temporal structured models (HTMs), whose parameters
are directly associated with the speciﬁc acoustic charac-
teristics. The update equations in DA(Deterministic An-
nealing)EM algorithm for the optimal parameter conver-
gence are derived by formulating the model with Gaussian
kernel representation. The experiment showed promising
results, and veriﬁed the potential of the proposed method."""
17,Jenn Riley,Exploiting Musical Connections: A Proposal for Support of Work Relationships in a Digital Music Library.,2005,https://doi.org/10.5281/zenodo.1415660,"Jenn Riley, Indiana University Digital Library Program, USA, education","Musical works in the Western art music tradition exist in a complex, inter-related web. Works that are de- rivative or part of another work are common; how- ever, most music information retrieval systems, in- cluding traditional library catalogs, don’t use these essential relationships to improve search results or provide information about them to end-users. As part of the NSF-funded Variations2 Digital Music Library project at Indiana University, we have developed a set of functional requirements defining how derivative and whole/part relationships between musical works should be acted upon in search results, and how these results should be displayed. This paper describes re- cent research into these relationships, provides exam- ples why they are important in Western art music, outlines how Variations2 or any other music informa- tion retrieval system could use these relationships in matching user queries, and describes optimal displays of these relationships to end-users."
18,Ajay Kapur;Richard I. McWalter;George Tzanetakis,New Music Interfaces for Rhythm-Based Retrieval.,2005,https://doi.org/10.5281/zenodo.1418313,"Ajay Kapur, University of Victoria, CAN, education;Richard I. McWalter, University of Victoria, CAN, education;George Tzanetakis, University of Victoria, CAN, education","In the majority of existing work in music information re-
trieval (MIR) the user interacts with the system using stan-
dard desktop components such as the keyboard, mouse or
sometimes microphone input. It is our belief that moving
away from the desktop to more physically tangible ways
of interacting can lead to novel ways of thinking about
MIR. In this paper, we report on our work in utilizing
new non-standard interfaces for MIR purposes. One of
the most important but frequently neglected ways of char-
acterizing and retrieving music is through rhythmic infor-
mation. We concentrate on rhythmic information both as
user input and as means for retrieval. Algorithms and ex-
periments for rhythm-based information retrieval of mu-
sic, drum loops and indian tabla thekas are described. This
work targets expert users such as DJs and musicians which
tend to be more curious about new technologies and there-
fore can serve as catalysts for accelerating the adoption of
MIR techniques. In addition, we describe how the pro-
posed rhythm-based interfaces can assist in the annotation
and preservation of perfomance practice."
19,Ioannis Karydis;Alexandros Nanopoulos;Apostolos N. Papadopoulos;Dimitrios Katsaros 0001;Yannis Manolopoulos,Content-Based Music Information Retrieval in Wireless Ad-Hoc Networks.,2005,https://doi.org/10.5281/zenodo.1417665,"Ioannis Karydis, Aristotle University, GRC, education;Alexandros Nanopoulos, Aristotle University, GRC, education;Dimitrios Katsaros, Aristotle University, GRC, education;Yannis Manolopoulos, Aristotle University, GRC, education;Apostolos Papadopoulos, Aristotle University, GRC, education","""This paper, introduces the application of Content-Based Music Information Retrieval (CBMIR) in wireless ad-hoc networks. We investigate for the ﬁrst time the challenges posed by the wireless medium and recognise the factors that require optimisation. We propose novel techniques, which attain a signiﬁcant reduction in both response times and trafﬁc, compared to naive approaches. Extensive ex- perimental results illustrate the appropriateness and efﬁ- ciency of the proposed method in this bandwidth-starving and volatile, due to mobility, environment."""
20,Richard Lobb;Tim Bell;David Bainbridge 0001,Fast Capture of Sheet Music for an Agile Digital Music Library.,2005,https://doi.org/10.5281/zenodo.1417989,"Richard Lobb, University of Canterbury, NZL, education;Tim Bell, University of Canterbury, NZL, education;David Bainbridge, University of Waikato, NZL, education","A personal digital music library needs to be “agile”, that is, it needs to make it easy to capture and index material on the ﬂy. A digital camera is a particularly effective way of achieving this, but there are several issues with the quality of the captured image, including distortions in the shape of the image due to the camera not being aligned prop- erly with the page, non-planarity of the page, lens distor- tion from close-up shots, and inconsistent lighting across the page. In this paper we explore ways to improve the quality of music images captured by a digital camera or an inexpensive scanner, where the user is not expected to pay a lot of attention to the process. Such pre-processing will signiﬁcantly aid Music Information Retrieval index- ing through Optical Music Recognition, for example. The research presented here is primarily based around using a Fast Fourier Transform (FFT) to determine the orien- tation of the page. We ﬁnd that a windowed FFT is ef- fective at correcting rotational errors, and we make sig- niﬁcant progress towards removing perspective distortion introduced by the camera not being parallel with the mu- sic."
21,Rainer Typke;Frans Wiering;Remco C. Veltkamp,A Survey of Music Information Retrieval Systems.,2005,https://doi.org/10.5281/zenodo.1417383,"Rainer Typke, Universiteit Utrecht, NLD, education;Frans Wiering, Universiteit Utrecht, NLD, education;Remco C. Veltkamp, Universiteit Utrecht, NLD, education","""This survey paper provides an overview of content-based
music information retrieval systems, both for audio and
for symbolic music notation. Matching algorithms and
indexing methods are brieﬂy presented. The need for a
TREC-like comparison of matching algorithms such as
MIREX at ISMIR becomes clear from the high number
of quite different methods which so far only have been
used on different data collections. We placed the systems
on a map showing the tasks and users for which they are
suitable, and we ﬁnd that existing content-based retrieval
systems fail to cover a gap between the very general and
the very speciﬁc retrieval tasks."""
22,Graham E. Poliner;Daniel P. W. Ellis,A Classification Approach to Melody Transcription.,2005,https://doi.org/10.5281/zenodo.1414796,"Graham E. Poliner, Columbia University, USA, education;Daniel P.W. Ellis, Columbia University, USA, education","Melodies provide an important conceptual summarization of polyphonic audio. The extraction of melodic content has practical applications ranging from content-based au- dio retrieval to the analysis of musical structure. In con- trast to previous transcription systems based on a model of the harmonic (or periodic) structure of musical pitches, we present a classiﬁcation-based system for performing au- tomatic melody transcription that makes no assumptions beyond what is learned from its training data. We evalu- ate the success of our algorithm by predicting the melody of the ISMIR 2004 Melody Competition evaluation set and on newly-generated test data. We show that a Sup- port Vector Machine melodic classiﬁer produces results comparable to state of the art model-based transcription systems."
23,Emilios Cambouropoulos;Maxime Crochemore;Costas S. Iliopoulos;Manal Mohamed;Marie-France Sagot,A Pattern Extraction Algorithm for Abstract Melodic Representations that Allow Partial Overlapping of Intervallic Categories.,2005,https://doi.org/10.5281/zenodo.1415008,"Emilios Cambouropoulos, University of Thessaloniki, GRC, education;Maxime Crochemore, University of Marne-la-Vallée, FRA, education;Costas Iliopoulos, King’s College London, GBR, education;Manal Mohamed, King’s College London, GBR, education;Marie-France Sagot, INRIA Rhône-Alpes, Université Claude Bernard, FRA, facility","""This paper proposes an efﬁcient pattern extraction algorithm that can be applied on melodic sequences that are represented as strings of abstract intervallic symbols; the melodic representation introduces special “don’t care” symbols for intervals that may belong to two partially overlapping intervallic categories. As a special case the well established “step-leap” representation is examined. In the step-leap representation, each melodic diatonic interval is classiﬁed as a step (±s), a leap (±l) or a unison (u). Binary don’t care symbols are introduced to represent the possible overlapping between the various abstract categories e.g. ∗ = s, ∗ = l and # = −s, # = −l. For such a sequence, we are interested in ﬁnding maximal repeating pairs and repetitions with a hole (two matching subsequences separated with an intervening non-matching symbol). We propose an O(n + d(n − d) + z)-time algorithm for computing all such repetitions in a given sequence x = x[1..n] with d binary don’t care symbols, where z is the output size."""
24,Rui Pedro Paiva,On the Detection of Melody Notes in Polyphonic Audio.,2005,https://doi.org/10.5281/zenodo.1417681,"Rui Pedro Paiva, Centre for Informatics and Systems of the University of Coimbra, PRT, education;Teresa Mendes, Centre for Informatics and Systems of the University of Coimbra, PRT, education;Amílcar Cardoso, Centre for Informatics and Systems of the University of Coimbra, PRT, education","""This paper describes a method for melody detection in polyphonic musical signals. Our approach starts by obtaining a set of pitch candidates for each time frame, with recourse to an auditory model. Trajectories of the most salient pitches are then constructed. Next, note candidates are obtained by trajectory segmentation (in terms of frequency and pitch salience variations). Too short, low-salience and harmonically related notes are then eliminated. Finally, the notes comprising the melody are extracted. This is the main topic of this paper. We select the melody notes by making use of note saliences and melodic smoothness. First, we select the notes with highest pitch salience at each moment. Then, by the melodic smoothness principle, we exploit the fact that tonal melodies are usually smooth. Thus, long music intervals indicate the presence of possibly erroneous notes, which are substituted by notes that smooth out the melodic contour. Finally, false positives in the extracted melody should be eliminated. To this end, we remove spurious notes that correspond to abrupt drops in note saliences or durations. Additionally, note clustering is conducted to further discriminate between true melody notes and false positives."""
25,Wei-Ho Tsai;Hung-Ming Yu;Hsin-Min Wang,Query-By-Example Technique for Retrieving Cover Versions of Popular Songs with Similar Melodies.,2005,https://doi.org/10.5281/zenodo.1415200,"Wei-Ho Tsai, Institute of Information Science, Academia Sinica, TWN, facility;Hung-Ming Yu, Institute of Information Science, Academia Sinica, TWN, facility;Hsin-Min Wang, Institute of Information Science, Academia Sinica, TWN, facility","Retrieving audio material based on audio queries is an important and challenging issue in the research field of content-based access to popular music. As part of this research field, we present a preliminary investigation into retrieving cover versions of songs specified by users. The technique enables users to listen to songs with an identical tune, but performed by different singers, in different languages, genres, and so on. The proposed system is built on a query-by-example framework, which takes a fragment of the song submitted by the user as input, and returns songs similar to the query in terms of the main melody as output. To handle the likely discrepancies, e.g., tempos, transpositions, and accompaniments between cover versions and the original song, methods are presented to remove the non-vocal portions of the song, extract the sung notes from the accompanied vocals, and compare the similarities between the sung note sequences."
26,Olivier Lartillot,Efficient Extraction of Closed Motivic Patterns in Multi-Dimensional Symbolic Representations of Music.,2005,https://doi.org/10.5281/zenodo.1418129,"Olivier Lartillot, University of Jyvaskyla, FIN, education","An efﬁcient model for discovering repeated patterns in symbolic representations of music is presented. Combinatorial redundancy inherent in the pattern discovery paradigm is usually ﬁltered using global selective mechanisms, based on pattern frequency and length. The proposed approach is founded instead on the concept of closed pattern, and insures lossless compression through an adaptive selection of most speciﬁc descriptions in the multi-dimensional parametric space. A notion of cyclic pattern is introduced, enabling the ﬁltering of another form of combinatorial redundancy provoked by successive repetitions of patterns. The use of cyclic patterns implies a necessary chronological scanning of the piece, and the addition of mechanisms formalising particular Gestalt principles. This study shows therefore that automated analysis of music cannot rely on simple mathematical or statistical approaches, but requires instead a complex and detailed modelling of the cognitive system ruling the listening processes. The resulting algorithm is able to offer for the ﬁrst time compact and relevant motivic analyses of monodies, and may therefore be applied to automated indexing of symbolic music databases. Numerous additional mechanisms need to be added in order to consider all aspects of music expression, including polyphony and complex motivic transformations."
27,Norman H. Adams;Daniela Marquez;Gregory H. Wakefield,Iterative Deepening for Melody Alignment and Retrieval.,2005,https://doi.org/10.5281/zenodo.1415712,"Norman Adams, University of Michigan, USA, education;Daniela Marquez, University of Michigan, USA, education;Gregory Wakefield, University of Michigan, USA, education","For melodic theme retrieval there is a fundamental trade-off between retrieval performance and retrieval speed. Melodic representations of large dimension yield the best retrieval performance, but at high computational cost, and vice versa. In the present work we explore the use of iterative deepening to achieve robust retrieval performance, but without the accompanying computational burden. In particular, we propose the use of a smooth pitch contour that facilitates query and target representations of variable length. We implement an iterative query-by-humming system that yields a dramatic increase in speed, without degrading performance compared to contemporary retrieval systems. Furthermore, we expand the conventional iterative framework to retain the alignment paths found in each iteration. These alignment paths are used to adapt the alignment window of subsequent iterations, further expediting retrieval without degrading performance."
28,Jeremy Pickens;Costas S. Iliopoulos,Markov Random Fields and Maximum Entropy Modeling for Music Information Retrieval.,2005,https://doi.org/10.5281/zenodo.1414716,"Jeremy Pickens, King’s College London, GBR, education;Costas Iliopoulos, King’s College London, GBR, education","Music information retrieval is characterized by a number of various user information needs. Systems are being developed that allow searchers to find melodies, rhythms, genres, and singers or artists, to name but a few. At the heart of all these systems is the need to find models or measures that answer the question “how similar are two given pieces of music”. However, similarity has a variety of meanings depending on the nature of the system being developed. More importantly, the features extracted from a music source are often either single-dimensional (i.e.: only pitch, or only rhythm, or only timbre) or else assumed to be orthogonal. In this paper we present a framework for developing systems which combine a wide variety of non-independent features without having to make the independence assumption. As evidence of effectiveness, we evaluate the system on the polyphonic theme similarity task over symbolic data. Nevertheless, we emphasize that the framework is general, and can handle a range of music information retrieval tasks."
29,Bryan Pardo;Manan Sanghi,Polyphonic Musical Sequence Alignment for Database Search.,2005,https://doi.org/10.5281/zenodo.1417909,"Bryan Pardo, Northwestern University, USA, education;Manan Sanghi, Northwestern University, USA, education","Finding the best matching database target to a melodic 
query has been of great interest in the music IR world. 
The string alignment paradigm works well for this 
task when comparing a monophonic query to a 
database of monophonic pieces. However, most tonal 
music is polyphonic, with multiple concurrent musical 
lines. Such pieces are not adequately represented as 
strings. Moreover, users often represent polyphonic 
pieces in their queries by skipping from one part (the 
soprano) to another (the bass). Current string 
matching approaches are not designed to handle this 
situation. This paper outlines approaches to extending 
string alignment that allow measuring similarity 
between a monophonic query and a polyphonic piece. 
These approaches are compared using synthetic 
queries on a database of Bach pieces. Results indicate 
that when a monophonic query is drawn from multiple 
parts in the target, a method which explicitly takes the 
multi-part 
structure 
of 
a 
piece 
into 
account 
significantly outperforms the one that does not."
30,Ning Hu;Roger B. Dannenberg,A Bootstrap Method for Training an Accurate Audio Segmenter.,2005,https://doi.org/10.5281/zenodo.1416200,"Ning Hu, Carnegie Mellon University, USA, education;Roger B. Dannenberg, Carnegie Mellon University, USA, education","Supervised learning can be used to create good systems for note segmentation in audio data. However, this requires a large set of labeled training examples, and hand-labeling is quite difficult and time consuming. A bootstrap approach is introduced in which audio alignment techniques are first used to find the correspondence between a symbolic music representation (such as MIDI data) and an acoustic recording. This alignment provides an initial estimate of note boundaries which can be used to train a segmenter. Once trained, the segmenter can be used to refine the initial set of note boundaries and training can be repeated. This iterative training process eliminates the need for hand-segmented audio. Tests show that this training method can improve a segmenter initially trained on synthetic data."
31,Pierre Roy;Jean-Julien Aucouturier;François Pachet;Anthony Beurivé,Exploiting the Tradeoff Between Precision and Cpu-Time to Speed Up Nearest Neighbor Search.,2005,https://doi.org/10.5281/zenodo.1417453,"Pierre Roy, SONY Computer Science Laboratory Paris, FRA, facility;Jean-Julien Aucouturier, SONY Computer Science Laboratory Paris, FRA, facility;Franc¸ois Pachet, SONY Computer Science Laboratory Paris, FRA, facility;Anthony Beuriv´e, SONY Computer Science Laboratory Paris, FRA, facility","""We describe an incremental ﬁltering algorithm to quickly compute the N nearest neighbors according to a similarity measure in a metric space. The algorithm exploits an intrinsic property of a large class of similarity measures for which some parameter p has a positive inﬂuence both on the precision and the cpu cost (precision-cputime trade-off). The algorithm uses successive approximations of the measure to compute ﬁrst cheap distances on the whole set of possible items, then more and more expensive measures on smaller and smaller sets. We illustrate the algorithm on the case of a timbre similarity algorithm, which compares gaussian mixture models using a Monte Carlo approximation of the Kullback-Leibler distance, where p is the number of points drawn from the distributions. We describe several Monte Carlo algorithmic variants, which improve the convergence speed of the approximation. On this problem, the algorithm performs more than 30 times faster than the naive approach."""
32,Nancy Bertin;Alain de Cheveigné,Scalable Metadata and Quick Retrieval of Audio Signals.,2005,https://doi.org/10.5281/zenodo.1417079,"Nancy Bertin, CNRS UMR 8581 - ENS (DEC), FRA, facility;Alain de Cheveigné, CNRS UMR 8581 - ENS (DEC), FRA, facility","Audio search algorithms have reached a degree of speed and accuracy that allows them to search efﬁciently within large databases of audio. For speed, algorithms generally depend on precalculated indexing metadata. Unfortunately, the size of the metadata follows the same exponential trend as the audio data itself, and this may lead to an exponential increase in storage cost and search time. The concept of scalable metadata has been introduced to allow metadata to adjust to such trends and alleviate the effects of forseeable increases of data and metadata size. Here, we argue that scalability ﬁts the needs of the hierarchical structures that allow fast search, and illustrate this by adapting a state-of-the-art search algorithm to a scalable indexing structure. Scalability allows search algorithms to adapt to the increase of database size without loss of performance."
33,Charles L. Parker,Applications of Binary Classification and Adaptive Boosting to the Query-By-Humming Problem.,2005,https://doi.org/10.5281/zenodo.1416482,"Charles Parker, Oregon State University, USA, education","""In the “query-by-humming” problem, we attempt to retrieve a specific song from a target set based on a sung query. Recent evaluations of query-by-humming systems show that the state-of-the-art algorithm is a simple dynamic programming-based interval matching technique. Other techniques based on hidden Markov models are far more expensive computationally and do not appear to offer significant increases in performance. Here, we borrow techniques from artificial intelligence to create an algorithm able to outperform the current state-of-the-art with only a negligible increase in running time."""
34,Ming Li;Ronan Sleep,Genre Classification via an LZ78-Based String Kernel.,2005,https://doi.org/10.5281/zenodo.1415162,"Ming Li, University of East Anglia, GBR, education;Ronan Sleep, University of East Anglia, GBR, education","""We develop the notion of normalized information distance (NID) [7] into a kernel distance suitable for use with a Support Vector Machine classifier, and demonstrate its use for an audio genre classification task. Our classification scheme involves a relatively small number of low-level audio features, is efficient to compute, yet generates an accuracy which compares well with recent works."""
35,Arthur Flexer;Elias Pampalk;Gerhard Widmer,Novelty Detection Based on Spectral Similarity of Songs.,2005,https://doi.org/10.5281/zenodo.1416504,"Arthur Flexer, Institute of Medical Cybernetics and Artificial Intelligence, Center for Brain Research, Medical University of Vienna, AUT, education;Elias Pampalk, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility;Gerhard Widmer, Department of Computational Perception, Johannes Kepler University, AUT, education","We are introducing novelty detection, i.e. the automatic identification of new or unknown data not covered by the training data, to the field of music information retrieval. Two methods for novelty detection - one based solely on the similarity information and one also utilizing genre label information - are evaluated within the context of genre classification based on spectral similarity. Both are shown to perform equally well."
36,Richard Stenzel;Thomas Kamps,Improving Content-Based Similarity Measures by Training a Collaborative Model.,2005,https://doi.org/10.5281/zenodo.1416090,"Richard Stenzel, Fraunhofer IPSI, DEU, facility;Thomas Kamps, Fraunhofer IPSI, DEU, facility","We observed that for multimedia data – especially music - collaborative similarity measures perform much better than similarity measures derived from content-based sound features. Our observation is based on a large scale evaluation with >250,000,000 collaborative data points crawled from the web and >190,000 songs annotated with content-based sound feature sets. A song mentioned in a playlist is regarded as one collaborative data point. In this paper we present a novel approach to bridging the performance gap between collaborative and content-based similarity measures. In the initial training phase a model vector for each song is computed, based on collaborative data. Each vector consists of 200 overlapping unlabelled 'genres' or song clusters. Instead of using explicit numerical voting, we use implicit user profile data as collaborative data source, which is, for example, available as purchase histories in many large scale e-commerce applications. After the training phase, we used support vector machines based on content-based sound features to predict the collaborative model vectors. These predicted model vectors are finally used to compute the similarity between songs. We show that combining collaborative and content-based similarity measures can help to overcome the new item problem in e-commerce applications that offer a collaborative similarity recommender as service to their customers."
37,Fabio Vignoli;Steffen Pauws,A Music Retrieval System Based on User Driven Similarity and Its Evaluation.,2005,https://doi.org/10.5281/zenodo.1418359,"Fabio Vignoli, Philips Research Laboratories, NLD, facility;Steffen Pauws, Philips Research Laboratories, NLD, facility","Large music collections require new ways to let users interact with their music. The concept of finding ‘similar’ songs, albums, or artists provides handles to users for easy navigation and instant retrieval. This paper presents the realization and user evaluation of a music retrieval music that sorts songs on the basis of similarity to a given seed song. Similarity is based on a user-weighted combination of timbre, genre, tempo, year, and mood. A conclusive user evaluation assessed the usability of the system in comparison to two control systems in which the user control of defining the similarity measure was diminished."
38,David Meredith 0001;Geraint A. Wiggins,Comparing Pitch Spelling Algorithms.,2005,https://doi.org/10.5281/zenodo.1416366,"David Meredith, Goldsmiths’ College, University of London, GBR, education;Geraint A. Wiggins, Goldsmiths’ College, University of London, GBR, education","A pitch spelling algorithm predicts the pitch names of the notes in a musical passage when given the onset-time, MIDI note number and possibly the duration and voice of each note. Various versions of the algorithms of Longuet-Higgins, Cambouropoulos, Temperley and Sleator, Chew and Chen, and Meredith were run on a corpus containing 195972 notes, equally divided between eight classical and baroque composers. The standard deviation of the accuracies achieved by each algorithm over the eight composers was used as a measure of its style dependence (SD). Meredith’s ps1303 was the most accurate algorithm, spelling 99.43% of the notes correctly (SD = 0.54). The best version of Chew and Chen’s algorithm was the least dependent on style (SD = 0.35) and spelt 99.15% of the notes correctly. A new version of Cambouropoulos’s algorithm, combining features of all three versions described by Cambouropoulos himself, also spelt 99.15% of the notes correctly (SD = 0.47). The best version of Temperley and Sleator’s algorithm spelt 97.79% of the notes correctly, but nearly 70% of its errors were due to a single sudden enharmonic change. Longuet-Higgins’s algorithm spelt 98.21% of the notes correctly (SD = 1.79) but only when it processed the music a voice at a time."
39,Meinard Müller;Frank Kurth;Michael Clausen,Audio Matching via Chroma-Based Statistical Features.,2005,https://doi.org/10.5281/zenodo.1416800,"Meinard M¨uller, Universität Bonn, Institut für Informatik III, DEU, education;Frank Kurth, Universität Bonn, Institut für Informatik III, DEU, education;Michael Clausen, Universität Bonn, Institut für Informatik III, DEU, education","In this paper, we describe an efﬁcient method for audio matching which performs effectively for a wide range of classical music. The basic goal of audio matching can be described as follows: consider an audio database con- taining several CD recordings for one and the same piece of music interpreted by various musicians. Then, given a short query audio clip of one interpretation, the goal is to automatically retrieve the corresponding excerpts from the other interpretations. To solve this problem, we in- troduce a new type of chroma-based audio feature that strongly correlates to the harmonic progression of the au- dio signal. Our feature shows a high degree of robustness to variations in parameters such as dynamics, timbre, ar- ticulation, and local tempo deviations. As another contri- bution, we describe a robust matching procedure, which allows to handle global tempo variations. Finally, we give a detailed account on our experiments, which have been carried out on a database of more than 110 hours of audio comprising a wide range of classical music."
40,Ching-Hua Chuan;Elaine Chew,Fuzzy Analysis in Pitch-Class Determination for Polyphonic Audio Key Finding.,2005,https://doi.org/10.5281/zenodo.1417297,"Ching-Hua Chuan, University of Southern California, USA, education;Elaine Chew, University of Southern California, USA, education","""This paper presents a fuzzy analysis technique for pitch class determination that improves the accuracy of key finding from audio information. Errors in audio key finding, typically incorrect assignments of closely related keys, commonly result from imprecise pitch class determination and biases introduced by the quality of the sound. Our technique is motivated by hypotheses on the sources of audio key finding errors, and uses fuzzy analysis to reduce the errors caused by noisy detection of lower pitches, and to refine the biased raw frequency data, in order to extract more correct pitch classes. We compare the proposed system to two others, an earlier one employing only peak detection from FFT results, and another providing direct key finding from MIDI. All three used the same key finding algorithm (Chew’s Spiral Array CEG algorithm) and the same 410 classical music pieces (ranging from Baroque to Contemporary). Considering only the first 15 seconds of music in each piece, the proposed fuzzy analysis technique outperforms the peak detection method by 12.18% on average, matches the performance of direct key finding from MIDI 41.73% of the time, and achieves an overall maximum correct rate of 75.25% (compared to 80.34% for MIDI key finding)."""
41,Juan Pablo Bello;Jeremy Pickens,A Robust Mid-Level Representation for Harmonic Content in Music Signals.,2005,https://doi.org/10.5281/zenodo.1417431,"Juan P. Bello, Queen Mary, University of London, GBR, education;Jeremy Pickens, Queen Mary, University of London, GBR, education","When considering the problem of audio-to-audio matching, determining musical similarity using low-level features such as Fourier transforms and MFCCs is an extremely difficult task, as there is little semantic information available. Full semantic transcription of audio is an unreliable and imperfect task in the best case, an unsolved problem in the worst. To this end we propose a robust mid-level representation that incorporates both harmonic and rhythmic information, without attempting full transcription. We describe a process for creating this representation automatically, directly from multi-timbral and polyphonic music signals, with an emphasis on popular music. We also offer various evaluations of our techniques. Moreso than most approaches working from raw audio, we incorporate musical knowledge into our assumptions, our models, and our processes. Our hope is that by utilizing this notion of a musically-motivated mid-level representation we may help bridge the gap between symbolic and audio research."
42,Jean-François Paiement;Douglas Eck;Samy Bengio,A Probabilistic Model for Chord Progressions.,2005,https://doi.org/10.5281/zenodo.1416922,"Jean-Franc¸ois Paiement, IDIAP Research Institute, CHE, facility;Douglas Eck, University of Montreal, CAN, education;Samy Bengio, IDIAP Research Institute, CHE, facility","Chord progressions are the building blocks from which tonal music is constructed. Inferring chord progressions is thus an essential step towards modeling long term dependencies in music. In this paper, a distributed representation for chords is designed such that Euclidean distances roughly correspond to psychoacoustic dissimilarities. Estimated probabilities of chord substitutions are derived from this representation and are used to introduce smoothing in graphical models observing chord progressions. Parameters in the graphical models are learnt with the EM algorithm and the classical Junction Tree algorithm is used for inference. Various model architectures are compared in terms of conditional out-of-sample likelihood. Both perceptual and statistical evidence show that binary trees related to meter are well suited to capture chord dependencies."
43,J. Stephen Downie;Kris West;Andreas F. Ehmann;Emmanuel Vincent,The 2005 Music Information retrieval Evaluation Exchange (MIREX 2005): Preliminary Overview.,2005,https://doi.org/10.5281/zenodo.1416044,"J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;Kris West, University of East Anglia, GBR, education;Andreas Ehmann, University of Illinois at Urbana-Champaign, USA, education;Emmanuel Vincent, Queen Mary University of London, GBR, education","""This paper is an extended abstract which provides a brief 
preliminary overview of the 2005 Music Information 
Retrieval Evaluation eXchange (MIREX 2005). The 
MIREX organizational framework and infrastructure are 
outlined. Summary data concerning the 10 evaluation 
contests is provided. Key issues affecting future MIR 
evaluations are identified and discussed. The paper con-
cludes with a listing of targets items to be undertaken 
before MIREX 2006 to ensure the ongoing success of 
the MIREX framework."""
44,Slim Essid;Gaël Richard;Bertrand David,Inferring Efficient Hierarchical Taxonomies for MIR Tasks: Application to Musical Instruments.,2005,https://doi.org/10.5281/zenodo.1416268,"Slim ESSID, GET-Télécom Paris, CNRS LTCI, FRA, education;Gaël RICHARD, GET-Télécom Paris, CNRS LTCI, FRA, education;Bertrand DAVID, GET-Télécom Paris, CNRS LTCI, FRA, education","A number of approaches for automatic audio classiﬁcation are based on hierarchical taxonomies since it is acknowledged that improved performance can be thereby obtained. In this paper, we propose a new strategy to automatically acquire hierarchical taxonomies, using machine learning methods, which are expected to maximize the performance of subsequent classiﬁcation. It is shown that the optimal hierarchical taxonomy of musical instruments (in the sense of inter-class distances) does not follow the traditional and more intuitive instrument classiﬁcation into instrument families."
45,Hiromasa Fujihara;Tetsuro Kitahara;Masataka Goto;Kazunori Komatani;Tetsuya Ogata;Hiroshi G. Okuno,Singer Identification Based on Accompaniment Sound Reduction and Reliable Frame Selection.,2005,https://doi.org/10.5281/zenodo.1418285,"Hiromasa Fujihara, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuro Kitahara, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Kazunori Komatani, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuya Ogata, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Hiroshi G. Okuno, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education","This paper describes a method for automatic singer identification from polyphonic musical audio signals including sounds of various instruments. Because singing voices play an important role in musical pieces with a vocal part, the identification of singer names is useful for music information retrieval systems. The main problem in automatically identifying singers is the negative influences caused by accompaniment sounds. To solve this problem, we developed two methods, accompaniment sound reduction and reliable frame selection. The former method makes it possible to identify the singer of a singing voice after reducing accompaniment sounds. It first extracts harmonic components of the predominant melody from sound mixtures and then resynthesizes the melody by using a sinusoidal model driven by those components. The latter method then judges whether each frame of the obtained melody is reliable (i.e. little influenced by accompaniment sound) or not by using two Gaussian mixture models for vocal and non-vocal frames. It enables the singer identification using only reliable vocal portions of musical pieces. Experimental results with forty popular-music songs by ten singers showed that our method was able to reduce the influences of accompaniment sounds and achieved an accuracy of 95%, while the accuracy for a conventional method was 53%."
46,Shankar Vembu;Stephan Baumann 0001,Separation of Vocals from Polyphonic Audio Recordings .,2005,https://doi.org/10.5281/zenodo.1414852,"Shankar Vembu, German Research Centre for AI, DEU, facility;Stephan Baumann, German Research Centre for AI, DEU, facility","Source separation techniques like independent component analysis and the more recent non-negative matrix factorization are gaining widespread use for the monaural separation of individual tracks present in a music sample. The underlying principle behind these approaches characterises only stationary signals and fails to separate non-stationary sources like speech or vocals. In this paper, we make an attempt to solve this problem and propose solutions to the extraction of vocal tracks from polyphonic audio recordings. We also present techniques to identify vocal sections in a music sample and design a classifier to perform a vocal–nonvocal segmentation task. Finally, we describe an application wherein we try to extract the melody from the separated vocal track using existing monophonic transcription techniques. The experimental work leads us to the conclusion that the quality of vocal source separation, albeit satisfactory, is not sufficient enough for further F0 analysis to extract the melody line from the vocal track. We identify areas that need further investigation to improve the quality of vocal source separation."
47,Norman Casagrande;Douglas Eck;Balázs Kégl,Frame-Level Audio Feature Extraction Using AdaBoost.,2005,https://doi.org/10.5281/zenodo.1414718,"Norman Casagrande, University of Montreal, CAN, education;Douglas Eck, University of Montreal, CAN, education;Balázs Kégl, University of Montreal, CAN, education","""In this paper we adapt an AdaBoost-based image processing algorithm to the task of predicting whether an audio signal contains speech or music. We derive a frame-level discriminator that is both fast and accurate. Using a simple FFT and no built-in prior knowledge of signal structure we obtain an accuracy of 88% on frames sampled at 20ms intervals. When we smooth the output of the classifier with the output of the previous 40 frames our forecast rate rises to 93% on the Scheirer-Slaney (Scheirer and Slaney, 1997) database. To demonstrate the efficiency and effectiveness of the model, we have implemented it as a graphical real-time plugin to the popular Winamp audio player."""
48,Petri Toiviainen;Tuomas Eerola,Classification of Musical Metre with Autocorrelation and Discriminant Functions.,2005,https://doi.org/10.5281/zenodo.1416040,"Petri Toiviainen, University of Jyväskylä, FIN, education;Tuomas Eerola, University of Jyväskylä, FIN, education","The performance of autocorrelation-based metre induction was tested with two large collections of folk melodies, consisting of approximately 13,000 melodies in MIDI file format, for which the correct metres were available. The analysis included a number of melodic accents assumed to contribute to metric structure. The performance was measured by the proportion of melodies whose metre was correctly classified by Multiple Discriminant Analysis. Overall, the method predicted notated metre with an accuracy of 75 % for classification into nine categories of metre. The most frequent confusions were made within the groups of duple and triple/compound metres, whereas confusions across these groups where significantly less frequent. In addition to note onset locations and note durations, Thomassen's melodic accent was found to be an important predictor of notated metre."
49,Masatoshi Hamanaka;Keiji Hirata;Satoshi Tojo,ATTA: Automatic Time-Span Tree Analyzer Based on Extended GTTM.,2005,https://doi.org/10.5281/zenodo.1415572,"Masatoshi Hamanaka, Japan Science and Technology Agency, JPN, facility, A.I.S.T., JPN, facility;Keiji Hirata, NTT Communication Science Laboratories, JPN, company;Satoshi Tojo, Japan Advanced Institute of Science and Technology, JPN, education","""This paper describes a music analyzing system called the automatic time-span tree analyzer (ATTA), which we have developed. The ATTA derives a time-span tree that assigns a hierarchy of 'structural importance' to the notes of a piece of music based on the generative theory of tonal music (GTTM). Although the time-span tree has been applied with music summarization and collaborative music creation systems, these systems use time-span trees manually analyzed by experts in musicology. Previous systems based on GTTM cannot acquire a time-span tree without manual application of most of the rules, because GTTM does not resolve much of the ambiguity that exists with the application of the rules. To solve this problem, we propose a novel computational model of the GTTM that re-formalizes the rules with computer implementation. The main advantage of our approach is that we can introduce adjustable parameters, which enables us to assign priority to the rules. Our analyzer automatically acquires time-span trees by configuring the parameters that cover 26 rules out of 36 GTTM rules for constructing a time-span tree. Experimental results showed that after these parameters were tuned, our method outperformed a baseline performance. We hope to distribute the time-span tree as the content for various musical tasks, such as searching and arranging music."""
50,Roger B. Dannenberg,"Toward Automated Holistic Beat Tracking, Music Analysis and Understanding.",2005,https://doi.org/10.5281/zenodo.1415246,"Roger B. Dannenberg, Carnegie Mellon University, USA, education","Most music processing attempts to focus on one particular feature or structural element such as pitch, beat location, tempo, or genre. This hierarchical approach, in which music is separated into elements that are analyzed independently, is convenient for the scientific researcher, but is at odds with intuition about music perception. Music is interconnected at many levels, and the interplay of melody, harmony, and rhythm are important in perception. As a first step toward more holistic music analysis, music structure is used to constrain a beat tracking program. With structural information, the simple beat tracker, working with audio input, shows a large improvement. The implications of this work for other music analysis problems are discussed."
51,Kristoffer Jensen;Jieping Xu;Martin Zachariasen,Rhythm-Based Segmentation of Popular Chinese Music.,2005,https://doi.org/10.5281/zenodo.1418117,"Kristoffer Jensen, University of Aalborg Esbjerg, DNK, education;Jieping Xu, Renmin University, CHN, education;Martin Zachariasen, University of Copenhagen, DNK, education","""We present a new method to segment popular music based on rhythm. By computing a shortest path based on the self-similarity matrix calculated from a model of rhythm, segmenting boundaries are found along the diagonal of the matrix. The cost of a new segment is optimized by matching manual and automatic segment boundaries. We compile a small song database of 21 randomly selected popular Chinese songs which come from Chinese Mainland, Taiwan and Hong Kong. The segmenting results on the small corpus show that 78% manual segmentation points are detected and 74% automatic segmentation points are correct. Automatic segmentation achieved 100% correct detection for 5 songs. The results are very encouraging."""
52,Frank Kurth;Meinard Müller;David Damm;Christian Fremerey;Andreas Ribbrock;Michael Clausen,Syncplayer - An Advanced System for Multimodal Music Access.,2005,https://doi.org/10.5281/zenodo.1416496,"Frank Kurth, Universität Bonn, DEU, education;Meinard Müller, Universität Bonn, DEU, education;David Damm, Universität Bonn, DEU, education;Christian Fremerey, Universität Bonn, DEU, education;Andreas Ribbrock, Universität Bonn, DEU, education;Michael Clausen, Universität Bonn, DEU, education","""In this paper, we present the SyncPlayer system for multimodal presentation of high quality audio and associated music-related data. Using the SyncPlayer client interface, a user may play back an audio recording that is locally available on his computer. The recording is then identiﬁed by the SyncPlayer server, a process which is performed entirely content-based. Subsequently, the server delivers music-related data like scores or lyrics to the client, which are then displayed synchronously with audio playback using a multimodal visualization plug-in. In addition to visualization, the system provides functionality for content-based music retrieval and semi-manual content annotation. To the best of our knowledge, our system is moreover the ﬁrst to systematically exploit automatically generated synchronization data for content-based symbolic browsing in high quality audio recordings. SyncPlayer has already proved to be a valuable tool for evaluating algorithms in MIR research on a larger scale. In this paper, we describe the technical background of the SyncPlayer framework in detail. We also give an overview of the underlying MIR techniques of audio matching, music synchronization, and text-based retrieval that are incorporated in the current version of the system."""
53,Eric J. Isaacson,What You See Is What You Get: on Visualizing Music.,2005,https://doi.org/10.5281/zenodo.1415992,"Eric Isaacson, Indiana University School of Music, USA, education","Though music is fundamentally an aural phenomenon, we often communicate about music through visual means. The paper examines a number of visualization techniques developed for music, focusing especially on those developed for music analysis by specialists in the field, but also looking at some less successful approaches. It is hoped that, by presenting them in this way, those in the MIR community will develop a greater awareness of the kinds of musical problems music scholars are concerned with, and might lend a hand toward addressing them"
54,Fabian Mörchen;Alfred Ultsch;Mario Nöcker;Christian Stamm,Databionic Visualization of Music Collections According to Perceptual Distance.,2005,https://doi.org/10.5281/zenodo.1417967,"Fabian Mörchen, Philipps-University Marburg, DEU, education;Alfred Ultsch, Philipps-University Marburg, DEU, education;Mario Nöcker, Philipps-University Marburg, DEU, education;Christian Stamm, Philipps-University Marburg, DEU, education","We describe the MusicMiner system for organizing large collections of music with databionic mining techniques. Low level audio features are extracted from the raw audio data on short time windows during which the sound is assumed to be stationary. Static and temporal statistics were consistently and systematically used for aggregation of low level features to form high level features. A supervised feature selection targeted to model perceptual distance between different sounding music lead to a small set of non-redundant sound features. Clustering and visualization based on these feature vectors can discover emergent structures in collections of music. Visualization based on Emergent Self-Organizing Maps in particular enables the unsupervised discovery of timbrally consistent clusters that may or may not correspond to musical genres and artists. We demonstrate the visualizations capabilities of the U-Map, displaying local sound differences based on the new audio features. An intuitive browsing of large music collections is offered based on the paradigm of topographic maps. The user can navigate the sound space and interact with the maps to play music or show the context of a song."
55,Masataka Goto;Takayuki Goto,"Musicream: New Music Playback Interface for Streaming, Sticking, Sorting, and Recalling Musical Pieces.",2005,https://doi.org/10.5281/zenodo.1415842,"Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Takayuki Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility","This paper describes a novel music playback interface, called Musicream, which lets a user unexpectedly come across various musical pieces similar to those liked by the user. With most previous “query-by-example” interfaces used for similarity-based searching, for the same query and music collection a user will always receive the same list of musical pieces ranked by their similarity and opportunities to encounter unfamiliar musical pieces in the collection are limited. Musicream facilitates active, ﬂexible, and unexpected encounters with musical pieces by providing four functions: the music-disc streaming function which creates a ﬂow of many musical-piece entities (discs) from a (huge) music collection, the similarity-based sticking function which allows a user to easily pick out and listen to similar pieces from the ﬂow, the meta-playlist function which can generate a playlist of playlists (ordered lists of pieces) while editing them with a high degree of freedom, and the time-machine function which automatically records all Musicream activities and allows a user to visit and retrieve a past state as if using a time machine. In our experiments, these functions were used seamlessly to achieve active and creative querying and browsing of music collections, conﬁrming the effectiveness of Musicream."
56,Jean-Julien Aucouturier;François Pachet,Ringomatic: A Real-Time Interactive Drummer Using Constraint-Satisfaction and Drum Sound Descriptors.,2005,https://doi.org/10.5281/zenodo.1416532,"Jean-Julien Aucouturier, SONY CSL Paris, FRA, company;Franc¸ois Pachet, SONY CSL Paris, FRA, company","""We describe a real-time musical agent that generates an audio drum-track by concatenating audio segments automatically extracted from pre-existing musical ﬁles. The drum-track can be controlled in real-time by specifying high-level properties (or constraints) holding on metadata automatically extracted from the audio segments. A constraint-satisfaction mechanism, based on local search, selects audio segments that best match those constraints at any time. We report on several drum track audio descriptors designed for the system. We also describe a basic mecanism for controlling the tradeoff between the agent’s autonomy and reactivity, which we illustrate with experiments made in the context of a virtual duet between the system and a human pianist."""
57,Samer A. Abdallah;Katy C. Noland;Mark B. Sandler;Michael A. Casey;Christophe Rhodes,Theory and Evaluation of a Bayesian Music Structure Extractor.,2005,https://doi.org/10.5281/zenodo.1416018,"Samer Abdallah, Queen Mary, University of London, GBR, education;Katy Noland, Queen Mary, University of London, GBR, education;Mark Sandler, Queen Mary, University of London, GBR, education;Michael Casey, Goldsmiths College, University of London, GBR, education;Christophe Rhodes, Goldsmiths College, University of London, GBR, education","""We introduce a new model for extracting classiﬁed struc-
tural segments, such as intro, verse, chorus, break and so
forth, from recorded music. Our approach is to classify
signal frames on the basis of their audio properties and
then to agglomerate contiguous runs of similarly classi-
ﬁed frames into texturally homogenous (or ‘self-similar’)
segments which inherit the classiﬁcaton of their con-
situent frames. Our work extends previous work on au-
tomatic structure extraction by addressing the classiﬁca-
tion problem using using an unsupervised Bayesian clus-
tering model, the parameters of which are estimated using
a variant of the expectation maximisation (EM) algorithm
which includes deterministic annealing to help avoid lo-
cal optima. The model identiﬁes and classiﬁes all the seg-
ments in a song, not just the chorus or longest segment.
We discuss the theory, implementation, and evaluation of
the model, and test its performance against a ground truth
of human judgements. Using an analogue of a precision-
recall graph for segment boundaries, our results indicate
an optimal trade-off point at approximately 80% precision
for 80% recall."""
58,Xavier Amatriain;Jordi Massaguer;David García;Ismael Mosquera,The CLAM Annotator: A Cross-Platform Audio Descriptors Editing Tool.,2005,https://doi.org/10.5281/zenodo.1416908,"Xavier Amatriain, CREATE, University of California, USA, education;Jordi Massaguer, Universitat Pompeu Fabra, ESP, education;David Garcia, Universitat Pompeu Fabra, ESP, education;Ismael Mosquera, Universitat Pompeu Fabra, ESP, education","""This paper presents the CLAM Annotator tool. This ap-
plication has been developed in the context of the CLAM
framework and can be used to manually edit any previ-
ously computed audio descriptors. The application offers
a convenient GUI that allows to edit low-level frame de-
scriptors, global descriptors of any kind and segmentation
marks.
It is designed in such a way that the interface
adapts itself to a user-deﬁned schema, offering possibil-
ities to a large range of applications."""
59,Tim Bell;David Blizzard;Richard D. Green;David Bainbridge 0001,Design of a Digital Music Stand.,2005,https://doi.org/10.5281/zenodo.1416290,,
60,Stuart Bray;George Tzanetakis,Distributed Audio Feature Extraction for Music.,2005,https://doi.org/10.5281/zenodo.1417563,"Stuart Bray, University of Victoria, CAN, education;George Tzanetakis, University of Victoria, CAN, education","One of the important challenges facing music information retrieval (MIR) of audio signals is scaling analysis algorithms to large collections. Typically, analysis of audio signals utilizes sophisticated signal processing and machine learning techniques that require significant computational resources. Therefore, audio MIR is an area were computational resources are a significant bottleneck. For example, the number of pieces utilized in the majority of existing work in audio MIR is at most a few thousand files. Computing audio features over thousands files can sometimes take days of processing. In this paper, we describe how Marsyas-0.2, a free software framework for audio analysis and synthesis can be used to rapidly implement efficient distributed audio analysis algorithms. The framework is based on a dataflow architecture which facilitates partitioning of audio computations over multiple computers. Experimental results demonstrating the effectiveness of the proposed approach are presented."
61,John Ashley Burgoyne;Lawrence K. Saul,Learning Harmonic Relationships in Digital Audio with Dirichlet-Based Hidden Markov Models.,2005,https://doi.org/10.5281/zenodo.1414870,"J. Ashley Burgoyne, University of Pennsylvania, USA, education;Lawrence K. Saul, University of Pennsylvania, USA, education","Harmonic analysis is a standard musicological tool for understanding many pieces of Western classical music and making comparisons among them. Traditionally, this analysis is done on paper scores, and most past research in machine-assisted analysis has begun with digital representations of them. Human music students are also taught to hear their musical analyses, however, in both musical recordings and performances. Our approach attempts to teach machines to do the same, beginning with a corpus of recorded Mozart symphonies. The audio files are first transformed into an ordered series of normalized pitch class profile (PCP) vectors. Simplified rules of tonal harmony are encoded in a transition matrix. Classical music tends to change key more frequently than popular music, and so these rules account not only for chords, as most previous work has done, but also for the keys in which they function. A hidden Markov model (HMM) is used with this transition matrix to train Dirichlet distributions for major and minor keys on the PCP vectors. The system tracks chords and keys successfully and shows promise for a real-time implementation."
62,Giordano Ribeiro de Eulalio Cabral;François Pachet;Jean-Pierre Briot,Automatic X Traditional Descriptor Extraction: the Case of Chord Recognition.,2005,https://doi.org/10.5281/zenodo.1415702,"Giordano Cabral, LIP6 – Paris 6, FRA, education;François Pachet, Sony CSL Paris, FRA, company;Jean-Pierre Briot, LIP6 – Paris 6, FRA, education","Audio descriptor extraction is the activity of finding 
mathematical models which describe properties of the 
sound, requiring signal processing skills. The scientific 
literature presents a vast collection of descriptors (e.g. 
energy, tempo, tonality) each one representing a signifi-
cant effort of research in finding an appropriate descrip-
tor for a particular application. The Extractor Discovery 
System (EDS)  [1] is a recent approach for the discovery 
of such descriptors, which aim is to extract them auto-
matically. This system can be useful for both non experts 
– who can let the system work fully automatically – and 
experts – who can start the system with an initial solution 
expecting it to enhance their results. Nevertheless, EDS 
still needs to be massively tested. We consider that its 
comparison with the results of problems already studied 
would be very useful to validate it as an effective tool. 
This work intends to perform the first part of this valida-
tion, comparing the results from classic approaches with 
EDS results when operated by a completely naïve user 
building a guitar chord recognizer."
63,Margaret Cahill;Donncha Ó Maidín,Melodic Similarity Algorithms -- Using Similarity Ratings for Development and Early Evaluation.,2005,https://doi.org/10.5281/zenodo.1415642,"Margaret Cahill, University of Limerick, IRL, education;Donncha Ó Maidín, University of Limerick, IRL, education","""This paper focuses on gathering similarity ratings for use in the construction, optimization and evaluation of melodic similarity algorithms. The approach involves conducting listening experiments to gather these ratings for a piece in Theme and Variation form."""
64,Domenico Cantone;Salvatore Cristofaro;Simone Faro,"On Tuning the (\delta, \alpha)-Sequential-Sampling Algorithm for \delta-Approximate Matching with Alpha-Bounded Gaps in Musical Sequences.",2005,https://doi.org/10.5281/zenodo.1417791,"Domenico Cantone, Università di Catania, Dipartimento di Matematica e Informatica, ITA, education;Salvatore Cristofaro, Università di Catania, Dipartimento di Matematica e Informatica, ITA, education;Simone Faro, Università di Catania, Dipartimento di Matematica e Informatica, ITA, education","We present a very efﬁcient variant of the (δ, α)-
SEQUENTIAL-SAMPLING algorithm, recently introduced
by the authors, for the δ-approximate string matching
problem with α-bounded gaps, which often arises in many
questions on musical information retrieval and musical
analysis.
Though it retains the same worst-case O(mn)-time
and O(mα)-space complexity of its progenitor to com-
pute the number of distinct δ-approximate α-gapped oc-
currences of a pattern of length m at each position in a text
of length n, our new variant achieves an average O(n)-
time complexity in practical cases.
Extensive experimentations indicate that our algo-
rithm is more efﬁcient than existing solutions for the same
problem, especially in the case of long patterns."
65,Domenico Cantone;Salvatore Cristofaro;Simone Faro,"Solving the (\delta, \alpha)-Approximate Matching Problem Under Transposition Invariance in Musical Sequences.",2005,https://doi.org/10.5281/zenodo.1416892,"Domenico Cantone, Università di Catania, Dipartimento di Matematica e Informatica, ITA, education;Salvatore Cristofaro, Università di Catania, Dipartimento di Matematica e Informatica, ITA, education;Simone Faro, Università di Catania, Dipartimento di Matematica e Informatica, ITA, education","The δ-approximate matching problem arises in many questions concerning musical information retrieval and musical analysis. In the case in which gaps are not allowed between consecutive pitches of the melody, transposition invariance is automatically taken care of, provided that the musical melodies are encoded using the pitch interval encoding. However, in the case in which nonnull gaps are allowed between consecutive pitches of the melodies, transposition invariance is not dealt with properly by the algorithms present in literature. In this paper, we propose two slightly different variants of the approximate matching problem under transposition invariance and for each of them provide an algorithm, obtained by adapting an efﬁcient algorithm for the δ-approximate matching problem with α-bounded gaps."
66,Òscar Celma;Miquel Ramírez;Perfecto Herrera,Foafing the Music: A Music Recommendation System based on RSS Feeds and User Preferences.,2005,https://doi.org/10.5281/zenodo.1414800,"Oscar Celma, Universitat Pompeu Fabra, ESP, education;Miquel Ramírez, Universitat Pompeu Fabra, ESP, education;Perfecto Herrera, Universitat Pompeu Fabra, ESP, education","In this paper we give an overview of the Foaﬁng the Music system. The system uses the Friend of a Friend (FOAF) and Rich Site Summary (RSS) vocabularies for recommending music to a user, depending on her musical tastes. Music information (new album releases, related artists’ news and available audio) is gathered from thousands of RSS feeds —an XML format for syndicating Web content. On the other hand, FOAF documents are used to define user preferences. The presented system provides music discovery by means of: user profiling —defined in the user’s FOAF description—, context-based information —extracted from music related RSS feeds— and content-based descriptions —extracted from the audio itself."
67,Wei Chai;Barry Vercoe,Detection of Key Change in Classical Piano Music.,2005,https://doi.org/10.5281/zenodo.1415538,"Wei Chai, MIT Media Laboratory, USA, education;Barry Vercoe, MIT Media Laboratory, USA, education","Tonality is an important aspect of musical structure. Detecting key of music is one of the major tasks in tonal analysis and will benefit semantic segmentation of music for indexing and searching. This paper presents an HMM-based approach for segmenting musical signals based on key change and identifying the key of each segment. Classical piano music was used in the experiment. The performance, evaluated by three proposed measures (recall, precision and label accuracy), demonstrates the promise of the method."
68,Sally Jo Cunningham;J. Stephen Downie;David Bainbridge 0001,"""The Pain, the Pain"": Modelling Music Information Behavior and the Songs We Hate.",2005,https://doi.org/10.5281/zenodo.1417209,"Sally Jo Cunningham, University of Waikato, NZL, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;David Bainbridge, University of Waikato, NZL, education","The paper presents a grounded theory analysis of 395 
user responses to the survey question, “What is the 
worst song ever?”  Important factors uncovered include: 
lyric quality, the “earworm” effect, voice quality, the 
influence of associated music videos, over-exposure, 
perceptions of pretentiousness, and associations with 
unpleasant personal experiences."
69,Christophe Dalitz;Thomas Karsten,Using the Gamera Framework for Building a Lute Tablature Recognition System.,2005,https://doi.org/10.5281/zenodo.1416378,"Christoph Dalitz, Niederrhein University of Applied Sciences, DEU, education;Thomas Karsten, Niederrhein University of Applied Sciences, DEU, education","In this article we describe an optical recognition system for historic lute tablature prints that we have built with the aid of the Gamera toolkit for document analysis and recognition. We give recognition rates for various historic sources and show that our system works quite well on printed tablature sources using movable types. For engraved and manuscript sources, we discuss some principal current limitations of our system and Gamera."
70,Sven Degroeve;Koen Tanghe;Bernard De Baets;Marc Leman;Jean-Pierre Martens,A Simulated Annealing Optimization of Audio Features for Drum Classification.,2005,https://doi.org/10.5281/zenodo.1417311,"Sven Degroeve, Ghent University, BEL, education;Koen Tanghe, Ghent University, BEL, education;Bernard De Baets, Ghent University, BEL, education;Marc Leman, Ghent University, BEL, education;Jean-Pierre Martens, Ghent University, BEL, education","""Current methods for the accurate recognition of instruments within music are based on discriminative data descriptors. These are features of the music fragment that capture the characteristics of the audio and suppress details that are redundant for the problem at hand. The extraction of such features from an audio signal requires the user to set certain parameters. We propose a method for optimizing the parameters for a particular task on the basis of the Simulated Annealing algorithm and Support Vector Machine classification. We show that using an optimized set of audio features improves the recognition accuracy of drum sounds in music fragments."""
71,Ruth Dhanaraj;Beth Logan,Automatic Prediction of Hit Songs.,2005,https://doi.org/10.5281/zenodo.1417571,"Ruth Dhanaraj, Hewlett Packard Labs, USA, company;Beth Logan, Hewlett Packard Labs, USA, company","We explore the automatic analysis of music to identify likely hit songs. We extract both acoustic and lyric information from each song and separate hits from non-hits using standard classiﬁers, speciﬁcally Support Vector Machines and boosting classiﬁers. Our features are based on global sounds learnt in an unsupervised fashion from acoustic data or global topics learnt from a lyrics database. Experiments on a corpus of 1700 songs demonstrate performance that is much better than random. The lyric-based features are slightly more useful than the acoustic features in correctly identifying hit songs. Concatenating the two features does not produce signiﬁcant improvements. Analysis of the lyric-based features shows that the absence of certain semantic information indicates that a song is more likely to be a hit."
72,Simon Dixon;Gerhard Widmer,MATCH: A Music Alignment Tool Chest.,2005,https://doi.org/10.5281/zenodo.1416952,"Simon Dixon, Austrian Research Institute for Artificial Intelligence, AUT, facility;Gerhard Widmer, Johannes Kepler University Linz, AUT, education","We present MATCH, a toolkit for aligning audio recordings of different renditions of the same piece of music, based on an efficient implementation of a dynamic time warping algorithm. A forward path estimation algorithm constrains the alignment path so that dynamic time warping can be performed with time and space costs that are linear in the size of the audio files. Frames of audio are represented by a positive spectral difference vector, which emphasises note onsets in the alignment process. In tests with Classical and Romantic piano music, the average alignment error was 41ms (median 20ms), with only 2 out of 683 test cases failing to align. The software is useful for content-based indexing of audio files and for the study of performance interpretation; it can also be used in real-time for tracking live performances. The toolkit also provides functions for displaying the cost matrix, the forward and backward paths, and any metadata associated with the recordings, which can be shown in real time as the alignment is computed."
73,Peter Jan O. Doets;Reginald L. Lagendijk,Extracting Quality Parameters for Compressed Audio from Fingerprints.,2005,https://doi.org/10.5281/zenodo.1416080,"P.J.O. Doets, Delft University of Technology, NLD, education;R.L. Lagendijk, Delft University of Technology, NLD, education","An audio ﬁngerprint is a compact yet very robust rep-
resentation of the perceptually relevant parts of audio
content.
It can be used to identify audio, even when
of severely distorted. Audio compression causes small
changes in the ﬁngerprint. We aim to exploit these small
ﬁngerprint differences due to compression to assess the
perceptual quality of the compressed audio ﬁle.
Anal-
ysis shows that for uncorrelated signals the Bit Error
Rate (BER) is approximately inversely proportional to the
square root of the Signal-to-Noise Ratio (SNR) of the sig-
nal. Experiments using real music conﬁrm this relation.
Further experiments show how the various local spectral
characteristics cause a large variation in the behavior of
the ﬁngerprint difference as a function of SNR or the bi-
trate set for compression."
74,Douglas Eck;Norman Casagrande,Finding Meter in Music Using An Autocorrelation Phase Matrix and Shannon Entropy.,2005,https://doi.org/10.5281/zenodo.1415650,"Douglas Eck, University of Montreal, CAN, education;Norman Casagrande, University of Montreal, CAN, education","This paper introduces a novel way to detect metrical struc-
ture in music. We introduce a way to compute autocorre-
lation such that the distribution of energy in phase space is
preserved in a matrix. The resulting autocorrelation phase
matrix is useful for several tasks involving metrical struc-
ture. First we can use the matrix to enhance standard auto-
correlation by calculating the Shannon entropy at each lag.
This approach yields improved results for autocorrelation-
based tempo induction. Second, we can efﬁciently search
the matrix for combinations of lags that suggest particular
metrical hierarchies. This approach yields a good model
for predicting the meter of a piece of music. Finally we
can use the phase information in the matrix to align a can-
didate meter with music, making it possible to perform
beat induction with an autocorrelation-based model. We
present results for several meter prediction and tempo in-
duction datasets, demonstrating that the approach is com-
petitive with models designed speciﬁcally for these tasks.
We also present preliminary beat induction results on a
small set of artiﬁcial patterns."
75,Rebecca Fiebrink;Cory McKay;Ichiro Fujinaga,Combining D2K and JGAP for Efficient Feature Weighting for Classification Tasks in Music Information Retrieval.,2005,https://doi.org/10.5281/zenodo.1415754,"Rebecca Fiebrink, McGill University, CAN, education;Cory McKay, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","Music classification continues to be an important component of music information retrieval research. An underutilized tool for improving the performance of classifiers is feature weighting. A major reason for its unpopularity, despite its benefits, is the potentially infinite calculation time it requires to achieve optimal results. Genetic algorithms offer potentially sub-optimal but reasonable solutions at much reduced calculation time, yet they are still quite costly. We investigate the advantages of implementing genetic algorithms in a parallel computing environment to make feature weighting an affordable instrument for researchers in MIR."
76,David Gerhard,Pitch Track Target Deviation in Natural Singing.,2005,https://doi.org/10.5281/zenodo.1418115,"David Gerhard, University of Regina, CAN, education","""Unlike ﬁxed-pitch instruments such as the piano, human singing can stray from a target pitch by as much as a semitone while still being perceived as a single ﬁxed note. This paper presents a study of the difference between tar- get pitch and actualized pitch in natural singing. A set of 50 subjects singing the same melody and lyric is used to compare utterance styles. An algorithm for alignment of idealized template pitch tracks to measured frequency tracks is presented. Speciﬁc examples are discussed, and generalizations are made with respect to the types of devi- ations typical in human singing. Demographics, including the skill of the singer, are presented and discussed in the context of the pitch track deviation from the ideal."""
77,Rob van Gulik;Fabio Vignoli,Visual Playlist Generation on the Artist Map.,2005,https://doi.org/10.5281/zenodo.1415206,"Rob van Gulik, Utrecht University, NLD, education;Fabio Vignoli, Philips Research Laboratories, NLD, company","""This paper describes a visual playlist creation method based on a previously designed visualization technique for large music collections. The method gives users high-level control over the contents of a playlist as well as the progression of songs in it, while minimizing the interaction requirements. An interesting feature of the technique is that it creates playlists that are independent of the underlying music collection, making them highly portable. Future work includes an extensive user evaluation to compare the described method with alternative techniques and to measure its qualities, such as the perceived ease of use and perceived usefulness."""
78,Peyman Heydarian;Joshua D. Reiss,The Persian Music and the Santur Instrument.,2005,https://doi.org/10.5281/zenodo.1415048,"Peyman Heydarian, Queen Mary, University of London, GBR, education;Joshua D. Reiss, Queen Mary, University of London, GBR, education","Persian music has had a profound effect on various Eastern musical cultures, and also influenced Southern European and Northern African music. The Santur, a hammered dulcimer, is one of the most important instruments in Persia. In this paper, Persian music and the Santur instrument are explained and analysed. Techniques for fundamental frequency detection are applied to data acquired from the Santur and results are reported."
79,Helge Homburg;Ingo Mierswa;Bülent Möller;Katharina Morik;Michael Wurst,A Benchmark Dataset for Audio Classification and Clustering.,2005,https://doi.org/10.5281/zenodo.1417065,"Helge Homburg, University of Dortmund, AI Unit, DEU, education;Ingo Mierswa, University of Dortmund, AI Unit, DEU, education;Bülent Möller, University of Dortmund, AI Unit, DEU, education;Katharina Morik, University of Dortmund, AI Unit, DEU, education;Michael Wurst, University of Dortmund, AI Unit, DEU, education","""We present a freely available benchmark dataset for audio classiﬁcation and clustering. This dataset consists of 10 seconds samples of 1886 songs obtained from the Garageband site. Beside the audio clips themselves, textual meta data is provided for the individual songs. The songs are classiﬁed into 9 genres. In addition to the genre infor- mation, our dataset also consists of 24 hierarchical cluster models created manually by a group of users. This en- ables a user centric evaluation of audio classiﬁcation and clustering algorithms and gives researchers the opportu- nity to test the performance of their methods on heteroge- neous data. We ﬁrst give a motivation for assembling our benchmark dataset. Then we describe the dataset and its elements in more detail. Finally, we present some initial results using a set of audio features generated by a feature construction approach."""
80,Toru Hosoya;Motoyuki Suzuki;Akinori Ito;Shozo Makino,Lyrics Recognition from a Singing Voice Based on Finite State Automaton for Music Information Retrieval.,2005,https://doi.org/10.5281/zenodo.1417855,"Toru Hosoya, Graduate School of Engineering, Tohoku University, JPN, education;Motoyuki Suzuki, Graduate School of Engineering, Tohoku University, JPN, education;Akinori Ito, Graduate School of Engineering, Tohoku University, JPN, education;Shozo Makino, Graduate School of Engineering, Tohoku University, JPN, education","Recently, several music information retrieval (MIR) sys-
tems have been developed which retrieve musical pieces
by the user’s singing voice. All of these systems use only
the melody information for retrieval. Although the lyrics
information is useful for retrieval, there have been few at-
tempts to exploit lyrics in the user’s input. In order to
develop a MIR system that uses lyrics and melody infor-
mation, lyrics recognition is needed. Lyrics recognition
from a singing voice is achieved by similar technology to
that of speech recognition. The difference between lyrics
recognition and general speech recognition is that the in-
put lyrics are a part of the lyrics of songs in a database. To
exploit linguistic constraints maximally, we described the
recognition grammar using a ﬁnite state automaton (FSA)
that accepts only lyrics in the database. In addition, we
carried out a “singing voice adaptation” using a speaker
adaptation technique. In our experimental results, about
86% retrieval accuracy was obtained."
81,Xiao Hu 0001;J. Stephen Downie;Kris West;Andreas F. Ehmann,Mining Music Reviews: Promising Preliminary Results.,2005,https://doi.org/10.5281/zenodo.1417067,"Xiao Hu, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;Kris West, University of East Anglia, GBR, education;Andreas Ehmann, University of Illinois at Urbana-Champaign, USA, education","In this paper we present a system for the automatic mining of information from music reviews. We demonstrate a system which has the ability to automatically classify reviews according to the genre of the music reviewed and to predict the simple one-to-five star rating assigned to the music by the reviewer. This experiment is the first step in the development of a system to automatically mine arbitrary bodies of text, such as weblogs (blogs) for musically relevant information."
82,Özgür Izmirli,Tonal Similarity from Audio Using a Template Based Attractor Model.,2005,https://doi.org/10.5281/zenodo.1416688,"Özgür İzmirli, Connecticut College, USA, education","A model that calculates similarity of tonal evolution among pieces in an audio database is presented. The model employs a template based key finding algorithm. This algorithm is used in a sliding window fashion to obtain a sequence of tonal center estimates that delineate the trajectory of tonal evolution in tonal space. A chroma based representation is used to capture tonality informa-tion. Templates are formed from instrument sounds weighted according to pitch distribution profiles. For each window in the input audio, the chroma based repre-sentation is interpreted with respect to the precalculated templates that serve as attractor points in tonal space. This leads to a discretization in both time and tonal space making the output representation compact. Local and global variations in tempo are accounted for using dynamic time warping that employs a special type of music theoretical distance measure. Evaluation is given in two stages. The first is evaluation of the key finding model to assess its performance in key finding for raw audio input. The second is based on cross validation testing for pieces that have multiple performances in the database to determine the success of recall by distance."
83,Jyh-Shing Roger Jang;Chao-Ling Hsu;Hong-Ru Lee,Continuous HMM and Its Enhancement for Singing/Humming Query Retrieval.,2005,https://doi.org/10.5281/zenodo.1414842,"Jyh-Shing Roger Jang, National Tsing Hua University, TWN, education;Chao-Ling Hsu, National Tsing Hua University, TWN, education;Hong-Ru Lee, National Tsing Hua University, TWN, education","""The use of HMM (Hidden Markov Models) for speech 
recognition has been successful for various applications 
in the past decades. However, the use of continuous 
HMM (CHMM) for melody recognition via acoustic 
input (MRAI for short), or the so-called query by sing-
ing/humming, has seldom been reported, partly due to 
the difference in acoustic characteristics between speech 
and singing/humming inputs. This paper will derive the 
formula of CHMM training for frame-based MRAI. In 
particular, we shall propose enhancement to CHMM and 
demonstrate that with the enhancement scheme, CHMM 
can compare favourably with DTW in both efficiency 
and effectiveness."""
84,Phillip B. Kirlin;Paul E. Utgoff,VOISE: Learning to Segregate Voices in Explicit and Implicit Polyphony.,2005,https://doi.org/10.5281/zenodo.1417225,"Phillip B. Kirlin, University of Massachusetts Amherst, USA, education;Paul E. Utgoff, University of Massachusetts Amherst, USA, education","Finding multiple occurrences of themes and patterns in music can be hampered due to polyphonic textures. This is caused by the complexity of music that weaves multiple independent lines of music together. We present and demonstrate a system, VoiSe, that is capable of isolating individual voices in both explicit and implicit polyphonic music. VoiSe is designed to work on a symbolic representation of a music score, and consists of two components: a same-voice predicate implemented as a learned decision tree, and a hard-coded voice numbering algorithm."
85,Tetsuro Kitahara;Masataka Goto;Kazunori Komatani;Tetsuya Ogata;Hiroshi G. Okuno,"Instrument Identification in Polyphonic Music: Feature Weighting with Mixed Sounds, Pitch-Dependent Timbre Modeling, and Use of Musical Context.",2005,https://doi.org/10.5281/zenodo.1415724,"Tetsuro Kitahara, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Kazunori Komatani, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuya Ogata, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Hiroshi G. Okuno, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education","This paper addresses the problem of identifying musical instruments in polyphonic music. Musical instrument identification (MII) is an important task in music information retrieval because MII results make it possible to automatically retrieving certain types of music (e.g., piano sonata, string quartet). Only a few studies, however, have dealt with MII in polyphonic music. In MII in polyphonic music, there are three issues: feature variations caused by sound mixtures, the pitch dependency of timbres, and the use of musical context. For the first issue, templates of feature vectors representing timbres are extracted from not only isolated sounds but also sound mixtures. Because some features are not robust in the mixtures, features are weighted according to their robustness by using linear discriminant analysis. For the second issue, we use an F0-dependent multivariate normal distribution, which approximates the pitch dependency as a function of fundamental frequency. For the third issue, when the instrument of each note is identified, the a priori probability of the note is calculated from the a posteriori probabilities of temporally neighboring notes. Experimental results showed that recognition rates were improved from 60.8% to 85.8% for trio music and from 65.5% to 91.1% for duo music."
86,Peter Knees;Markus Schedl;Gerhard Widmer,Multiple Lyrics Alignment: Automatic Retrieval of Song Lyrics.,2005,https://doi.org/10.5281/zenodo.1415140,"Peter Knees, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility;Markus Schedl, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility;Gerhard Widmer, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility","We present an approach to automatically retrieve and extract lyrics of arbitrary songs from the Internet. It is intended to provide easy and convenient access to lyrics for users, as well as a basis for further research based on lyrics, e.g. semantic analysis. Due to the fact that many lyrics found on the web suffer from individual errors like typos, we make use of multiple versions from different sources to eliminate mistakes. This is accomplished by Multiple Sequence Alignment. The different sites are aligned and examined for matching sequences of words, finding those parts on the pages that are likely to contain the lyrics. This provides a means to find the most probable version of lyrics, i.e. a version with highest consensus among different sources."
87,Catherine Lai;Beinan Li;Ichiro Fujinaga,Preservation Digitization of David Edelberg's Handel LP Collection: A Pilot Project.,2005,https://doi.org/10.5281/zenodo.1416616,"Catherine Lai, McGill University, CAN, education;Beinan Li, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","""This paper describes the digitization process for building an online collection of LPs and the procedure for creating the ground-truth data essential for developing an automated metadata and content capturing system."""
88,Aristomenis S. Lampropoulos;Paraskevi S. Lampropoulou;George A. Tsihrintzis,Musical Genre Classification Enhanced by Improved Source Separation Technique.,2005,https://doi.org/10.5281/zenodo.1416292,"Aristomenis S. Lampropoulos, University of Piraeus, GRC, education;Paraskevi S. Lampropoulou, University of Piraeus, GRC, education;George A. Tsihrintzis, University of Piraeus, GRC, education","""We present a system for musical genre classification based on audio features extracted from signals which correspond to distinct musical instrument sources. For the separation of the musical sources, we propose an innovative technique in which the convolutive sparse coding algorithm is applied to several portions of the audio signal. The system is evaluated and its performance is assessed."""
89,Wei Liang;Shuwu Zhang;Bo Xu 0002,A Hierarchical Approach for Audio Stream Segmentation and Classification.,2005,https://doi.org/10.5281/zenodo.1415166,"Wei Liang, Institute of Automation, Chinese Academy of Sciences, CHN, facility;Shuwu Zhang, Institute of Automation, Chinese Academy of Sciences, CHN, facility;Bo Xu, Institute of Automation, Chinese Academy of Sciences, CHN, facility","""This paper describes a hierarchical approach for fast audio stream segmentation and classification. With this approach, the audio stream is firstly segmented into audio clips by MBCR (Multiple sub-Bands spectrum Centroid relative Ratio) based histogram modeling. Then a MGM (Modified Gaussian modeling) based hierarchical classifier is adopted to put the segmented audio clips into six pre-defined categories in terms of discriminative background sounds, which is pure speech, pure music, song, speech with music, speech with noise and silence. The experiments on real TV program recordings showed that this approach has higher accuracy and recall rate for audio classification with a fast speed under noise environments."""
90,Wei Liang;Shuwu Zhang;Bo Xu 0002,A Histogram Algorithm for Fast Audio Retrieval.,2005,https://doi.org/10.5281/zenodo.1415812,"Wei Liang, Institute of Automation, Chinese Academy of Sciences, CHN, facility;Shuwu Zhang, Institute of Automation, Chinese Academy of Sciences, CHN, facility;Bo Xu, Institute of Automation, Chinese Academy of Sciences, CHN, facility","""This paper describes a fast audio detection method for specific audio retrieval in the AV stream. The method is a histogram matching algorithm based on structural and perceptual features. This algorithm extracts audio features based on human perception on the sound scene and locates the special audio clip by fast histogram matching. Experimental results based on the advertisement detection in TV program showed that the algorithm can achieve a very high overall precision and recall rate both about 97% with very fast search time about 1/40 on real time."""
91,Dominik Lübbers,SoniXplorer: Combining Visualization and Auralization for Content-Based Exploration of Music Collections.,2005,https://doi.org/10.5281/zenodo.1418021,"Dominik Lübbers, RWTH Aachen University, DEU, education","Music can be described best by music. However, current research in the design of user interfaces for the exploration of music collections has mainly focused on visualization aspects ignoring possible benefits from spatialized music playback. We describe our first development steps towards two novel user-interface designs: The Sonic Radar arranges a fixed number of prototypes resulting from a content-based clustering process in a circle around the user’s standpoint. To derive an auralization of the scene, we introduce the concept of an aural focus of perception that adapts well-known principles from the visual domain. The Sonic SOM is based on Kohonen’s Self-Organizing Map. It helps the user in understanding the structure of his music collection by positioning titles on a two-dimensional grid according to their high-dimensional similarity. We show how our auralization concept can be adapted to extend this visualization technique and thereby support multimodal navigation."
92,Michael I. Mandel;Dan Ellis,Song-Level Features and Support Vector Machines for Music Classification.,2005,https://doi.org/10.5281/zenodo.1415024,"Michael I. Mandel, Columbia University, USA, education;Daniel P.W. Ellis, Columbia University, USA, education","Searching and organizing growing digital music collections requires automatic classification of music. This paper describes a new system, tested on the task of artist identification, that uses support vector machines to classify songs based on features calculated over their entire lengths. Since support vector machines are exemplar-based classifiers, training on and classifying entire songs instead of short-time features makes intuitive sense. On a dataset of 1200 pop songs performed by 18 artists, we show that this classifier outperforms similar classifiers that use only SVMs or song-level features. We also show that the KL divergence between single Gaussians and Mahalanobis distance between MFCC statistics vectors perform comparably when classifiers are trained and tested on separate albums, but KL divergence outperforms Mahalanobis distance when trained and tested on songs from the same albums."
93,Daniel McEnnis;Cory McKay;Ichiro Fujinaga;Philippe Depalle,jAudio: An Feature Extraction Library.,2005,https://doi.org/10.5281/zenodo.1416648,"Daniel McEnnis, McGill University, CAN, education;Cory McKay, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education;Philippe Depalle, McGill University, CAN, education","jAudio is a new framework for feature extraction designed to eliminate the duplication of effort in calculating features from an audio signal. This system meets the needs of MIR researchers by providing a library of analysis algorithms that are suitable for a wide array of MIR tasks. In order to provide these features with a minimal learning curve, the system implements a GUI that makes the process of selecting desired features straight forward. A command-line interface is also provided to manipulate jAudio via scripting. Furthermore, jAudio provides a unique method of handling multidimensional features and a new mechanism for dependency handling to prevent duplicate calculations. The system takes a sequence of audio files as input. In the GUI, users select the features that they wish to have extracted—letting jAudio take care of all dependency problems—and either execute directly from the GUI or save the settings for batch processing. The output is either an ACE XML file or an ARFF file depending on the user’s preference."
94,Anders Meng;John Shawe-Taylor,An Investigation of Feature Models for Music Genre Classification Using the Support Vector Classifier.,2005,https://doi.org/10.5281/zenodo.1416052,"Anders Meng, Technical University of Denmark, DNK, education;John Shawe-Taylor, University of Southampton, GBR, education","In music genre classification the decision time is typically of the order of several seconds, however, most automatic music genre classification systems focus on short time features derived from 10 − 50ms. This work investigates two models, the multivariate Gaussian model and the multivariate autoregressive model for modelling short time features. Furthermore, it was investigated how these models can be integrated over a segment of short time features into a kernel such that a support vector machine can be applied. Two kernels with this property were considered, the convolution kernel and product probability kernel. In order to examine the different methods an 11 genre music setup was utilized. In this setup the Mel Frequency Cepstral Coefficients were used as short time features. The accuracy of the best performing model on this data set was ∼ 44% compared to a human performance of ∼ 52% on the same data set."
95,Annamaria Mesaros;Jaakko Astola,The Mel-Frequency Cepstral Coefficients in the Context of Singer Identification.,2005,https://doi.org/10.5281/zenodo.1417539,"Annamaria Mesaros, Technical University of Cluj Napoca, ROMANIA, education;Jaakko Astola, Tampere University of Technology, FINLAND, education","The singing voice is the oldest and most complex musical instrument. A familiar singer’s voice is easily recognizable for humans, even when hearing a song for the first time. On the other hand, for automatic identification this is a difficult task among sound source identification applications. The signal processing techniques aim to extract features that are related to identity characteristics. The research presented in this paper considers 32 Mel-Frequency Cepstral Coefficients in two subsets: the low order MFCCs characterizing the vocal tract resonances and the high order MFCCs related to the glottal wave shape. We explore possibilities to identify and discriminate singers using the two sets. Based on the results we can affirm that both subsets have their contribution in defining the identity of the voice, but the high order subset is more robust to changes in singing style."
96,J. Enrique Muñoz Expósito;Sebastian García Galán;Nicolás Ruiz-Reyes;Pedro Vera-Candeas;F. Rivas-Peña,Speech/Music Discrimination Using a Single Warped LPC-Based Feature.,2005,https://doi.org/10.5281/zenodo.1417711,"J.E. Muñoz-Expósito, University of Jaén, ESP, education;S. Garcia-Galán, University of Jaén, ESP, education;N. Ruiz-Reyes, University of Jaén, ESP, education;P. Vera-Candeas, University of Jaén, ESP, education;F. Rivas-Peña, University of Jaén, ESP, education","Automatic discrimination of speech and music is an important tool in many multimedia applications. The paper presents a low complexity but effective approach for speech/music discrimination, which exploits only one simple feature, called Warped LPC-based Spectral Centroid (WLPC-SC). A three-component Gaussian Mixture Model (GMM) classifier is used because it showed a slightly better performance than other Statistical Pattern Recognition (SPR) classifiers. Comparison between WLPC-SC and the timbral features proposed in Tzanetakis and Cook (2002) is performed, aiming to assess the good discriminatory power of the proposed feature. Experimental results reveal that our speech/music discriminator is robust and fast, making it suitable for real-time multimedia applications."
97,Robert Neumayer;Michael Dittenbach;Andreas Rauber,"PlaySOM and PocketSOMPlayer, Alternative Interfaces to Large Music Collections.",2005,https://doi.org/10.5281/zenodo.1414818,"Robert Neumayer, Vienna University of Technology, AUT, education;Michael Dittenbach, eCommerce Competence Center, AUT, company;Andreas Rauber, Vienna University of Technology, AUT, education","With the rising popularity of digital music archives the need for new access methods such as interactive exploration or similarity-based search become significant. In this paper we present the PlaySOM, as well as the PocketSOMPlayer, two novel interfaces that enable one to browse a music collection by navigating a map of clustered music tracks and to select regions of interest containing similar tracks for playing. The PlaySOM system is primarily designed to allow interaction via a large-screen device, whereas the PocketSOMPlayer is implemented for mobile devices, supporting both local as well as streamed audio replay. This approach offers content-based organization of music as an alternative to conventional navigation of audio archives, i.e. flat or hierarchical listings of music tracks that are sorted and filtered by meta information."
98,Giovanna Neve;Nicola Orio,Experiments on Segmentation Techniques for Music Documents Indexing.,2005,https://doi.org/10.5281/zenodo.1416996,"Nicola Orio, Department of Information Engineering, ITA, education;Giovanna Neve, Department of Information Engineering, ITA, education","""This paper presents an overview of different approaches to melody segmentation aimed at extracting music lexical units, which can be used as content descriptors of music documents. Four approaches have been implemented and compared on a test collection of real documents and queries, showing their impact on index term size and on retrieval effectiveness. From the results, simple but extensive approaches seem to give better performances than more sophisticated segmentation algorithms."""
99,Elias Pampalk;Arthur Flexer;Gerhard Widmer,Improvements of Audio-Based Music Similarity and Genre Classificaton.,2005,https://doi.org/10.5281/zenodo.1418083,"Elias Pampalk, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility, Institute of Medical Cybernetics and Artificial Intelligence, Center for Brain Research, Medical University of Vienna, AUT, education, Department of Computational Perception, Johannes Kepler University, AUT, education;Arthur Flexer, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility, Institute of Medical Cybernetics and Artificial Intelligence, Center for Brain Research, Medical University of Vienna, AUT, education;Gerhard Widmer, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility, Department of Computational Perception, Johannes Kepler University, AUT, education","Audio-based music similarity measures can be applied to automatically generate playlists or recommendations. In this paper spectral similarity is combined with complementary information from fluctuation patterns including two new descriptors derived thereof. The performance is evaluated in a series of experiments on four music collections. The evaluations are based on genre classification, assuming that very similar tracks belong to the same genre. The main findings are that, (1) although the improvements are substantial on two of the four collections our extensive experiments confirm earlier findings that we are approaching the limit of how far we can get using simple audio statistics. (2) We have found that evaluating similarity through genre classification is biased by the music collection (and genre taxonomy) used. Furthermore, (3) in a cross validation no pieces from the same artist should be in both training and test set."
100,Elias Pampalk;Tim Pohle;Gerhard Widmer,Dynamic Playlist Generation Based on Skipping Behavior.,2005,https://doi.org/10.5281/zenodo.1414932,"Elias Pampalk, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility, Johannes Kepler University, AUT, education;Tim Pohle, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility, Johannes Kepler University, AUT, education;Gerhard Widmer, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility, Johannes Kepler University, AUT, education","Common approaches to creating playlists are to randomly
shufﬂe a collection (e.g. iPod shufﬂe) or manually select
songs. In this paper we present and evaluate heuristics
to adapt playlists automatically given a song to start with
(seed song) and immediate user feedback.
Instead of rich metadata we use audio-based similar-
ity. The user gives feedback by pressing a skip button
if the user dislikes the current song.
Songs similar to
skipped songs are removed, while songs similar to ac-
cepted ones are added to the playlist. We evaluate the
heuristics with hypothetical use cases. For each use case
we assume a speciﬁc user behavior (e.g. the user always
skips songs by a particular artist). Our results show that
using audio similarity and simple heuristics it is possible
to drastically reduce the number of necessary skips."
101,Steffen Pauws;Sander van de Wijdeven,User Evaluation of a New Interactive Playlist Generation Concept.,2005,https://doi.org/10.5281/zenodo.1415180,"Steffen Pauws, Philips Research, NLD, company;Sander van de Wijdeven, Philips Research, NLD, company","Selecting the ‘right’ songs and putting them in the ‘right’
order are key to a great music listening or dance experi-
ence. ‘SatisFly’ is an interactive playlist generation sys-
tem in which the user can tell what kind of songs should
be contained in what order in the playlist, while she navi-
gates through the music collection. The system uses con-
straint satisfaction to generate a playlist that meets all user
wishes. In a user evaluation, it was found that users cre-
ated high-quality playlists in a swift way and with little ef-
fort using the system, while still having complete control
on their music choices. The novel interactive way of cre-
ating a playlist, while browsing through the music collec-
tion, was highly appreciated. Ease of navigation through
a music collection is still an issue that needs further atten-
tion."
102,Geoffroy Peeters,Rhythm Classification Using Spectral Rhythm Patterns.,2005,https://doi.org/10.5281/zenodo.1417495,"Geoffroy Peeters, IRCAM, FRA, facility","In this paper, we study the use of spectral patterns to represent the characteristics of the rhythm of an audio signal. A function representing the position of onsets over time is ﬁrst extracted from the audio signal. From this function we compute at each time a vector which represents the characteristics of the local rhythm. Three feature sets are studied for this vector. They are derived from the amplitude of the Discrete Fourier Transform, the Auto- Correlation Function and the product of the DFT and of a Frequency-Mapped ACF. The vectors are then sampled at some speciﬁc frequencies, which represents various ratios of the local tempo. The ability of the three feature sets to represent the rhythm characteristics of an audio item is evaluated through a classiﬁcation task. We show that using such simple spectral representations allows obtaining results comparable to the state of the art."
103,Jeremy Pickens,Classifier Combination for Capturing Musical Variation.,2005,https://doi.org/10.5281/zenodo.1418219,"Jeremy Pickens, King’s College London, GBR, education","At its heart, music information retrieval is characterized by the need to ﬁnd the similarity between pieces of music. However, “similar” does not mean “the same”. Therefore, techniques for approximate matching are crucial to the development of good music information retrieval sys- tems. Yet as one increases the level of approximation, one ﬁnds not only additional similar, relevant music, but also a larger number of not-as-similar, non-relevant music. The purpose of this work is to show that if two different re- trieval systems do approximate matching in different man- ners, and both give decent results, they can be combined to give results better than either system individually. One need not sacriﬁce accuracy for the sake of ﬂexibility."
104,Aggelos Pikrakis;Sergios Theodoridis,A Novel HMM Approach to Melody Spotting in Raw Audio Recordings.,2005,https://doi.org/10.5281/zenodo.1414886,"Aggelos Pikrakis, University of Athens, GRC, education;Sergios Theodoridis, University of Athens, GRC, education","This paper presents a melody spotting system based on Variable Duration Hidden Markov Models (VDHMM’s), capable of locating monophonic melodies in a database of raw audio recordings. The audio recordings may either contain a single instrument performing in solo mode, or an ensemble of instruments where one of the instruments has a leading role. The melody to be spotted is presented to the system as a sequence of note durations and music intervals. In the sequel, this sequence is treated as a pattern prototype and based on it, a VDHMM is constructed. The probabilities of the associated VDHMM are determined according to a set of rules that account (a) for the allowable note duration flexibility and (b) with possible structural deviations from the prototype pattern. In addition, for each raw audio recording in the database, a sequence of note durations and music intervals is extracted by means of a multi pitch tracking algorithm. These sequences are subsequently fed as input to the constructed VDHMM that models the pattern to be located. The VDHMM employs an enhanced Viterbi algorithm, previously introduced by the authors, in order to account for pitch tracking errors and performance improvisations of the instrument players. For each audio recording in the database, the best-state sequence generated by the enhanced Viterbi algorithm is further post-processed in order to locate occurrences of the melody which is searched. Our method has been successfully tested with a variety of cello recordings in the context of Western Classical music, as well as with Greek traditional multi-instrument recordings, in which clarinet has a leading role."
105,Christopher Raphael,A Graphical Model for Recognizing Sung Melodies.,2005,https://doi.org/10.5281/zenodo.1417052,"Christopher Raphael, Indiana Univ., USA, education","A method is presented for automatic transcription of sung melodic fragments to score-like representation, including metric values and pitch. A joint model for pitch, rhythm, segmentation, and tempo is deﬁned for a sung fragment. We then discuss the identiﬁcation of the globally optimal musical transcription, given the observed audio data. A post process estimates the location of the tonic, so the transcription can be presented into they key of C. Experimental results are presented for a small test collection."
106,Craig Stuart Sapp,Online Database of Scores in the Humdrum File Format.,2005,https://doi.org/10.5281/zenodo.1417281,"Craig Stuart Sapp, Center for Computer Assisted Research in the Humanities, USA, facility, Stanford University, USA, education, Centre for the History and Analysis of Recorded Music, Royal Holloway, University of London, GBR, education","KernScores, an online library of musical data currently consisting of over 5 million notes, has been created to assist projects dealing with the computational analysis of musical scores.  The online scores are in a format suitable for processing with the Humdrum Toolkit for Music Research, but the website also provides automatic translations into several other popular data formats for digital musical scores."
107,Nicolas Scaringella;Giorgio Zoia,On the Modeling of Time Information for Automatic Genre Recognition Systems in Audio Signals.,2005,https://doi.org/10.5281/zenodo.1416064,"Nicolas Scaringella, École Polytechnique Fédérale de Lausanne, CHE, education;Giorgio Zoia, École Polytechnique Fédérale de Lausanne, CHE, education","""The creation of huge databases coming from both restoration of existing analogue archives and new content is demanding fast and more and more reliable tools for content analysis and description, to be used for searches, content queries and interactive access. In that context, musical genres are crucial descriptors since they have been widely used for years to organize music catalogues, libraries and shops. Despite their use musical genres remain poorly defined concepts which make of the automatic classification problem a non-trivial task. Most automatic genre classification models rely on the same pattern recognition architecture: extracting features from chunks of audio signal and classifying features independently. In this paper, we focus instead on the low-level temporal relationships between chunks when classifying audio signals in terms of genre; in other words, we investigate means to model short-term time structures from context information in music segments to consolidate classification consistency by reducing ambiguities. A detailed comparative analysis of five different time modelling schemes is provided and classification results are reported for a database of 1400 songs evenly distributed over 7 genres."""
108,Elliot Sinyor;Cory McKay;Rebecca Fiebrink;Daniel McEnnis;Ichiro Fujinaga,Beatbox Classification Using ACE.,2005,https://doi.org/10.5281/zenodo.1414920,"Elliot Sinyor, McGill University, CAN, education;Cory McKay, McGill University, CAN, education;Rebecca Fiebrink, McGill University, CAN, education;Daniel McEnnis, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","This paper describes the use of the Autonomous Classification Engine (ACE) to classify beatboxing (vocal percussion) sounds. A set of unvoiced percussion sounds belonging to five classes (bass drum, open hihat, closed hihat and two types of snare drum) were recorded and manually segmented. ACE was used to compare various classification techniques, both with and without feature selection. The best result was 95.55% accuracy using AdaBoost with C4.5 decision tress."
109,Robert Young Walser,Herding Folksongs.,2005,https://doi.org/10.5281/zenodo.1415640,"Robert Young Walser, University of Aberdeen, GBR, education;Julia Bishop, University of Sheffield, GBR, education","Cataloging a large, multi-media collection of traditional
song and drama in preparation for online presentation
highlights issues of song identity and access in the con-
text of contemporary digitized archives. In the James
Madison Carpenter collection a particular folksong sung
by a particular individual may exist in multiple manifes-
tations: typed song text, sound recording(s), and/or
manuscript music notation. While controlled vocabulary
references such as Child and Roud numbers provide a
degree of identification, such narrative- and text-centric
tools are only partly effective in differentiating folkloric
materials. Additional means are needed for identifying
and controlling folk materials which are distinguished by
other aspects of the song such as melody or non-narrative
text. The Carpenter project team’s experience with En-
coded Archival Description (EAD) illustrates the value of
this platform-independent, widely recognized standard
and suggests opportunities for further developments par-
ticularly suited to locating and retrieving folk music
materials."
110,Kris West;Stephen Cox,Finding An Optimal Segmentation for Audio Genre Classification.,2005,https://doi.org/10.5281/zenodo.1416746,"Kris West, University of East Anglia, GBR, education;Stephen Cox, University of East Anglia, GBR, education","""In the automatic classiﬁcation of music many different segmentations of the audio signal have been used to calculate features. These include individual short frames (23 ms), longer frames (200 ms), short sliding textural windows (1 sec) of a stream of 23 ms frames, large ﬁxed windows (10 sec) and whole ﬁles. In this work we present an evaluation of these different segmentations, showing that they are sub-optimal for genre classiﬁcation and introduce the use of an onset detection based segmentation, which appears to outperform all of the ﬁxed and sliding windows segmentation schemes in terms of classiﬁcation accuracy and model size."""
111,Tillman Weyde;Christian Datzko,Efficient Melody Retrieval with Motif Contour Classes.,2005,https://doi.org/10.5281/zenodo.1414738,"Tillman Weyde, City University, School of Informatics, Department of Computing, London, UK, education;Christian Datzko, University of Osnabrück, Research Department of Music and Media Technology, Osnabrück, Germany, education","This paper describes the use of motif contour classes for efﬁcient retrieval of melodies from music collections. Instead of extracting incipits or themes, complete monophonic pieces are indexed for their motifs, using classes of motif contours. Similarity relations between these classes can be used for a very efﬁcient search. This can serve as a ﬁrst level search, which can be reﬁned by using more computationally intensive comparisons on its results. The model introduced has been implemented and tested using the MUSITECH framework. We present empirical and analytical results on the retrieval quality, the complexity, and quality/efﬁciency trade-off."
112,Wen Xue;Mark Sandler,A Partial Searching Algorithm and Its Application for Polyphonic Music Transcription.,2005,https://doi.org/10.5281/zenodo.1415740,"Xue Wen, Queen Mary, University of London, GBR, education;Mark Sandler, Queen Mary, University of London, GBR, education","This paper proposes an algorithm for studying spectral contents of pitched sounds in real-world recordings. We assume that the 2nd-order difference, w.r.t. partial index, of a pitched sound is bounded by some small positive value, rather than equal to 0 in a perfect harmonic case. Given a spectrum and a fundamental frequency f0, the algorithm searches the spectrum for partials that can be associated with f0 by dynamic programming. In section 3 a background-foreground model is plugged into the algorithm to make it work with reverberant background, such as in a piano recording. In section 4 we illustrate an application of the algorithm in which a multipitch scoring machine, which involves special processing for close or shared partials, is coupled with a tree searching method for polyphonic transcription task. Results are evaluated on the traditional note level, as well as on a partial-based sub-note level."
113,Yi Yu 0001;Chiemi Watanabe;Kazuki Joe,Towards a Fast and Efficient Match Algorithm for Content-Based Music Retrieval on Acoustic Data.,2005,https://doi.org/10.5281/zenodo.1415874,"Yi YU, Nara Women’s University, JPN, education;Chiemi WATANABE, Nara Women’s University, JPN, education;Kazuki JOE, Nara Women’s University, JPN, education","In this paper we present a fast and efﬁcient match algorithm, which consists of two key techniques: Spectral Correlation Based Feature Merge(SCBFM) and Two-Step Retrieval(TSR). SCBFM can remove the redundant information. In consequence, the resulting feature sequence has a smaller size, requiring less storage and computation. In addition, most of the tempo variation is removed; thus a much simpler sequence match method can be adopted. Also, TSR relies on the characteristics of Mel-Frequency Cepstral Coefﬁcient(MFCC), where the precise match in the second step depends on the ﬁrst step to ﬁlter out most of the dissimilar references with only the low order MFCC feature. As a result, the whole retrieval speed can be further improved. The experimental evaluation veriﬁes that SCBFM-TSR yields more meaningful results in comparatively short time. The experiment results are analyzed with a theoretical approach that seeks to ﬁnd the relation between Spectral Correlation(SC) threshold and storage, computation."
