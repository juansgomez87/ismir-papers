Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,David Bainbridge 0001,The role of Music IR in the New Zealand Digital Music Library project.,2000,https://doi.org/10.5281/zenodo.1416260,"David Bainbridge, Department of Computer Science, University of Waikato","This extended abstract describes the computer music work that forms part of the New Zealand Digital Library (NZDL) project. The music work focuses on data acquisition, retrieval, presentation, and scalability. The MELDEX system, a web-based system, supports searching through text and sung queries, and browsing through metadata lists. The system includes collections of popular tunes derived from sheet music, folksongs, and MIDI files. The software implements a distributed architecture and allows for different indexes to be served to the same collection on different computers. The acquisition methods include automatic conversion of sheet music using Optical Music Recognition (OMR) software, online MIDI files, and existing databases of music in symbolic form. The OMR software has been extended to merge reconstructed scores with MIDI renditions to improve accuracy. Acquiring symbolic music information from MIDI files is simpler compared to sheet music."
1,Eloi Batlle;Pedro Cano,Automatic Segmentation for Music Classification using Competitive Hidden Markov Models.,2000,https://doi.org/10.5281/zenodo.1416764,"Eloi Batlle, Audiovisual Institute. Universitat Pompeu Fabra;Pedro Cano, Audiovisual Institute. Universitat Pompeu Fabra","Music information retrieval has become a major topic in recent years, leading to the growth of audio databases. However, the usefulness of these databases relies on their organization and structure. In this paper, we propose a new audio classification tool that can automatically segment audio material in an unsupervised way. The segments obtained are labeled based on their psychoacoustic properties, allowing for fast indexing and retrieval of audio fragments. We use competitive hidden Markov models as the main classification engine, eliminating the need for previous labeled data. Our results show that these models converge to a realistic segmentation architecture."
2,Juan Pablo Bello;Giuliano Monti;Mark B. Sandler,Techniques for Automatic Music Transcription.,2000,https://doi.org/10.5281/zenodo.1414872,"Juan Pablo Bello, Department of Electronic Engineering, King’s College London;Giuliano Monti, Department of Electronic Engineering, King’s College London;Mark Sandler, Department of Electronic Engineering, King’s College London","Two systems for automatic music transcription are reviewed in this paper. The first system performs monophonic transcription using an autocorrelation pitch tracker. It takes advantage of heuristic parameters related to the similarity between image and sound in the collector. The second system is able to analyze simple polyphonic tracks using a blackboard system. It receives input from a segmentation routine and includes a neural network chord recognizer. Examples are provided to illustrate the performance and weaknesses of the current implementation, and next steps for further development are defined."
3,Daniel Bendor;Mark B. Sandler,Time Domain Extraction of Vibrato from Monophonic Instruments.,2000,https://doi.org/10.5281/zenodo.1416810,"Daniel Bendor, Undergraduate School of Electrical Engineering, University of Maryland at College Park;Mark Sandler, Department of Electronic Engineering, King's College London","Vibrato is an essential ingredient in the expressive nature of many musical instruments. The goal of this research is to extract information describing the amplitude, frequency, and phase of the vibrato from a section of monophonic music. The amplitude and frequency modulation signals can be extracted using envelope and pitch extraction techniques respectively. The unfiltered vibrato signal is found by sliding a window and calculating the standard deviation within the window. The signal can then be filtered to obtain the original vibrato signal causing the amplitude modulation. Pitch extraction can be done using a bandpass filter."
4,Alain Bonardi,IR for Contemporary Music: What the Musicologist Needs.,2000,https://doi.org/10.5281/zenodo.1415912,"Alain Bonardi, IRCAM","Active listening in contemporary music involves more than just receiving musical information. It is an interactive process between the listener and the musical documents, including automatic music information research and extraction, to uncover the composer's intentions. Computer-assisted listening for musicologists, such as in IRCAM's digital library, provides a framework that allows for varying representations of music and the ability to associate different contexts. This enables the musicologist to analyze and interpret the music more effectively."
5,Wei Chai;Barry Vercoe,Using User Models in Music Information Retrieval Systems.,2000,https://doi.org/10.5281/zenodo.1415898,"Wei Chai, Media Laboratory, Massachusetts Institute of Technology;Barry Vercoe, Media Laboratory, Massachusetts Institute of Technology","Most websites providing music services only support category-based browsing and/or text-based searching. There has been some research to improve the interface either for pull applications, e.g. query-by-humming systems, or for push applications, e.g. collaborative-filtering-based or feature-based music recommendation systems. However, for content-based search or feature-based filtering systems, one important problem is to describe music by its parameters or features, so that search engines or information filtering agents can use them to measure the similarity of the target (user's query or preference) and the candidates. MPEG7 (formally called ""Multimedia Content Description Interface"") is an international standard, which describes the multimedia content data to allow universal indexing, retrieval, filtering, control, and other activities supported by rich metadata. However, the metadata about the multimedia content itself are still insufficient, because many features of multimedia content are quite perceptual and user-dependent. For example, emotional features are very important for multimedia retrieval, but they are hard to be described by a universal model since different users may have different emotional responses to the same multimedia content. We therefore turn to user modeling techniques and representations to describe the properties of each user, so that the retrieval will be more accurate. Besides, user modeling can be used to reduce the search space, make push service easier and improve the user interface."
6,Arbee L. P. Chen,"Music Representation, Indexing and Retrieval at NTHU.",2000,https://doi.org/10.5281/zenodo.1417981,"Arbee L.P. Chen, Department of Computer Science, National Tsing Hua University","In this extended abstract, the work on the representation, indexing, and retrieval of music data is summarized. The focus is on treating rhythm, melody, and chords as music features and developing data structures and algorithms for efficient matching and retrieval. Techniques for retrieving songs by music segments are presented, along with multi-feature index structures for searching on different features. The problem of feature extraction is also studied, with a focus on discovering repeating patterns in music objects. The feasibility of the proposed concepts is illustrated through the implementation of a prototype system called Muse."
7,G. Sayeed Choudhury;M. Droetboom;Tim DiLauro;Ichiro Fujinaga;Brian Harrington,Optical Music Recognition System within a Large-Scale Digitization Project.,2000,https://doi.org/10.5281/zenodo.1415730,"G. Sayeed Choudhury, ",""""""
8,Michael Clausen;R. Engelbrecht;D. Meyer;J. Schmitz,PROMS: A Web-based Tool for Searching in Polyphonic Music.,2000,https://doi.org/10.5281/zenodo.1417139,"M. Clausen, Institut f¨ur Informatik V, Universit¨at Bonn;R. Engelbrecht, Institut f¨ur Informatik V, Universit¨at Bonn;D. Meyer, Institut f¨ur Informatik V, Universit¨at Bonn;J. Schmitz, Institut f¨ur Informatik V, Universit¨at Bonn","One major task of a digital music library (DML) is to provide techniques to locate a queried musical pattern in all pieces of music in the database containing that pattern. Existing DMLs work with melody databases relying on score-like information and mainly take into account pitch information. However, we believe that both pitch and rhythm are crucial for recognizing melodies, especially in the context of polyphonic music. PROMS is a web-based computer-music service that aims to design and implement procedures for music search. It is set-oriented and uses single notes as basic objects, specified by onset time, pitch, and duration. The database consists of a sequence of pieces of music in the MIDI format, and a query is a finite set of notes."
9,Dave Cliff;Heppie Freeburn,Exploration of Point-Distribution Models for Similarity-based Classification and Indexing of Polyphonic Music.,2000,https://doi.org/10.5281/zenodo.1416572,"Dave Cliff, Hewlett-Packard Labs;Heppie Freeburn, Hewlett-Packard Labs","Similarity-based classification and indexing of polyphonic music remains a challenge in music information retrieval systems. This paper explores the use of high-order multivariate statistical techniques, specifically point distribution models (PDMs), for similarity-based classification of polyphonic music in digital audio files. The goal is to apply PDMs to musical similarity by creating neural networks that approximate the statistical processing. However, the results so far are inconclusive and negative. The paper encourages further exploration of PDMs in the music retrieval community."
10,Maxime Crochemore;Costas S. Iliopoulos;Yoan J. Pinzón,Finding Motifs with Gaps.,2000,https://doi.org/10.5281/zenodo.1415986,"Maxime Crochemore, Institut Gaspard-Monge, Laboratoire d'informatique, Université de Marne-la-Vallée;Wojciech Rytter, Uniwersytet Warszawski, Banacha 2, 02--097, Warszawa, Poland, and Department of Computer Science, University of Liverpool, Liverpool L69 7ZF, UK.;Costas S. Iliopoulos and Yoan J. Pinzon, Dept. Computer Science, King's College London, London WC2R 2LS, UK, and School of Computing, Curtin University of Technology, GPO Box 1987 U, WA. Australia","This paper focuses on a set of string pattern-matching problems that arise in musical analysis, particularly in musical information retrieval. The paper discusses the flexibility required in score searching, especially in polyphonic music where there may be gaps between events in different voices. The paper presents a mathematical treatment of allowing gaps in the query and the score being searched, represented by the constant α. The paper also defines the problem of matching with gaps and discusses various conditions and variants of the problem. Efficient algorithms and implementations for these variants have been designed."
11,Jon W. Dunn,Beyond VARIATIONS: Creating a Digital Music Library.,2000,https://doi.org/10.5281/zenodo.1415148,"Jon W. Dunn, Indiana University","This presentation focuses on the work being done at Indiana University in the area of digital music libraries, specifically the VARIATIONS system. The VARIATIONS system provides online access to sound recordings from the library's collections, with a focus on musical repertoire central to the teaching mission of the Indiana University School of Music. The collection includes over 6800 sound recording titles, covering a broad range of musical material. Indiana University is embarking on a project to expand the VARIATIONS system and create a Digital Music Library, funded by the National Science Foundation and National Endowment for the Humanities. The project aims to develop applications for music education and research, as well as research in the areas of instruction, usability, and intellectual property rights."
12,Jonathan Foote,ARTHUR: Retrieving Orchestral Music by Long-Term Structure.,2000,https://doi.org/10.5281/zenodo.1416644,"Jonathan Foote, FX Palo Alto Laboratory, Inc.","We introduce an audio retrieval-by-example system for orchestral music. Unlike many other approaches, this system is based on analysis of the audio waveform and does not rely on symbolic or MIDI representations. ARTHUR retrieves audio on the basis of long-term structure, specifically the variation of soft and louder passages. The long-term structure is determined from envelope of audio energy versus time in one or more frequency bands. Similarity between energy profiles is calculated using dynamic programming. Given an example audio document, other documents in a collection can be ranked by similarity of their energy profiles. Experiments are presented for a modest corpus that demonstrate excellent results in retrieving different performances of the same orchestral work, given an example performance or short excerpt as a query."
13,Anastasia Georgaki;Spyros Raptis;Stelios Bakamidis,A Music Interface for Visually Impaired People in the WEDELMUSIC Environment. Design and Architecture.,2000,https://doi.org/10.5281/zenodo.1417291,"Anastasia Georgaki, Institute for Language and Speech Processing, Speech Technology Department;Spyros Raptis, Institute for Language and Speech Processing, Speech Technology Department;Stelios Bakamidis, Institute for Language and Speech Processing, Speech Technology Department","In this poster, the authors present the architecture of a new music interface for blind musicians in the WEDELMUSIC environment. The interface aims to facilitate access to musical databases and allow visually impaired individuals to edit and create musical scores. The architecture includes modules such as a Braille printer, a spoken music interpreter, and various data interpretations and output devices."
14,Michael Good,Representing Music Using XML.,2000,https://doi.org/10.5281/zenodo.1415032,"Michael Good, Recordare","Why does the world need another music representation language? Beyond MIDI describes over 20 different languages or musical codes (Selfridge-Field, 1997). Most commercial music programs have their own internal, proprietary music representation and file format. Music's complexity has led to this proliferation of languages and formats. Sequencers, notation programs, analysis tools, and retrieval tools all need musical information optimized in different ways. Yet no music interchange language has been widely adopted since MIDI. MIDI has contributed to enormous growth in the electronic music industry, but has many well-known limitations for notation, analysis, and retrieval. These include its lack of representation of musical concepts such as rests and enharmonic pitches (distinguishing Db from C#), as well as notation concepts such as stem direction and beaming. Other interchange formats such as NIFF and SMDL overcome these restrictions, but have not been widely adopted. Successful interchange formats such as MIDI and HTML share a common trait that NIFF and SMDL lack. MIDI and HTML skillfully balance simplicity and power. They are simple enough for many people to learn, and powerful enough for many real-world applications. The simplicity makes it easy for software developers to implement the standards and to develop encoding tools for musicians. This helps circumvent the “chicken-and-egg” problem with new formats. XML (Extensible Markup Language) is a World Wide Web Consortium (W3C) recommendation for representing structured data in text, designed for ease of usage over the Internet by a wide variety of applications. XML is a meta-markup language that lets designers and communities develop their own representation languages for different applications. Like HTML and MIDI, it balances simplicity and power in a way that has made it very attractive to software developers. The common base of XML technology lets developers of new languages focus on representation issues instead of low-level software development. All XML-based languages can be processed by a variety of XML tools available from multiple vendors. Since XML files are text files, users of XML files always have generic text-based tools available as a lowest common denominator. XML documents are represented in Unicode, providing support for international score exchange. MusicXML is an XML-based music interchange language. It represents common western musical notation from the 17th century onwards, including both classical and popular music. The language is designed to be extensible to future coverage of early music and less standard 20th and 21st century scores. Non-western musical notations would use a separate XML language. As an interchange language, it is designed to be sufficient, not optimal, for diverse musical applications. MusicXML is not intended to supersede other languages that are optimized for specific musical applications, but to support sharing of musical data between applications. The current MusicXML software runs on Windows. As of September 2000, it reads 100% of the MuseData format plus portions of NIFF and Finale’s Enigma Transportable Files (ETF). It writes to Standard MIDI Files in Format 1, MuseData files, and Sibelius. The NIFF, ETF, and MIDI converters use XML versions of these languages as intermediate structures. MusicXML is defined using an XML Document Type Definition (DTD) at www.musicxml.com/xml.html. XML Schemas address some shortcomings of DTDs, but are not yet a W3C recommendation."
15,Perfecto Herrera-Boyer;Xavier Amatriain;Eloi Batlle;Xavier Serra,Towards Instrument Segmentation for Music Content Description: a Critical Review of Instrument Classification Techniques.,2000,https://doi.org/10.5281/zenodo.1416768,"Perfecto Herrera, Audiovisual Institute - Pompeu Fabra University;Xavier Amatriain, Audiovisual Institute - Pompeu Fabra University;Eloi Batlle, Audiovisual Institute - Pompeu Fabra University;Xavier Serra, Audiovisual Institute - Pompeu Fabra University","A system capable of describing the musical content of any kind of sound file or sound stream, as it is supposed to be done in MPEG7-compliant applications, should provide an account of the different moments where a certain instrument can be listened to. In this paper we concentrate on reviewing the different techniques that have been so far proposed for automatic classification of musical instruments. As most of the techniques to be discussed are usable only in ""solo"" performances we will evaluate their applicability to the more complex case of describing sound mixes. We conclude this survey discussing the necessity of developing new strategies for classifying sound mixes without a priori separation of sound sources."
16,David Huron,Perceptual and Cognitive Applications in Music Information Retrieval.,2000,https://doi.org/10.5281/zenodo.1414794,"David Huron, Cognitive and Systematic Musicology Laboratory, School of Music, Ohio State University","Music librarians and cataloguers have traditionally created indexes for accessing musical works based on standard reference information. However, these standard reference tags have limited applicability in most music-related queries. Music serves a variety of purposes, such as targeting a certain clientele, setting a certain tempo, conveying a certain mood, or motivating a patient. The most useful retrieval indexes for music are those that facilitate searching based on social and psychological functions, focusing on stylistic, mood, and similarity information. Building musical web crawlers that index music-related files will require drawing on research in music perception and cognition, particularly for tasks such as music summarization and mood characterization."
17,Mari Itoh,Subject Search for Music: Quantitative Analysis of Access Point Selection.,2000,https://doi.org/10.5281/zenodo.1414950,"Smiraglia, ",Non-book materials have unique characteristics in subject analysis that influence their information retrieval process. This study aims to explore useful tools for subject search of music scores in an online environment. The purpose of this survey is to comprehend how searchers selected access points for examining what search tools are most effective and necessary for searching music. The survey analyzed transaction logs from an academic library of music and found that more than half of the initial searches were combinations of access points.
18,Özgür Izmirli,Using a Spectral Flatness Based Feature for Audio Segmentation and Retrieval.,2000,https://doi.org/10.5281/zenodo.1416438,"Ozgur Izmirli, Center for Arts and Technology, Department of Mathematics and Computer Science, Connecticut College","A method that utilizes a spectral flatness based tonality feature for segmentation and content-based retrieval of audio is outlined. The method uses the tonality measure which is derived from the discrete bark spectrum as a means of detecting transitions between tonal and noise-like parts of the audio input. Segmentation is performed by determining the times of these transitions, hence providing reference points for search purposes. Search is carried out by pivoting the query information on these reference points. The cumulative distance between the tonality pattern in successive frames of the query and the candidate sound fragments is used as a measure of similarity."
19,Kjell Lemström;Sami Perttu,SEMEX - An efficient Music Retrieval Prototype.,2000,https://doi.org/10.5281/zenodo.1415908,"Kjell Lemström, Department of Computer Science, University of Helsinki;Sami Perttu, Department of Computer Science, University of Helsinki","We present an efficient prototype for music information retrieval. The prototype uses bit-parallel algorithms for locating transposition invariant matches of monophonic query melodies within monophonic or polyphonic music stored in a database. When dealing with monophonic music, we employ a fast approximate bit-parallel algorithm with special edit distance metrics. The fast scanning phase is succeeded by verification where a separate metrics is used for ranking matches. We also offer the possibility to search for exact occurrences of a 'distributed' melody within polyphonic databases via a bit-parallel filtering technique. In our experiments with a database of 2 million musical elements (notes in a monophonic and chords in a polyphonic database) the responses were obtained within one second in both cases. Furthermore, our prototype is capable of using various interval classes in matching, producing more approximation when it is needed."
20,Francis J. Kiernan,Score-based Style Recognition Using Artificial Neural Networks.,2000,https://doi.org/10.5281/zenodo.1416626,"Francis J. Kiernan, Pythagoras Graduate School","The original idea of this research was to develop a system for musicological analysis that could assist in resolving issues of compositional authenticity. The system uses a data extraction engine to gather statistical information from a musical score, and then uses a neural network to form an abstract impression of habitual characteristics within the composition. The system does not aim to model human musical perception. The system was initially developed to explore the authenticity of flute compositions attributed to Frederick II ""The Great"". A rule base was compiled based on information from performers and musicologists, and this rule base was implemented into the system. The methodology involved creating a corpus of score representations in ALMA, using intervallic difference of note relations and horizontal pitch-class snapshots to analyze the tonal contents of each measure. Vertical pitch-class analysis and monitoring the frequency of note occurrence over time were also used. The sequence recognition algorithm checked for recurring interval sequences on the major metric points of the melody."
21,Youngmoo E. Kim;Wei Chai;Ricardo García;Barry Vercoe,Analysis of a Contour-based Representation for Melody.,2000,https://doi.org/10.5281/zenodo.1416760,"Youngmoo E. Kim, Machine Listening Group, MIT Media Lab;Wei Chai, Machine Listening Group, MIT Media Lab;Ricardo Garcia, Machine Listening Group, MIT Media Lab;Barry Vercoe, Machine Listening Group, MIT Media Lab","Identifying a musical work from a melodic fragment is a task that most people are able to accomplish with relative ease. For some time now researchers have worked to give computers this ability as well, as it would be the cornerstone of any query-by-humming system. To accomplish this, it is reasonable to study how humans are able to perform this task, and to assess what features we use to determine melodic similarity. Research has shown that melodic contour is an important feature in determining melodic similarity, but it is also clear that rhythmic information is important as well. The goal of this research is to explore what variation of contour and rhythmic information can result in the most efficient, robust, and scalable representation for melody. We intend for this to be the basis of a query-by-humming system that will be used to test the validity of our proposed representation."
22,Steve Larson,"Searching for Meaning: Melodic Patterns, Combinations, and Embellishments.",2000,https://doi.org/10.5281/zenodo.1415738,"Steve Larson, University of Oregon","I am interested in the search for musical patterns -- not so much because I want to find particular patterns, but because I want to understand musical meaning and I believe that musical meaning is something that listeners create when they relate musical patterns to one another, and when they relate musical patterns to other sorts of patterns. I describe a theory of musical meaning that argues that experienced listeners of tonal music hear musical motion metaphorically, as purposeful action within a dynamic field of musical forces (musical gravity, magnetism, and inertia). That theory has been used to clarify issues in Schenkerian theory, to analyze music in many styles, to improve the training of musicians, to account for experimental results in melodic expectation, to explain striking regularities in published analyses of tonal music, and even to illuminate the phenomenon of ""swing"" in jazz. The assumptions of that theory generate a small set of patterns and pattern combinations. This small set of patterns crops up over and over again in tonal music. Recognizing these patterns and their significance requires seeing how they are embellished in particular pieces. I illustrate these patterns, their combinations and embellishments, and something about their meaning by analyzing several folk songs, including ""Ah, vous dirai-je, Maman"" and Mozart's variations on it. The ubiquity of this small set of patterns raises interesting questions about searching for musical patterns, about the role of computers in information retrieval vs their role in musical artificial intelligence, and about musical meaning. My presentation ends with a series of such questions."
23,Mary Levering,"Intellectual Property Rights in Musical Works: Overview, Digital Library Issues and Related Initiatives.",2000,https://doi.org/10.5281/zenodo.1416786,"Mary Levering, U.S. Copyright Office, Library of Congress","Our nation's Founding Fathers incorporated copyright principles into the U.S. Constitution to foster the creation and dissemination of intellectual works for the public good. The federal copyright law supports these goals by granting creators and owners of musical works an exclusive bundle of rights for limited periods of time. It is important for all potential users, including academics and scholars, to be aware of these rights when using copyrighted musical works in electronic formats. Understanding the range of exclusive rights, statutory limitations, fair use doctrine, authorization requirements, and how to secure permissions efficiently have become increasingly important."
24,Karen Lin;Tim Bell,Integrating Paper and Digital Music Information Systems.,2000,https://doi.org/10.5281/zenodo.1416544,"Karen Lin, University of Canterbury, Christchurch, New Zealand;Tim Bell, University of Canterbury, Christchurch, New Zealand","Active musicians often prefer using paper-based music information retrieval systems over digital ones, despite the advantages of digital tools. In this paper, the authors propose a model that integrates paper and digital domains, offering musicians the benefits of both. They conducted a survey to identify the challenges and potential of working with digital tools, and propose a system that simplifies the process of moving music documents between the two domains using color printing and scanning technology. The model divides the digital state into image data and semantic data."
25,Beth Logan,Mel Frequency Cepstral Coefficients for Music Modeling.,2000,https://doi.org/10.5281/zenodo.1416444,"Beth Logan, Cambridge Research Laboratory","We examine in some detail Mel Frequency Cepstral Coefficients (MFCCs) - the dominant features used for speech recognition - and investigate their applicability to modeling music.In particular, we examine two of the main assumptions of the process of forming MFCCs: the use of the Mel frequency scale to model the spectra; and the use of the Discrete Cosine Transform (DCT) to decorrelate the Mel-spectral vectors. We examine the first assumption in the context of speech/music discrimination. Our results show that the use of the Mel scale for modeling music is at least not harmful for this problem, although further experimentation is needed to verify that this is the optimal scale in the general case. We investigate the second assumption by examining the basis vectors of the theoretically optimal transform to decorrelate music and speech spectral vectors. Our results demonstrate that the use of the DCT to decorrelate vectors is appropriate for both speech and music spectra."
26,Donald MacLellan;Carola Boehm,MuTaTeD'll: A System for Music Information Retrieval of Encoded Music.,2000,https://doi.org/10.5281/zenodo.1417755,"Donald MacLellan, Department of Music, University of Glasgow;Carola Boehm, Department of Music, University of Glasgow","MuTaTeD'II started in November 1999, building on the results of the MuTaTeD project. Its aim is to design and implement a music information retrieval system with delivery/access services for encoded music. The prototype service will provide a user friendly, web-based search/browse/query interface to access musical content."
27,Jeremy Pickens,A Comparison of Language Modeling and Probabilistic Text Information Retrieval Approaches to Monophonic Music Retrieval.,2000,https://doi.org/10.5281/zenodo.1415100,"Jeremy Pickens, Department of Computer Science, University of Massachusetts","With interest in music information retrieval increasing the need for retrieval systems unique to music is also growing. Despite its unique properties music shares many similarities with text. The goal of this paper is to explore some of the capabilities and limitations of current text information retrieval systems as applied to the task of music retrieval. Monophonic music is converted into text and retrieval experiments are run using two different text information retrieval systems in various configurations. Finally, we will discuss whether the techniques applied here are generalizable to the larger problem of polyphonic music retrieval."
28,Perry Roland,XML4MIR: Extensible Markup Language for Music Information Retrieval.,2000,https://doi.org/10.5281/zenodo.1417167,"Perry Roland, University of Virginia",This paper evaluates the role of standards in information exchange and suggests the adoption of XML standards for music representation and meta-data to serve as the basis for music information retrieval.
29,Jochen Schimmelpfennig;Frank Kurth,MCML - Music Contents Markup Language.,2000,https://doi.org/10.5281/zenodo.1415526,"Jochen Schimmelpfennig and Frank Kurth, University of Bonn","We present an XML-based description interface for various types of musical contents - MCML, Music Contents Markup Language. An application of MCML currently developed within our group is a music browser system which enables a content based navigation in digital music files. Another major application of a music contents annotation interface is the description and handling of query results to digital music libraries."
30,Eleanor Selfridge-Field,What Motivates a Musical Query?.,2000,https://doi.org/10.5281/zenodo.1415970,,The abstract is not available in this context.
31,Perry R. Cook;George Tzanetakis,Audio Information Retrieval (AIR) Tools.,2000,https://doi.org/10.5281/zenodo.1416716,,""""""
32,Alexandra L. Uitdenbogerd,"Music IR: Past, Present, and Future.",2000,https://doi.org/10.5281/zenodo.1417545,"Alexandra L. Uitdenbogerd, Department of Computer Science, RMIT University;Abhijit Chattaraj, Department of Computer Science, RMIT University;Justin Zobel, Department of Computer Science, RMIT University","Music Information Retrieval (MIR) has a long history, dating back to the 1960s. It is rooted in information retrieval, musicology, and music psychology. Over the years, various techniques have been applied to measure stylistic parameters of composers and general similarity of musical works. The current trend in MIR research is the development of systems that allow the location of answers to queries presented as hummed melodies or entered in some other way. However, comparing systems is challenging due to the lack of a common data set, queries, or relevance judgments. MIR systems can be evaluated similarly to other systems, with the definition of queries, answers, and relevance depending on the user's needs."
33,Alexandra L. Uitdenbogerd;Justin Zobel,Music Ranking Techniques Evaluated.,2000,https://doi.org/10.5281/zenodo.1414990,"Alexandra L. Uitdenbogerd, Department of Computer Science, RMIT University;Justin Zobel, Department of Computer Science, RMIT University","Several techniques have been proposed for matching melody queries to stored music. In this paper, we explore a broader range of n-gram techniques and test them with both manual queries and queries automatically extracted from MIDI files. Our experiments show that alternative n-gram matching techniques, such as simply counting the number of 5-grams in common between query and stored piece of music, can be as effective as local alignment. N-grams are particularly effective for short and manual queries, while local alignment is superior for automatic queries."
34,Thomas von Schroeter;Shyamala Doraisamy;Stefan M. Rüger,From Raw Polyphonic Audio to Locating Recurring Themes.,2000,https://doi.org/10.5281/zenodo.1416124,"Thomas von Schroeter, T H Huxley School of Environment, Earth Sciences and Engineering Imperial College of Science, Technology and Medicine Prince Consort Road, London SW7 2BZ, England;Shyamala Doraisamy, Department of Multimedia Faculty of Computer Science and Information Technology University Putra Malaysia, 43400 UPM Serdang, Selangor D.E., Malaysia;Stefan M R¨uger, Department of Computing Imperial College of Science, Technology and Medicine 180 Queen’s Gate, London SW7 2BZ, England",We present research studies of two related strands in content-based music retrieval: the automatic transcription of raw audio from a single polyphonic instrument with discrete pitch (eg piano) and the location of recurring themes from a Humdrum score.
