Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,Eric Allamanche,Content-based Identification of Audio Material Using MPEG-7 Low Level Description.,2001,https://doi.org/10.5281/zenodo.1417853,"Eric Allamanche, Fraunhofer IIS-A;Bernhard Fröba, Fraunhofer IIS-A;Jürgen Herre, Fraunhofer IIS-A;Thorsten Kastner, Fraunhofer IIS-A;Oliver Hellmuth, Fraunhofer IIS-A;Markus Cremer, Fraunhofer IIS-A / AEMT","Along with investigating similarity metrics between audio material, the topic of robust matching of pairs of audio content has gained wide interest recently. In particular, if this matching process is carried out using a compact representation of the audio content (""audio fingerprint""), it is possible to identify unknown audio material by means of matching it to a database with the fingerprints of registered works. This paper presents a system for reliable, fast and robust identification of audio material which can be run on the resources provided by today's standard computing platforms. The system is based on a general pattern recognition paradigm and exploits low level signal features standardized within the MPEG-7 framework, thus enabling interoperability on a world-wide scale. Compared to similar systems, particular attention is given to issues of robustness with respect to common signal distortions, i.e. recognition performance for processed/modified audio signals. The system's current performance figures are benchmarked for a range of real-world signal distortions, including low bitrate coding and transmission over an acoustic channel. A number of interesting applications are discussed."
1,Jérôme Barthélemy,Figured Bass and Tonality Recognition.,2001,https://doi.org/10.5281/zenodo.1417161,"Jerome Barthélemy, Ircam;Alain Bonardi, Ircam","In the course of the WedelMusic project, the authors are implementing retrieval engines based on musical content extracted from a musical score. This includes main melodic motives, harmony, and tonality. The paper reviews previous research in harmonic analysis of tonal music and presents a method for automated harmonic analysis based on the extraction of a figured bass. The figured bass is determined using a template-matching algorithm, and tonality recognition is addressed using a simple algorithm based on the figured bass. The limitations of the method are discussed, and results are compared to previous research. Potential uses for Music Information Retrieval are also discussed."
2,William P. Birmingham,MUSART: Music Retrieval Via Aural Queries.,2001,https://doi.org/10.5281/zenodo.1415810,"William P. Birmingham, University of Michigan;Roger B. Dannenberg, Carnegie Mellon University;Gregory H. Wakefield, University of Michigan;Mark Bartsch, University of Michigan;David Bykowski, University of Michigan;Dominic Mazzoni, University of Michigan;Colin Meek, University of Michigan;Maureen Mellody, University of Michigan;William Rand, University of Michigan","MUSART is a research project developing and studying new techniques for music information retrieval. The MUSART architecture uses a variety of representations to support multiple search modes. Progress is reported on the use of Markov modeling, melodic contour, and phonetic streams for music retrieval. To enable large-scale databases and more advanced searches, musical abstraction is studied. The MME subsystem performs theme extraction, and two other analysis systems are described that discover structure in audio representations of music. Theme extraction and structure analysis promise to improve search quality and support better browsing and “audio thumbnailing.” Integration of these components within a single architecture will enable scientific comparison of different techniques and, ultimately, their use in combination for improved performance and functionality."
3,Arbee L. P. Chen,Building a Platform for Performance Study of Various Music Information Retrieval Approaches.,2001,https://doi.org/10.5281/zenodo.1414822,"Jia-Lien Hsu, Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan 300, R.O.C.;Arbee L.P. Chen, Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan 300, R.O.C.","In this paper, we describe the Ultima project which aims to construct a platform for evaluating various approaches of music information retrieval. Three approaches with the corresponding tree-based, list-based, and (n-gram+tree)-based index structures are implemented. A series of experiments has been carried out. With the support of the experiment results, we compare the performance of index construction and query processing of the three approaches and give a summary for efficient content-based music information retrieval."
4,Roger B. Dannenberg,Music Information Retrieval as Music Understanding.,2001,https://doi.org/10.5281/zenodo.1418263,"Roger B. Dannenberg, Carnegie Mellon University","Much of the difficulty in Music Information Retrieval can be traced to problems of good music representations, understanding music structure, and adequate models of music perception. In short, the central problem of Music Information Retrieval is Music Understanding, a topic that also forms the basis for much of the work in the fields of Computer Music and Music Perception. It is important for all of these fields to communicate and share results. With this goal in mind, the author’s work on Music Understanding in interactive systems, including computer accompaniment and style recognition, is discussed."
5,Shyamala Doraisamy,An Approach Towards A Polyphonic Music Retrieval System.,2001,https://doi.org/10.5281/zenodo.1415622,"Shyamala Doraisamy, Dept. of Computing, Imperial College;Stefan M Rüger, Dept. of Computing, Imperial College","Most research on music retrieval systems is based on monophonic musical sequences. In this paper, we investigate techniques for a full polyphonic music retrieval system. A method for indexing polyphonic music data files using the pitch and rhythm dimensions of music information is introduced. Our strategy is to use all combinations of monophonic musical sequences from polyphonic music data. ‘Musical words’ are then obtained using the n-gram approach enabling text retrieval methods to be used for polyphonic music retrieval. Here we extend the n-gram technique to encode rhythmic as well as interval information, using the ratios of onset time differences between two adjacent pairs of pitch events. In studying the precision in which intervals are to be represented, a mapping function is formulated in dividing intervals into smaller classes. To overcome the quantisation problems that arise with using rhythmic information from performance data, an encoding mechanism using ratio bins is also adopted. We present results from retrieval experiments with a database of 3096 polyphonic pieces."
6,Matthew J. Dovey,A Technique for Regular Expression Style Searching in Polyphonic Music.,2001,https://doi.org/10.5281/zenodo.1416140,"Matthew J. Dovey, Visiting Research Fellow, Dept. of Computer Science, Kings College, London","This paper discusses ongoing investigative work on integrating two systems as part of the NSF/JISC funded OMRAS project into polyphonic searching of music. It describes a simple and efficient algorithm for locating a polyphonic query within a large polyphonic text and ways in which this algorithm can be modified to allow more freedom in how a match is made, allowing queries involving polyphonic regular expressions to be located in the text."
7,Michael Droettboom,Expressive and Efficient Retrieval of Symbolic Musical Data.,2001,https://doi.org/10.5281/zenodo.1417741,"Michael Droettboom, The Peabody Institute, The Johns Hopkins University;Ichiro Fujinaga, The Peabody Institute, The Johns Hopkins University;Karl MacMillan, The Peabody Institute, The Johns Hopkins University;Mark Patton, Digital Knowledge Center, Milton S. Eisenhower Library, The Johns Hopkins University;James Warner, Digital Knowledge Center, Milton S. Eisenhower Library, The Johns Hopkins University;G. Sayeed Choudhury, Digital Knowledge Center, Milton S. Eisenhower Library, The Johns Hopkins University;Tim DiLauro, Digital Knowledge Center, Milton S. Eisenhower Library, The Johns Hopkins University","The ideal content-based musical search engine for large corpora must be both expressive enough to meet the needs of a diverse user base and efficient enough to perform queries in a reasonable amount of time. In this paper, we present such a system, based on an existing advanced natural language search engine. In our design, musically meaningful searching is simply a special case of more general search techniques. This approach has allowed us to create an extremely powerful and fast search engine with minimal effort."
8,Adriane Durey,Melody Spotting Using Hidden Markov Models.,2001,https://doi.org/10.5281/zenodo.1415680,"Adriane Swalm Durey, Center for Signal and Image Processing, School of Electrical and Computer Engineering, Georgia Institute of Technology;Mark A. Clements, Center for Signal and Image Processing, School of Electrical and Computer Engineering, Georgia Institute of Technology","Melody spotting is an important task in music information retrieval. In this paper, we propose a melody spotting system based on hidden Markov models (HMMs). We use a set of acoustic features to model the melodic patterns in music recordings. Experimental results show that our proposed system achieves high accuracy in detecting the presence of a melody in music recordings."
9,Ludger Hofmann-Engl,Towards a Cognitive Model of Melodic Similarity.,2001,https://doi.org/10.5281/zenodo.1417359,"Ludger Hofmann-Engl, Keele University UK","In recent years, there has been increased interest in melodic similarity due to the importance of music information retrieval (MIR). However, little attention has been paid to cognitive or perceptual aspects of melodic similarity. This paper proposes a cognitive model of melodic similarity, focusing on the pitch aspect and suggesting the use of a term called ""meloton"" instead of pitch. The paper suggests approaching melotonic similarity from a transformational angle, where transformations are executed as reflections and translations. The paper concludes that melotonic similarity is a multi-faceted phenomenon that requires the development of flexible models."
10,Holger H. Hoos;Kai Renz;Marko Görg,GUIDO/MIR - an Experimental Musical Information Retrieval System based on GUIDO Music Notation.,2001,https://doi.org/10.5281/zenodo.1417517,"Holger H. Hoos, ",""""""
11,Andreas Kornstädt,The JRing System for Computer-Assisted Musicological Analysis.,2001,https://doi.org/10.5281/zenodo.1416100,"Andreas Kornstädt, Arbeitsbereich Softwaretechnik (SWT), Fachbereich Informatik, Universität Hamburg","Among other factors, high complexity and mandatory expert computer knowledge make many music IR and music analysis systems unsuitable for the majority of largely computer-illiterate musicologists. The JRing system offers highly flexible yet intuitively usable search and comparison operations to aid musicologists during score analysis. This paper discusses the requirement analysis that led to JRing’s inception, its IR tools and graphical user interface plus the kind of musical material it works on and the Humdrum-based technical realization of IR operations."
12,Adam Lindsay;Youngmoo Kim,"Adventures in Standardization, or How We Learned to Stop Worrying and Love MPEG-7.",2001,https://doi.org/10.5281/zenodo.1418071,"Adam Lindsay, Computing Department, Lancaster University;Youngmoo Kim, MIT Media Lab","The authors give a brief account of their combined 7+ years in multimedia standardization, namely in the MPEG arena. They discuss specifics on musical content description in MPEG-7 Audio and other items relevant to Music Information Retrieval among the MPEG-7 Multimedia Description Schemes. In the presentation, they will give a historical overview of the MPEG-7 standard, its motivations, and what led to its current state."
13,Colin Meek,Thematic Extractor.,2001,https://doi.org/10.5281/zenodo.1414828,"Colin Meek, University of Michigan;William P. Birmingham, University of Michigan","We have created a system that identifies musical keywords or themes. The system searches for all patterns composed of melodic repetition in a piece. This process uncovers a large number of patterns, which are then filtered and rated according to perceptually significant characteristics. The top-ranked patterns correspond to important thematic or motivic musical content. The system operates across a broad range of styles and relies on no meta-data, allowing it to independently and efficiently catalog multimedia data."
14,Takuichi Nishimura,Music Signal Spotting Retrieval by a Humming Query Using Start Frame Feature Dependent Continuous Dynamic Programming.,2001,https://doi.org/10.5281/zenodo.1417191,"Takuichi Nishimura, Real World Computing Partnership / National Institute of Advanced Industrial Science and Technology;J. Xin Zhang, Media Drive Co.;Hiroki Hashiguchi, Real World Computing Partnership;Masataka Goto, National Institute of Advanced Industrial Science and Technology / PRESTO, JST;Junko Takita, Mathematical Systems Inc.;Ryuichi Oka, Real World Computing Partnership","We have developed a music retrieval method that takes a humming query and finds similar audio intervals (segments) in a music audio database. This method can also address a personally recorded video database containing melodies in its audio track. Our previous retrieving method took too much time to retrieve a segment: for example, a 60-minute database required about 10-minute computation on a personal computer. In this paper, we propose a new high-speed retrieving method, called start frame feature dependent continuous Dynamic Programming, which assumes that the pitch of the interval start point is accurate. Test results show that the proposed method reduces retrieval time to about 1/40 of present methods."
15,Donncha Ó Maidín,Score Processing For MIR.,2001,https://doi.org/10.5281/zenodo.1416442,"Donncha S. Ó Maidín, Centre for Computational Musicology and Computer Music, Department of Computer Science and Information Systems, University of Limerick;Margaret Cahill, Centre for Computational Musicology and Computer Music, Department of Computer Science and Information Systems, University of Limerick","The focus of this paper is on the design and use of a music score representation. The structure of the representation is discussed and illustrated with sample algorithms, including some from music information retrieval. The score representation was designed for the development of general algorithms and applications. The common container-iterator paradigm is used, in which the score is modelled as a container of objects, such as clefs, key signatures, time signatures, notes, rests and barlines. Access to objects within the score is achieved through iterators. These iterators provide the developer with a mechanism for accessing the information content of the score. The iterators are designed to achieve a high level of data hiding, so that the user is shielded from the substantial underlying complexity of score representation, while at the same time, having access to the score’s full information content."
16,François Pachet,A Naturalist Approach to Music File Name Analysis.,2001,https://doi.org/10.5281/zenodo.1415856,"François Pachet, Sony CSL-Paris;Damien Laigre, Sony CSL-Paris","Music title identification is a key ingredient of content-based electronic music distribution. Because of the lack of standards in music identification – or the lack of enforcement of existing standards – there is a huge amount of unidentified music files in the world. We propose here an identification mechanism that exploits the information possibly contained in the file name itself. We study large corpora of files whose names are decided by humans without particular constraints other than readability, and draw various hypotheses concerning the natural syntaxes that emerge from these corpora. A central hypothesis is the local syntactic consistency, which claims that file name syntaxes, whatever they are, are locally consistent within clusters of related music files. These heuristics allow to parse successfully file names without knowing their syntax a priori, using statistical measures on clusters of files, rather than on parsing files on a strict individual basis. Based on these validated hypothesis we propose a heuristics-based parsing system and illustrate it in the context of an Electronic Music Distribution project."
17,Emanuele Pollastri,An Audio Front End for Query-by-Humming Systems.,2001,https://doi.org/10.5281/zenodo.1415056,"Goffredo Haus, L.I.M.-Laboratorio di Informatica Musicale, Dipartimento di Scienze dell’Informazione, Università Statale di Milano;Emanuele Pollastri, L.I.M.-Laboratorio di Informatica Musicale, Dipartimento di Scienze dell’Informazione, Università Statale di Milano","In this paper, the authors address the problem of processing audio signals in the context of query-by-humming systems. They aim to develop a front end dedicated to the symbolic translation of voice into a sequence of pitch and duration pairs. The authors propose a novel post-processing stage to adjust the intonation of the user, based on a relative scale estimated from the most frequent errors made by singers. The front end has been tested with five subjects and four short tunes, achieving a detection rate of approximately 90% of right notes. The authors also discuss issues regarding the best representation for the translated symbols."
18,Christopher Raphael,Automated Rhythm Transcription.,2001,https://doi.org/10.5281/zenodo.1416122,"Christopher Raphael, Department of Mathematics and Statistics, University of Massachusetts, Amherst","We present a technique that, given a sequence of musical note onset times, performs simultaneous identification of the notated rhythm and the variable tempo associated with the times. Our formulation is probabilistic: We develop a stochastic model for the interconnected evolution of a rhythm process, a tempo process, and an observable process. This model allows the globally optimal identification of the most likely rhythm and tempo sequence, given the observed onset times. We demonstrate applications to a sequence of times derived from a sampled audio file and to MIDI data."
19,Josh Reiss,Efficient Multidimensional Searching Routines.,2001,https://doi.org/10.5281/zenodo.1415546,"Josh Reiss, Department of Electronic Engineering, Queen Mary, University of London;Jean-Julien Aucouturier, Sony Computer Science Laboratory;Mark Sandler, Department of Electronic Engineering, Queen Mary, University of London","The problem of Music Information Retrieval can often be formalized as “searching for multidimensional trajectories”. In this work, the authors examine and benchmark different methods for low dimensional searches, particularly queries concerning a single vector. They propose the use of KD-Trees for multidimensional near-neighbor searching and show that KD-Trees are optimized for multidimensional data and preferred over other methods such as K-Tree, box-assisted sort, and multidimensional quick-sort."
20,Richard P. Smiraglia,Musical Works as Information Retrieval Entities: Epistemological Perspectives.,2001,https://doi.org/10.5281/zenodo.1416512,"Richard P. Smiraglia, Palmer School of Library and Information Science, Long Island University","Musical works form a key entity for music information retrieval. Works contain representations of recorded knowledge and function to preserve and disseminate the parameters of a culture. A musical work is an intellectual sonic conception that takes documentary form in various instantiations. Epistemology for documentary analysis provides key perceptual information about the objects of knowledge organization. Musical works are carriers of knowledge, representing deliberately-constructed packages of both rational and empirical evidence of human knowledge. Semiotic analysis suggests a variety of cultural and social roles for works. Musical works, defined as entities for information retrieval, are seen to constitute sets of varying instantiations of abstract creations. Variability over time is an innate aspect of the set of all instantiations of a musical work, leading to complexity in the information retrieval domain."
21,George Tzanetakis,Automatic Musical Genre Classification of Audio Signals.,2001,https://doi.org/10.5281/zenodo.1415058,"George Tzanetakis, Computer Science Department;Georg Essl, Computer Science Dep.;Perry Cook, Computer Science and Music Dep.","Musical genres are categorical descriptions used to describe music and are important for music information retrieval. Traditionally, genre categorization for audio has been done manually. In this work, algorithms for automatic genre categorization of audio signals are proposed. The algorithms use features for representing texture, instrumentation, rhythmic structure, and strength. The performance of these feature sets has been evaluated using real-world audio collections. Based on the automatic genre classification, two graphical user interfaces for browsing and interacting with large audio collections have been developed."
