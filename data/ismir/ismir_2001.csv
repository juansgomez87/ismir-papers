Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,Eric Allamanche,Content-based Identification of Audio Material Using MPEG-7 Low Level Description.,2001,https://doi.org/10.5281/zenodo.1417853,Eric Allamanche+Fraunhofer IIS-A>DEU>facility;Bernhard Fröba+Fraunhofer IIS-A>DEU>facility;Jürgen Herre+Fraunhofer IIS-A>DEU>facility;Thorsten Kastner+Fraunhofer IIS-A>DEU>facility;Oliver Hellmuth+Fraunhofer IIS-A>DEU>facility;Markus Cremer+Fraunhofer IIS-A / AEMT>DEU>facility,"""Along with investigating similarity metrics between audio material, the topic of robust matching of pairs of audio content has gained wide interest recently. In particular, if this matching process is carried out using a compact representation of the audio content ('audio fingerprint'), it is possible to identify unknown audio material by means of matching it to a database with the fingerprints of registered works. This paper presents a system for reliable, fast and robust identification of audio material which can be run on the resources provided by today's standard computing platforms. The system is based on a general pattern recognition paradigm and exploits low level signal features standardized within the MPEG-7 framework, thus enabling interoperability on a world-wide scale. Compared to similar systems, particular attention is given to issues of robustness with respect to common signal distortions, i.e. recognition performance for processed/modified audio signals. The system's current performance figures are benchmarked for a range of real-world signal distortions, including low bitrate coding and transmission over an acoustic channel. A number of interesting applications are discussed."""
1,Jérôme Barthélemy,Figured Bass and Tonality Recognition.,2001,https://doi.org/10.5281/zenodo.1417161,Jerome Barthélemy+Ircam>FRA>facility;Alain Bonardi+Ircam>FRA>facility,"In the course of the WedelMusic project [15], we are currently implementing retrieval engines based on musical content automatically extracted from a musical score. By musical content, we mean not only main melodic motives, but also harmony, or tonality. In this paper, we first review previous research in the domain of harmonic analysis of tonal music. We then present a method for automated harmonic analysis of a music score based on the extraction of a figured bass. The figured bass is determined by means of a template-matching algorithm, where templates for chords can be entirely and easily redefined by the end-user. We also address the problem of tonality recognition with a simple algorithm based on the figured bass. Limitations of the method are discussed. Results are shown and compared to previous research. Finally, potential uses for Music Information Retrieval are discussed."
2,William P. Birmingham,MUSART: Music Retrieval Via Aural Queries.,2001,https://doi.org/10.5281/zenodo.1415810,William P. Birmingham+University of Michigan>USA>education;Roger B. Dannenberg+Carnegie Mellon University>USA>education;Gregory H. Wakefield+University of Michigan>USA>education;Mark Bartsch+University of Michigan>USA>education;David Bykowski+University of Michigan>USA>education;Dominic Mazzoni+University of Michigan>USA>education;Colin Meek+University of Michigan>USA>education;Maureen Mellody+University of Michigan>USA>education;William Rand+University of Michigan>USA>education,"MUSART is a research project developing and studying new techniques for music information retrieval. The MUSART architecture uses a variety of representations to support multiple search modes. Progress is reported on the use of Markov modeling, melodic contour, and phonetic streams for music retrieval. To enable large-scale databases and more advanced searches, musical abstraction is studied. The MME subsystem performs theme extraction, and two other analysis systems are described that discover structure in audio representations of music. Theme extraction and structure analysis promise to improve search quality and support better browsing and “audio thumbnailing.” Integration of these components within a single architecture will enable scientific comparison of different techniques and, ultimately, their use in combination for improved performance and functionality."
3,Arbee L. P. Chen,Building a Platform for Performance Study of Various Music Information Retrieval Approaches.,2001,https://doi.org/10.5281/zenodo.1414822,Jia-Lien Hsu+National Tsing Hua University>TWN>education|Unknown>Unknown>Unknown;Arbee L. P. Chen+National Tsing Hua University>TWN>education|Unknown>Unknown>Unknown,"In this paper, we describe the Ultima project which aims to construct a platform for evaluating various approaches of music information retrieval. Three approaches with the corresponding tree-based, list-based, and (n-gram+tree)-based index structures are implemented. A series of experiments has been carried out. With the support of the experiment results, we compare the performance of index construction and query processing of the three approaches and give a summary for efficient content-based music information retrieval."
4,Roger B. Dannenberg,Music Information Retrieval as Music Understanding.,2001,https://doi.org/10.5281/zenodo.1418263,Roger B. Dannenberg+Carnegie Mellon University>USA>education,"Much of the difficulty in Music Information Retrieval can be traced to problems of good music representations, understanding music structure, and adequate models of music perception. In short, the central problem of Music Information Retrieval is Music Understanding, a topic that also forms the basis for much of the work in the fields of Computer Music and Music Perception. It is important for all of these fields to communicate and share results. With this goal in mind, the author’s work on Music Understanding in interactive systems, including computer accompaniment and style recognition, is discussed."
5,Shyamala Doraisamy,An Approach Towards A Polyphonic Music Retrieval System.,2001,https://doi.org/10.5281/zenodo.1415622,Shyamala Doraisamy+Imperial College>GBR>education|Imperial College>GBR>education;Stefan M Rüger+Imperial College>GBR>education|Imperial College>GBR>education,"Most research on music retrieval systems is based on monophonic musical sequences. In this paper, we investigate techniques for a full polyphonic music retrieval system. A method for indexing polyphonic music data files using the pitch and rhythm dimensions of music information is introduced. Our strategy is to use all combinations of monophonic musical sequences from polyphonic music data. ‘Musical words’ are then obtained using the n-gram approach enabling text retrieval methods to be used for polyphonic music retrieval. Here we extend the n-gram technique to encode rhythmic as well as interval information, using the ratios of onset time differences between two adjacent pairs of pitch events. In studying the precision in which intervals are to be represented, a mapping function is formulated in dividing intervals into smaller classes. To overcome the quantisation problems that arise with using rhythmic information from performance data, an encoding mechanism using ratio bins is also adopted. We present results from retrieval experiments with a database of 3096 polyphonic pieces."
6,Matthew J. Dovey,A Technique for Regular Expression Style Searching in Polyphonic Music.,2001,https://doi.org/10.5281/zenodo.1416140,Matthew J. Dovey+Kings College London>GBR>education,"This paper discussed some of the ongoing investigative work on integrating these two systems conducted as part of the NSF/JISC funded OMRAS (Online Music Retrieval and Searching) project into polyphonic searching of music. It describes a simple and efficient “piano-roll” based algorithm for locating a polyphonic query within a large polyphonic text. It then describes ways in which this algorithm can be modified without affecting the performance to allow more freedom in the how a match is made, allowing queries which involve something akin to polyphonic regular expressions to be located in the text."
7,Michael Droettboom,Expressive and Efficient Retrieval of Symbolic Musical Data.,2001,https://doi.org/10.5281/zenodo.1417741,Michael Droettboom+The Peabody Institute The Johns Hopkins University>USA>education;Ichiro Fujinaga+The Peabody Institute The Johns Hopkins University>USA>education;Karl MacMillan+The Peabody Institute The Johns Hopkins University>USA>education;Mark Patton+Milton S. Eisenhower Library The Johns Hopkins University>USA>education;James Warner+Milton S. Eisenhower Library The Johns Hopkins University>USA>education;G. Sayeed Choudhury+Milton S. Eisenhower Library The Johns Hopkins University>USA>education;Tim DiLauro+Milton S. Eisenhower Library The Johns Hopkins University>USA>education,"The ideal content-based musical search engine for large corpora must be both expressive enough to meet the needs of a diverse user base and efficient enough to perform queries in a reasonable amount of time. In this paper, we present such a system, based on an existing advanced natural language search engine. In our design, musically meaningful searching is simply a special case of more general search techniques. This approach has allowed us to create an extremely powerful and fast search engine with minimal effort."
8,Adriane Durey,Melody Spotting Using Hidden Markov Models.,2001,https://doi.org/10.5281/zenodo.1415680,Adriane Swalm Durey+Georgia Institute of Technology>USA>education|Center for Signal and Image Processing>USA>facility;Mark A. Clements+Georgia Institute of Technology>USA>education|Center for Signal and Image Processing>USA>facility,""""""
9,Ludger Hofmann-Engl,Towards a Cognitive Model of Melodic Similarity.,2001,https://doi.org/10.5281/zenodo.1417359,Ludger Hofmann-Engl+Keele University>GBR>education,"In recent years the interest in melodic similarity has mushroomed mainly due to the increased importance of music information retrieval (MIR). A great number of similarity models and algorithms have been developed, but little or no attention has been paid to cognitive or perceptual aspects to the issue at hand. Questions, about the relevant parameters and the appropriate implementation are under-researched as are experimental data. This paper focuses on the pitch aspect of melodic similarity, scrutinising the term pitch replacing it by a less ambivalent and overused term, which we will call meloton. Based on the term meloton the paper suggests to approach the issue of ‘melotonic’ similarity from a transformational angle, where transformations are executed as reflections and translations. ‘Melotonic’ similarity then is seen as related to the transformation process in form of a transpositional and interval vector. Finally, melotonic similarity as portrait in a psychological context emerges as a multi-facet phenomenon requiring the development of flexible models."
10,Holger H. Hoos;Kai Renz;Marko Görg,GUIDO/MIR - an Experimental Musical Information Retrieval System based on GUIDO Music Notation.,2001,https://doi.org/10.5281/zenodo.1417517,Holger H. Hoos+University of British Columbia>CAN>education;Kai Renz+Technische Universität Darmstadt>DEU>education;Marko Görg+Unknown>Unknown>Unknown,"Musical databases are growing in number, size, and complexity, and they are becoming increasingly relevant for a broad range of academic as well as commercial applications. The features and performance of musical database systems critically depend on two factors: The nature and representation of the information stored in the database, and the search and retrieval mechanisms available to the user. In this paper, we present an experimental database and retrieval system for score-level musical information based on GUIDO Music Notation as the underlying music representation. We motivate and describe the database design as well as the flexible and efficient query and retrieval mechanism, a query-by-example technique based on probabilistic matching over a clustered dataset. This approach has numerous advantages, and based on experience with a first, experimental implementation, we believe it provides a solid foundation for powerful, efficient, and usable database and retrieval systems for structured musical information."
11,Andreas Kornstädt,The JRing System for Computer-Assisted Musicological Analysis.,2001,https://doi.org/10.5281/zenodo.1416100,Andreas Kornstädt+Universität Hamburg>DEU>education,"Among other factors, high complexity and mandatory expert computer knowledge make many music IR and music analysis systems unsuitable for the majority of largely computer-illiterate musicologists. The JRing system offers highly flexible yet intuitively usable search and comparison operations to aid musicologists during score analysis. This paper discusses the requirement analysis that led to JRing’s inception, its IR tools and graphical user interface plus the kind of musical material it works on and the Humdrum-based technical realization of IR operations."
12,Adam Lindsay;Youngmoo Kim,"Adventures in Standardization, or How We Learned to Stop Worrying and Love MPEG-7.",2001,https://doi.org/10.5281/zenodo.1418071,Adam Lindsay+Lancaster University>GBR>education;Youngmoo Kim+MIT Media Lab>USA>facility,"The authors give a brief account of their combined 7+ years in multimedia standardization, namely in the MPEG arena. They discuss specifics on musical content description in MPEG-7 Audio and other items relevant to Music Information Retrieval among the MPEG-7 Multimedia Description Schemes. In the presentation, they will give a historical overview of the MPEG-7 standard, its motivations, and what led to its current state."
13,Colin Meek,Thematic Extractor.,2001,https://doi.org/10.5281/zenodo.1414828,Colin Meek+University of Michigan>USA>education;William P. Birmingham+University of Michigan>USA>education,"We have created a system that identifies musical keywords or themes. The system searches for all patterns composed of melodic (intervallic for our purposes) repetition in a piece. This process generally uncovers a large number of patterns, many of which are either uninteresting or only superficially important. Filters reduce the number or prevalence, or both, of such patterns. Patterns are then rated according to perceptually significant characteristics. The top-ranked patterns correspond to important thematic or motivic musical content, as has been verified by comparisons with published musical thematic catalogs. The system operates robustly across a broad range of styles, and relies on no meta-data on its input, allowing it to independently and efficiently catalog multimedia data."
14,Takuichi Nishimura;Hiroki Hashiguchi;Junko Takita;J. Xin Zhang;Masataka Goto;Ryuichi Oka,Music Signal Spotting Retrieval by a Humming Query Using Start Frame Feature Dependent Continuous Dynamic Programming.,2001,https://doi.org/10.5281/zenodo.1417191,Takuichi Nishimura+Real World Computing Partnership>JPN>facility|National Institute of Advanced Industrial Science and Technology>JPN>facility;J. Xin Zhang+Media Drive Co.>JPN>company;Hiroki Hashiguchi+Real World Computing Partnership>JPN>facility;Masataka Goto+National Institute of Advanced Industrial Science and Technology>JPN>facility;Junko Takita+Mathematical Systems Inc.>JPN>company;Ryuichi Oka+Real World Computing Partnership>JPN>facility,"We have developed a music retrieval method that takes a humming query and finds similar audio intervals (segments) in a music audio database. This method can also address a personally recorded video database containing melodies in its audio track. Our previous retrieving method took too much time to retrieve a segment: for example, a 60-minute database required about 10-minute computation on a personal computer. In this paper, we propose a new high-speed retrieving method, called start frame feature dependent continuous Dynamic Programming, which assumes that the pitch of the interval start point is accurate. Test results show that the proposed method reduces retrieval time to about 1/40 of present methods."
15,Donncha Ó Maidín,Score Processing For MIR.,2001,https://doi.org/10.5281/zenodo.1416442,Donncha S. Ó Maidín+University of Limerick>IRL>education;Margaret Cahill+University of Limerick>IRL>education,"The focus of this paper is on the design and use of a music score representation. The structure of the representation is discussed and illustrated with sample algorithms, including some from music information retrieval. The score representation was designed for the development of general algorithms and applications. The common container-iterator paradigm is used, in which the score is modelled as a container of objects, such as clefs, key signatures, time signatures, notes, rests and barlines. Access to objects within the score is achieved through iterators. These iterators provide the developer with a mechanism for accessing the information content of the score. The iterators are designed to achieve a high level of data hiding, so that the user is shielded from the substantial underlying complexity of score representation, while at the same time, having access to the score’s full information content."
16,François Pachet,A Naturalist Approach to Music File Name Analysis.,2001,https://doi.org/10.5281/zenodo.1415856,François Pachet+Sony CSL-Paris>FRA>company;Damien Laigre+Sony CSL-Paris>FRA>company,"Music title identification is a key ingredient of content-based electronic music distribution. Because of the lack of standards in music identification – or the lack of enforcement of existing standards – there is a huge amount of unidentified music files in the world. We propose here an identification mechanism that exploits the information possibly contained in the file name itself. We study large corpora of files whose names are decided by humans without particular constraints other than readability, and draw various hypotheses concerning the natural syntaxes that emerge from these corpora. A central hypothesis is the local syntactic consistency, which claims that file name syntaxes, whatever they are, are locally consistent within clusters of related music files. These heuristics allow to parse successfully file names without knowing their syntax a priori, using statistical measures on clusters of files, rather than on parsing files on a strict individual basis. Based on these validated hypothesis we propose a heuristics-based parsing system and illustrate it in the context of an Electronic Music Distribution project."
17,Emanuele Pollastri,An Audio Front End for Query-by-Humming Systems.,2001,https://doi.org/10.5281/zenodo.1415056,Goffredo Haus+Università Statale di Milano>ITA>education;Emanuele Pollastri+Università Statale di Milano>ITA>education,"In this paper, the problem of processing audio signals is addressed in the context of query-by-humming systems. Since singing is naturally used as input, we aim to develop a front end dedicated to the symbolic translation of voice into a sequence of pitch and duration pairs. This operation is crucial for the effectiveness of searching for music by melodic similarity. In order to identify and segment a tune, well-known signal processing techniques are applied to the singing voice. After detecting pitch, a novel post-processing stage is proposed to adjust the intonation of the user. A global refinement is based on a relative scale estimated out of the most frequent errors made by singers. Four rules are then employed to eliminate local errors. This front end has been tested with five subjects and four short tunes, detecting some 90% of right notes. Results have been compared to other approximation methods like rounding to the nearest absolute tone/interval and an example of adaptive moving tuning, achieving respectively 74%, 80% and 44% of right estimations. A special session of tests has been conducted to verify the capability of the system in detecting vibrato/legato notes. Finally, issues about the best representation for the translated symbols are briefly discussed."
18,Christopher Raphael,Automated Rhythm Transcription.,2001,https://doi.org/10.5281/zenodo.1416122,"Christopher Raphael+University of Massachusetts, Amherst>USA>education","We present a technique that, given a sequence of musical note onset times, performs simultaneous identification of the notated rhythm and the variable tempo associated with the times. Our formulation is probabilistic: We develop a stochastic model for the interconnected evolution of a rhythm process, a tempo process, and an observable process. This model allows the globally optimal identification of the most likely rhythm and tempo sequence, given the observed onset times. We demonstrate applications to a sequence of times derived from a sampled audio file and to MIDI data."
19,Josh Reiss,Efficient Multidimensional Searching Routines.,2001,https://doi.org/10.5281/zenodo.1415546,"Josh Reiss+Queen Mary, University of London>GBR>education;Jean-Julien Aucouturier+Sony Computer Science Laboratory>FRA>company;Mark Sandler+Queen Mary, University of London>GBR>education","The problem of Music Information Retrieval can often be formalized as “searching for multidimensional trajectories”. It is well known that string-matching techniques provide robust and effective theoretic solutions to this problem. However, for low dimensional searches, especially queries concerning a single vector as opposed to a series of vectors, there are a wide variety of other methods available. In this work we examine and benchmark those methods and attempt to determine if they may be useful in the field of information retrieval. Notably, we propose the use of KD-Trees for multidimensional near-neighbor searching. We show that a KD-Tree is optimized for multidimensional data, and is preferred over other methods that have been suggested, such as the K-Tree, the box-assisted sort and the multidimensional quick-sort."
20,Richard P. Smiraglia,Musical Works as Information Retrieval Entities: Epistemological Perspectives.,2001,https://doi.org/10.5281/zenodo.1416512,Richard P. Smiraglia+Long Island University>USA>education,"Musical works form a key entity for music information retrieval. Explicit linkage of relationships among entities is critical for document-based information retrieval. Works contain representations of recorded knowledge. Core bodies of work—canons—function to preserve and disseminate the parameters of a culture. A musical work is an intellectual sonic conception. Musical works take documentary form in a variety of instantiations. Epistemology for documentary analysis provides key perceptual information about the objects of knowledge organization. Works are carriers of knowledge, representing deliberately-constructed packages of both rational and empirical evidence of human knowledge. Smiraglia (2001) suggests the parameters of a theory of the work, incorporating the tools of epistemology to comprehend works by expressing theoretical parameters in the context of a taxonomic definition. A work is a signifying, concrete set of ideational conceptions that finds realization through semantic or symbolic expression. Semiotic analysis suggests a variety of cultural and social roles for works. Musical works, defined as entities for information retrieval, are seen to constitute sets of varying instantiations of abstract creations. Variability over time, demonstrated empirically, is an innate aspect of the set of all instantiations of a musical work, leading to complexity in the information retrieval domain."
21,George Tzanetakis,Automatic Musical Genre Classification of Audio Signals.,2001,https://doi.org/10.5281/zenodo.1415058,George Tzanetakis+Princeton University>USA>education;Georg Essl+Princeton University>USA>education;Perry Cook+Princeton University>USA>education,"Musical genres are categorical descriptions that are used to describe music. They are commonly used to structure the increasing amounts of music available in digital form on the Web and are important for music information retrieval. Genre categorization for audio has traditionally been performed manually. A particular musical genre is characterized by statistical properties related to the instrumentation, rhythmic structure and form of its members. In this work, algorithms for the automatic genre categorization of audio signals are described. More specifically, we propose a set of features for representing texture and instrumentation. In addition a novel set of features for representing rhythmic structure and strength is proposed. The performance of those feature sets has been evaluated by training statistical pattern recognition classifiers using real world audio collections. Based on the automatic hierarchical genre classification two graphical user interfaces for browsing and interacting with large audio collections have been developed."
