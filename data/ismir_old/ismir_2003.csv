Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,E. Allamanche;Jürgen Herre;Oliver Hellmuth;T. Kastner;C. Ertel,A multiple feature model for musical similarity retrieval.,2003,https://doi.org/10.5281/zenodo.1416684,"Eric Allamanche, Fraunhofer Institut Integrierte Schaltungen, IIS, DEU, facility;J¨urgen Herre, Fraunhofer Institut Integrierte Schaltungen, IIS, DEU, facility;Oliver Hellmuth, Fraunhofer Institut Integrierte Schaltungen, IIS, DEU, facility;Thorsten Kastner, Fraunhofer Institut Integrierte Schaltungen, IIS, DEU, facility;Christian Ertel, Fraunhofer Institut Integrierte Schaltungen, IIS, DEU, facility","""Despite the “fuzzy” nature of musical similarity, which varies from one person to another, perceptual low level features combined with appropriate classi- ﬁcation schemes have proven to perform satisfactorily for this task. Since a single feature only captures some selective characteristics of an audio signal, this information may, in some cases, not be sufﬁcient to properly identify similarities between songs. This pa- per presents a system which combines a set of acous- tic features for the task of retrieving similar sounding songs. The methodology for optimum feature selec- tion and combination is explained, and the system’s performance is assessed by means of a subjective lis- tening test."""
1,Vlora Arifi;Michael Clausen;Frank Kurth;Meinard Müller,"Automatic synchronization of music data in score-, MIDI- and PCM-format.",2003,https://doi.org/10.5281/zenodo.1417848,"Vlora Ariﬁ, Universität Bonn, Institut für Informatik III, DEU, education;Michael Clausen, Universität Bonn, Institut für Informatik III, DEU, education;Frank Kurth, Universität Bonn, Institut für Informatik III, DEU, education;Meinard Müller, Universität Bonn, Institut für Informatik III, DEU, education","""In this paper we present algorithms for the automatic time-synchronizationof score-, MIDI- or PCM- data streams representing the same polyphonic piano piece."""
2,David Bainbridge 0001;Sally Jo Cunningham;J. Stephen Downie,Analysis of queries to a Wizard-of-Oz MIR system: Challenging assumptions about what people really want.,2003,https://doi.org/10.5281/zenodo.1416850,"David Bainbridge, University of Waikato, NZL, education;Sally Jo Cunningham, University of Waikato, NZL, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education","How do users of music information retrieval (MIR)
systems express their needs? Using a Wizard of Oz
approach to system evaluation, combined with a
grounded theory analysis of 502 real-world music
queries posted to Google Answers, this paper
addresses this pivotal question."
3,Adam Berenzweig;Beth Logan;Daniel P. W. Ellis;Brian Whitman,A large-scale evalutation of acoustic and subjective music similarity measures.,2003,https://doi.org/10.5281/zenodo.1417010,"Adam Berenzweig, LabROSA, Columbia University, USA, education;Beth Logan, HP Labs, USA, company;Daniel P.W. Ellis, LabROSA, Columbia University, USA, education;Brian Whitman, Music Mind & Machine Group, MIT Media Lab, USA, education","Subjective similarity between musical pieces and artists is an elusive concept, but one that must be pursued in support of applications to provide automatic organization of large music collections. In this paper, we examine both acoustic and subjective approaches for calculating similarity between artists, comparing their performance on a common database of 400 popular artists. Specifically, we evaluate acoustic techniques based on Mel-frequency cepstral coefficients and an intermediate ‘anchor space’ of genre classification, and subjective techniques which use data from The All Music Guide, from a survey, from playlists and personal collections, and from web-text mining. We find the following: (1) Acoustic-based measures can achieve agreement with ground truth data that is at least comparable to the internal agreement between different subjective sources. However, we observe significant differences between superficially similar distribution modeling and comparison techniques. (2) Subjective measures from diverse sources show reasonable agreement, with the measure derived from co-occurrence in personal music collections being the most reliable overall. (3) Our methodology for large-scale cross-site music similarity evaluations is practical and convenient, yielding directly comparable numbers for different approaches. In particular, we hope that our information-retrieval-based approach to scoring similarity measures, our paradigm of sharing common feature representations, and even our particular dataset of features for 400 artists, will be useful to other researchers."
4,Elaine Chew;Yun-Ching Chen,Determining context-defining windows: Pitch spelling using the spiral array.,2003,https://doi.org/10.5281/zenodo.1418037,"Elaine Chew, University of Southern California, USA, education;Yun-Ching Chen, University of Southern California, USA, education","""This paper presents algorithms for pitch spelling using the Spiral Array model. Accurate pitch spelling, assigning contextually consistent letter names to pitch numbers (for example, MIDI), is a critical component of music transcription and analysis systems. The local context is found to be more important than the global, but a combination of both achieves the best results."""
5,Roger B. Dannenberg;William P. Birmingham;George Tzanetakis;Colin Meek;Ning Hu;Bryan Pardo,The MUSART testbed for query-by-humming evaluation.,2003,https://doi.org/10.5281/zenodo.1415978,"Roger B. Dannenberg, Carnegie Mellon University, USA, education;William P. Birmingham, University of Michigan, USA, education;George Tzanetakis, University of Michigan, USA, education;Colin Meek, Carnegie Mellon University, USA, education;Ning Hu, Carnegie Mellon University, USA, education;Bryan Pardo, Carnegie Mellon University, USA, education","Evaluating music information retrieval systems is acknowledged to be a difficult problem. We have created a database and a software testbed for the systematic evaluation of various query-by-humming (QBH) search systems. As might be expected, different queries and different databases lead to wide variations in observed search precision. “Natural” queries from two sources led to lower performance than that typically reported in the QBH literature. These results point out the importance of careful measurement and objective comparisons to study retrieval algorithms. This study compares search algorithms based on note-interval matching with dynamic programming, fixed-frame melodic contour matching with dynamic time warping, and a hidden Markov model. An examination of scaling trends is encouraging: precision falls off very slowly as the database size increases. This trend is simple to compute and could be useful to predict performance on larger databases."
6,Stephen Davison,The Sheet Music Consortium: A Specialized Open Archives Initiative harvester project.,2003,https://doi.org/10.5281/zenodo.1417731,"Stephen Davison, University of California, Los Angeles, USA, education;Cynthia Requardt, The Johns Hopkins University, USA, education;Kristine Brancolini, Indiana University, USA, education","The Open Archives Initiative (OAI) Sheet Music Project is a consortium of institutions building OAI-compliant data providers, a metadata harvester, and a web-based service provider for digital sheet music collections. The project aims to test the viability of the OAI standard for providing access to sheet music collections on the web, and to build a permanent and increasingly participatory service for the discovery of digital sheet music. The service provider design has been informed by detailed usability testing, and by limitations imposed by the variations in metadata harvested from the different participating collections. Advanced services in addition to basic searching and browsing have been developed, including the ability to save and share subsets across participating collections. Harvesting and searching strategies for overcoming metadata limitations are being developed. The consortium is seeking additional participants with digital sheet music collections, and is exploring the possibility of incorporating scores and audio into the project."
7,Tom De Mulder;Jean-Pierre Martens;Micheline Lesaffre;Marc Leman;Bernard De Baets,An auditory model based transriber of vocal queries.,2003,https://doi.org/10.5281/zenodo.1416492,"Tom De Mulder, Ghent University, BEL, education;Jean-Pierre Martens, Ghent University, BEL, education;Micheline Lesaffre, Ghent University, BEL, education;Marc Leman, Ghent University, BEL, education;Bernard De Baets, Ghent University, BEL, education;Hans De Meyer, Ghent University, BEL, education","""In this paper a new auditory model-based transcriber of vocal melodic queries is presented. Our experiments show that the new system can transcribe queries with an accuracy between 76 % (whistling) and 85 % (singing with syllables), and that it outperforms four state-of-the-art systems it was compared with."""
8,Simon Dixon;Elias Pampalk;Gerhard Widmer,Classification of dance music by periodicity patterns.,2003,https://doi.org/10.5281/zenodo.1414936,"Simon Dixon, Austrian Research Institute for AI, AUT, facility;Elias Pampalk, Austrian Research Institute for AI, AUT, facility;Gerhard Widmer, Austrian Research Institute for AI, AUT, facility, Department of Medical Cybernetics and AI, University of Vienna, AUT, education","""This paper addresses the genre classiﬁcation prob-
lem for a speciﬁc subset of music, standard and Latin
ballroom dance music, using a classiﬁcation method
based only on timing information.
We compare
two methods of extracting periodicities from audio
recordings in order to ﬁnd the metrical hierarchy and
timing patterns by which the style of the music can
be recognised: the ﬁrst method performs onset detec-
tion and clustering of inter-onset intervals; the sec-
ond uses autocorrelation on the amplitude envelopes
of band-limited versions of the signal as its method
of periodicity detection. The relationships between
periodicities are then used to ﬁnd the metrical hierar-
chy and to estimate the tempo at the beat and measure
levels of the hierarchy. The periodicities are then in-
terpreted as musical note values, and the estimated
tempo, meter and the distribution of periodicities are
used to predict the style of music using a simple set
of rules. The methods are evaluated with a test set of
standard and Latin dance music, for which the style
and tempo are given on the CD cover, providing a
“ground truth” by which the automatic classiﬁcation
can be measured."""
9,Shyamala Doraisamy;Stefan M. Rüger,Position Indexing of Adjacent and Concurrent N-Grams for Polyphonic Music Retrieval.,2003,https://doi.org/10.5281/zenodo.1417919,"Shyamala Doraisamy, Imperial College London, GBR, education;Stefan Rüger, Imperial College London, GBR, education","In this paper we examine the retrieval performance of adjacent and concurrent n-grams generated from polyphonic music data.  We deploy a method to index polyphonic music using a word position indexer with the n-gram approach.  Using all possible combinations of monophonic sequences from polyphonic music data, “overlaying” word locations within a document are obtained, such as needed with polyphony (i.e. where more than one word can assume the same word position).  The feasibility in utilising the position information of polyphonic ‘musical words’ is investigated using various proximity-based and structured query operators available with text retrieval system.  Our experiments show that nested phrase operators improve the retrieval performance and we present the results of our comparative study on a collection of 5456 polyphonic pieces encoded in the MIDI format."
10,J. Stephen Downie,Toward the scientific evaluation of music information retrieval systems.,2003,https://doi.org/10.5281/zenodo.1417121,"J. Stephen Downie, Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, USA, education","""This paper outlines the findings-to-date of a project to assist in the efforts being made to establish a TREC-like evaluation paradigm within the Music Information Retrieval (MIR) research community. The findings and recommendations are based upon expert opinion garnered from members of the Information Retrieval (IR), Music Digital Library (MDL) and MIR communities with regard to the construction and implementation of scientifically valid evaluation frameworks. Proposed recommendations include the creation of data-rich query records that are both grounded in real-world requirements and neutral with respect to retrieval technique(s) being examined; adoption, and subsequent validation, of a “reasonable person” approach to “relevance” assessment; and, the development of a secure, yet accessible, research environment that allows researchers to remotely access the large-scale testbed collection."""
11,Jana Eggink;Guy J. Brown,Application of missing feature theory to the recognition of musical instruments in polyphonic audio.,2003,https://doi.org/10.5281/zenodo.1416262,"Jana Eggink, University of Sheffield, GBR, education;Guy J. Brown, University of Sheffield, GBR, education","""A system for musical instrument recognition based on a Gaussian Mixture Model (GMM) classifier is introduced. To enable instrument recognition when more than one sound is present at the same time, ideas from missing feature theory are incorporated. Specifically, frequency regions that are dominated by energy from an interfering tone are marked as unreliable and excluded from the classification process. The approach has been evaluated on clean and noisy monophonic recordings, and on combinations of two instrument sounds. These included random chords made from two isolated notes and combinations of two realistic phrases taken from commercially available compact discs. Classification results were generally good, not only when the decision between reliable and unreliable features was based on the knowledge of the clean signal, but also when it was solely based on the harmonic overtone series of the interfering sound."""
12,Olivier Gillet;Gaël Richard,Automatic labeling of tabla signals.,2003,https://doi.org/10.5281/zenodo.1418281,"Olivier K. GILLET, GET-ENST (TELECOM Paris), FRA, education;Ga¨el RICHARD, GET-ENST (TELECOM Paris), FRA, education","Most of the recent developments in the ﬁeld of music indexing and music information retrieval are focused on western music. In this paper, we present an automatic music transcription system dedicated to Tabla - a North Indian percussion instrument. Our approach is based on three main steps: ﬁrstly, the audio signal is segmented in adjacent segments where each segment represents a single stroke. Secondly, rhythmic information such as relative durations are calculated using beat detection techniques. Finally, the transcription (recognition of the strokes) is performed by means of a statistical model based on Hidden Markov Model (HMM). The structure of this model is designed in order to represent the time dependencies between successives strokes and to take into account the speciﬁcities of the tabla score notation (transcription symbols may be context dependent). Realtime transcription of Tabla soli (or performances) with an error rate of 6.5% is made possible with this transcriber. The transcription system, along with some additional features such as sound synthesis or phrase correction, are integrated in a user-friendly environment called Tablascope."
13,Masataka Goto,Music scene description project: Toward audio-based real-time music understanding.,2003,https://doi.org/10.5281/zenodo.1415684,"Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility","""This paper reports a research project intended to build a real-time music-understanding system producing intuitively meaningful descriptions of real-world musical audio signals, such as the melody lines and chorus sections. This paper also introduces our efforts to add correct descriptions (metadata) to the pieces in a music database."""
14,Masataka Goto;Hiroki Hashiguchi;Takuichi Nishimura;Ryuichi Oka,RWC Music Database: Music genre database and musical instrument sound database.,2003,https://doi.org/10.5281/zenodo.1415536,"Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility, Information and Human Activity, PRESTO, JST, JPN, facility;Hiroki Hashiguchi, Mejiro University, JPN, education;Takuichi Nishimura, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Ryuichi Oka, University of Aizu, JPN, education","This paper describes the design policy and speciﬁcations of the RWC Music Database, a copyright-cleared mu- sic database (DB) compiled speciﬁcally for research pur- poses. Shared DBs are common in other research ﬁelds and have made signiﬁcant contributions to progress in those ﬁelds. The ﬁeld of music information processing, however, has lacked a common DB of musical pieces or a large-scale DB of musical instrument sounds. We therefore recently constructed the RWC Music Database comprising four original component DBs: Popular Mu- sic Database (100 pieces), Royalty-Free Music Database (15 pieces), Classical Music Database (50 pieces), and Jazz Music Database (50 pieces). In this paper we re- port the construction of two additional component DBs: Music Genre Database (100 pieces) and Musical Instru- ment Sound Database (50 instruments). It is our hope that our DB will make a signiﬁcant contribution to future advances in the ﬁeld of music information processing."
15,S. Harford,"Automatic segmentation, learning and retrieval of melodies using a self-organizing neural network.",2003,https://doi.org/10.5281/zenodo.1416182,"Steven Harford, Dublin City University, IRL, education","We introduce a neural network, known as SONNET-
MAP, capable of automatic segmentation, learning
and retrieval of melodies. SONNET-MAP is a syn-
thesis of the SONNET (Self-Organizing Neural NET-
work) architecture (Nigrin, 1993) and an associa-
tive map derived from ARTMAP (Carpenter, Gross-
berg, and Reynolds, 1991). SONNET-MAP automat-
ically segments a melody based on pitch and rhythmic
grouping cues. Separate SONNET modules represent
the pitch and rhythm dimensions of each segmented
phrase independently, with two associative maps fus-
ing these representations at the phrase level. Further
SONNET modules aggregate these phrases forming a
hierarchical memory structure that encompasses the
entire melody. In addition, melodic queries may be
used to retrieve any encoded melody. As far as we
are aware, SONNET-MAP is the ﬁrst self-organizing
neural network architecture capable of automatically
segmenting and retrieving melodies based on both
pitch and rhythm."
16,Sung-Phil Heo;Motoyuki Suzuki;Akinori Ito;Shozo Makino,Three-dimensional continuous DP algorithm for multiple pitch candidates in a music information retrieval system.,2003,https://doi.org/10.5281/zenodo.1416862,"Sung-Phil HEO, Graduate School of Information Sciences Tohoku University, JPN, education;Motoyuki SUZUKI, Graduate School of Engineering Tohoku University, JPN, education;Akinori ITO, Graduate School of Engineering Tohoku University, JPN, education;Shozo MAKINO, Graduate School of Engineering Tohoku University, JPN, education","This paper treats theoretical and practical issues that implement a music information retrieval system based on query by humming. In order to extract accuracy features from the user’s humming, we propose a new retrieval method based on multiple pitch candidates. Extracted multiple pitches have shown to be very important parameters in determining melodic similarity, but it is also clear that the confidence measures feature which are obtained from the power are important as well. Furthermore, we propose extending the traditional DP algorithm to three dimensions so that multiple pitch candidates can be treated. Simultaneously, at the melody representation technique, we propose the DP paths are changed dynamically to be able to take relative values so that they can respond to insert or omit notes."
17,Olivier Lartillot,Discovering musical pattern through perceptual heuristics.,2003,https://doi.org/10.5281/zenodo.1417285,"Olivier Lartillot, IRCAM - Centre Pompidou, FRA, facility","""This paper defends the view that the intricate
difficulties challenging the emerging domain of
Musical Pattern Discovery, which is dedicated to the
automation of motivic analysis, will be overcome
only through a thorough taking into account of the
specificity of music as a perceptive object. Actual
musical patterns, although constantly transformed,
are nevertheless perceived by the listener as musical
identities. Such dynamical properties of human
perception, not reducible to geometrical models, will
only be explained with the notions of contexts and
expectations. This paper sketches the general
principles of a new approach that attempts to build
such a general perceptual system. On a sub-cognitive
level, patterns are discovered through the detection,
by an associative memory, of local similarities. On a
cognitive level, patterns are managed by a general
logical framework that avoids irrelevant inferences
and combinatorial explosion. In this way, actual
musical patterns that convey musical significance are
discovered. This approach, offering promising
results, is a first step toward a complete system of
automated music analysis and an explicit modeling of
basic mechanisms for music understanding."""
18,Kjell Lemström;Veli Mäkinen;Anna Pienimäki;M. Turkia;Esko Ukkonen,The C-BRAHMS project.,2003,https://doi.org/10.5281/zenodo.1417551,"Kjell Lemström, University of Helsinki, FIN, education;Veli Mäkinen, University of Helsinki, FIN, education;Anna Pienimäki, University of Helsinki, FIN, education;Mika Turkia, University of Helsinki, FIN, education;Esko Ukkonen, University of Helsinki, FIN, education","""The C-BRAHMS project develops computational methods for content-based retrieval and analysis of music data. A summary of the recent algorithmic and experimental developments of the project is given."""
19,Micheline Lesaffre;Koen Tanghe;Gaëtan Martens;Dirk Moelants;Marc Leman;Bernard De Baets;Hans De Meyer;Jean-Pierre Martens,The MAMI query-by-voice experiment: collecting and annotating vocal queries for music information retrieval.,2003,https://doi.org/10.5281/zenodo.1418133,"Micheline Lesaffre, Ghent University, BEL, education;Koen Tanghe, Ghent University, BEL, education;Gaëtan Martens, Ghent University, BEL, education;Dirk Moelants, Ghent University, BEL, education;Marc Leman, Ghent University, BEL, education;Bernard De Baets, Ghent University, BEL, education;Hans De Meyer, Ghent University, BEL, education;Jean-Pierre Martens, Ghent University, BEL, education","""The MIR research community requires coordinated strategies in dealing with databases for system development and experimentation. Manually annotated files can accelerate the development of accurate analysis tools for music information retrieval. This paper presents background information on an annotated database of vocal queries that is freely available on the Internet. First we outline the design and set up of the experiment through which the vocal queries were generated. Then attention is drawn to the manual annotation of the vocal queries."""
20,Tao Li 0001;Mitsunori Ogihara,Detecting emotion in music.,2003,https://doi.org/10.5281/zenodo.1417293,"Tao Li, University of Rochester, USA, education;Mitsunori Ogihara, University of Rochester, USA, education",""""""
21,Dan Liu 0001;Lie Lu;HongJiang Zhang,Automatic mood detection from acoustic music data.,2003,https://doi.org/10.5281/zenodo.1418335,"Dan Liu, Tsinghua University, CHN, education;Lie Lu, Microsoft Research Asia, CHN, company;Hong-Jiang Zhang, Microsoft Research Asia, CHN, company","Music mood describes the inherent emotional meaning of a music clip.  It is helpful in music understanding, music search and some music-related applications.  In this paper, a hierarchical framework is presented to automate the task of mood detection from acoustic music data, by following some music psychological theories in western cultures.  Three feature sets , intensity, timbre and rhythm, are extracted to represent the characteristics of a music clip.  Moreover, a mood tracking approach is also presented for a whole piece of music.  Experimental evaluations indicate that the proposed algorithms produce satisfactory results."
22,Arie Livshin;Xavier Rodet,The importance of cross database evaluation in musical instrument sound classification: A critical approach.,2003,https://doi.org/10.5281/zenodo.1417771,"Arie Livshin, IRCAM Centre Pompidou, FRA, facility;Xavier Rodet, IRCAM Centre Pompidou, FRA, facility","In numerous articles (Martin and Kim, 1998; Fraser and Fujinaga, 1999; and many others) sound classification algorithms are evaluated using ""self classification"" - the learning and test groups are randomly selected out of the same sound database. We will show that ""self classification"" is not necessarily a good statistic for the ability of a classification algorithm to learn, generalize or classify well. We introduce the alternative ""Minus-1 DB"" evaluation method and demonstrate that it does not have the shortcomings of ""self classification""."
23,Namunu Chinthaka Maddage;Changsheng Xu;Ye Wang,An SVM-based classification approach to musical audio.,2003,https://doi.org/10.5281/zenodo.1415610,"Namunu Chinthaka Maddage, Institute for Inforcomm Research, SGP, facility;Changsheng Xu, Institute for Inforcomm Research, SGP, facility;Ye Wang, National University of Singapore, SGP, education","""This paper describes an automatic hierarchical music 
classification approach based on support vector 
machines (SVM). Based on the proposed method, the 
music is classified into coursed classes such as vocal, 
instrumental or vocal mixed with instrumental music. 
These main classes are further sub-classed according 
to gender and instrument type. A novel method, 
Correction Algorithm for Music Sequence (CAMS) 
has been developed to improve the classification 
efficiency."""
24,Martin F. McKinney;Jeroen Breebaart,Features for audio and music classification.,2003,https://doi.org/10.5281/zenodo.1415026,"Martin F. McKinney, Philips Research Laboratories, NLD, company;Jeroen Breebaart, Philips Research Laboratories, NLD, company","Four audio feature sets are evaluated in their ability to classify ﬁve general audio classes and seven pop- ular music genres. The feature sets include low-level signal properties, mel-frequency spectral coefﬁcients, and two new sets based on perceptual models of hear- ing. The temporal behavior of the features is ana- lyzed and parameterized and these parameters are in- cluded as additional features. Using a standard Gaus- sian framework for classiﬁcation, results show that the temporal behavior of features is important for both music and audio classiﬁcation. In addition, classiﬁca- tion is better, on average, if based on features from models of auditory perception rather than on standard features."
25,Colin Meek;William P. Birmingham,The dangers of parsimony in query-by-humming applications.,2003,https://doi.org/10.5281/zenodo.1415828,"Colin Meek, University of Michigan, USA, education;William P. Birmingham, University of Michigan, USA, education","""Query-by-humming systems attempt to address the needs of the non-expert user, for whom the most natural query format – for the purposes of finding a tune, hook or melody of unknown providence – is to sing it. While human listeners are quite tolerant of error in these queries, a music retrieval mechanism must explicitly model such errors in order to perform its task. We will present a unifying view of existing models, illuminating the assumptions underlying their respective designs, and demonstrating where such assumptions succeed and fail, through analysis and real-world experiments."""
26,T. Olson;S. J. Downie,Chopin early editions: The construction and usage of a collection of digital scores.,2003,https://doi.org/10.5281/zenodo.1417397,"Tod A. Olson, The University of Chicago Library, USA, education;J. Stephen Downie, Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, USA, education","The University of Chicago Library has digitized a collection of 19th century music scores. The online collection is generated programmatically from the scanned images and human-created descriptive and structural metadata, encoded as METS objects, and delivered using the Greenstone Digital Library software. Use statistics are analyzed and possible future directions for the collection are discussed."
27,Nicola Orio;M. Sisti Sette,An HMM-based pitch tracker for audio queries.,2003,https://doi.org/10.5281/zenodo.1417601,"Nicola Orio, University of Padova, ITA, education;Matteo Sisti Sette, University of Padova, ITA, education","""In this paper we present an approach to the transcrip-
tion of musical queries based on a hidden Markov
model (HMM). The HMM is used to model the audio
features related to the singing voice, and the transcrip-
tion is obtained through Viterbi decoding. We report
our preliminary work on evaluation of the system."""
28,Elias Pampalk;Simon Dixon;Gerhard Widmer,Exploring music collections by browsing different views.,2003,https://doi.org/10.5281/zenodo.1416876,"Elias Pampalk, Austrian Research Institute for Artificial Intelligence (OeFAI), AUT, facility, University of Vienna, AUT, education;Simon Dixon, Austrian Research Institute for Artificial Intelligence (OeFAI), AUT, facility;Gerhard Widmer, Austrian Research Institute for Artificial Intelligence (OeFAI), AUT, facility, University of Vienna, AUT, education","""The availability of large music collections calls for ways to efﬁciently access and explore them. We present a new approach which combines descriptors derived from audio analysis with meta-information to create different views of a collection. Such views can have a focus on timbre, rhythm, artist, style or other aspects of music. For each view the pieces of mu- sic are organized on a map in such a way that similar pieces are located close to each other. The maps are visualized using an Islands of Music metaphor where islands represent groups of similar pieces. The maps are linked to each other using a new technique to align self-organizing maps. The user is able to browse the collection and explore different aspects by gradu- ally changing focus from one view to another. We demonstrate our approach on a small collection using a meta-information-based view and two views gener- ated from audio analysis, namely, beat periodicity as an aspect of rhythm and spectral information as an aspect of timbre."""
29,R. Mitchell Parry;Irfan A. Essa,Rhythmic similarity through elaboration.,2003,https://doi.org/10.5281/zenodo.1416738,"Mitchell Parry, Georgia Institute of Technology, USA, education;Irfan Essa, Georgia Institute of Technology, USA, education",Rhythmic similarity techniques for audio tend to evaluate how close to identical two rhythms are. This paper proposes a similarity metric based on rhythmic elaboration that matches rhythms that share the same beats regardless of tempo or identicalness. Elaborations can help an application decide where to transition between songs. Potential applications include automatically generating a non-stop music mix or sonically browsing a music library.
30,Steffen Pauws,"Effects of song familiarity, singing training and recent song exposure on the singing of melodies.",2003,https://doi.org/10.5281/zenodo.1414722,", ",""""""
31,Jeremy Pickens,Key-specific shrinkage techniques for harmonic models.,2003,https://doi.org/10.5281/zenodo.1414776,"Jeremy Pickens, University of Massachusetts, USA, education",""""""
32,Christopher Raphael;Josh Stoddard,Harmonic analysis with probabilistic graphical models.,2003,https://doi.org/10.5281/zenodo.1415574,"Christopher Raphael, Univ. of Massachusetts, USA, education;Josh Stoddard, Univ. of Massachusetts, USA, education","""A technique for harmonic analysis is presented that
partitions a piece of music into contiguous regions
and labels each with the key, mode, and functional
chord, e.g. tonic, dominant, etc. The analysis is per-
formed with a hidden Markov model and, as such, is
automatically trainable from generic MIDI ﬁles and
capable of ﬁnding the globally optimal harmonic la-
beling. Experiments are presented highlighting our
current state of the art.
An extension to a more
complex probabilistic graphical model is outlined in
which music is modeled as a collection of voices
that evolve independently given the harmonic pro-
gression."""
33,Julien Ricard;Perfecto Herrera,Using morphological description for generic sound retrieval.,2003,https://doi.org/10.5281/zenodo.1416042,"Julien Ricard, Pompeu Fabra University, ESP, education;Perfecto Herrera, Pompeu Fabra University, ESP, education","Systems for sound retrieval are usually “source-
centred”. This means that retrieval is based on using 
the proper keywords that define or specify a sound 
source. Although this type of description is of great 
interest, it is very difficult to implement it into 
realistic automatic labelling systems because of the 
necessity of dealing with thousands of categories, 
hence with thousands of different sound models. 
Moreover, digitally synthesised or transformed 
sounds, which are frequently used in most of the 
contemporary popular music, have no identifiable 
sources. We propose a description framework, based 
on Schaeffer’s research on a generalised solfeggio 
which could be applied to any type of sounds. He 
defined some morphological description criteria, 
based on intrinsic perceptual qualities of sound, 
which doesn’t refer to the cause or the meaning of a 
sound. We describe more specifically experiments on 
automatic extraction of morphological descriptors."
34,P. Roland,Design patterns in XML music representation.,2003,https://doi.org/10.5281/zenodo.1417445,"Perry Roland, University of Virginia, USA, education","Design patterns attempt to formalize the discussion of recurring problems and their solutions. This paper introduces several XML design patterns and demonstrates their usefulness in the development of XML music representations. The patterns have been grouped into several categories of desirable outcome of the design process – modularity, separation of data and meta-data, reduction of learning requirements, assistance to tool development, and increase in legibility and understandability. The Music Encoding Initiative (MEI) DTD, from which the examples are drawn, the examples, and other materials related to MEI are available at http://www.people.virginia.edu/~pdr4h/."
35,B. Schwartz,Music Notation as a MEI Feasability Test.,2003,https://doi.org/10.5281/zenodo.1416136,"Baron Schwartz, University of Virginia, USA, education","""This project demonstrated that enough information
can be retrieved from MEI, an XML format for mu-
sical information representation, to transform it into
music notation with good ﬁdelity. The process in-
volved writing an XSLT script to transform ﬁles into
Mup, an intermediate format, then processing the
Mup into PostScript, the de facto page description
language for high-quality printing. The results show
that the MEI format represents musical information
such that it may be retrieved simply, with good recall
and precision."""
36,Anthony Seeger,"I Found It, How Can I Use It?"" - Dealing With the Ethical and Legal Constraints of Information Access.",2003,https://doi.org/10.5281/zenodo.1417719,"Anthony Seeger, Johns Hopkins University, USA, education","""It is very easy to find music on the Internet today, but how it may be used is the source of considerable conflict, front-page news stories, and increasingly of scholarly reflection.  One of the frustrations for libraries, archives, and patrons alike is the gulf between the information about a holding and actual access to it.  But users are not the only ones to  have an opinion about free access.  Local musicians feel that everyone profits from their cultural heritage but them; researchers find themselves held responsible for research recordings made decades earlier and largely forgotten; and some communities seek to protect music that was never meant to be commercialized, and is considered to be secret or divine. Caught in the middle between angry patrons, angry companies, and angry artists, what are music librarians and archivists supposed to do?   Using his own experience as a researcher, archivist, and record producer, the author discusses the issues and makes some suggestions that can help those who wish to use the music they can so easily find out about."""
37,Frank Seifert 0001;Wolfgang Benn,Music identification by leadsheets: Converging perceptive and productive musical principles for estimation of semantic similarity of musical documents.,2003,https://doi.org/10.5281/zenodo.1417759,"Frank Seifert, University of Technology, Chemnitz, DEU, education;Wolfgang Benn, University of Technology, Chemnitz, DEU, education","Most experimental research on content-based
automatic recognition and identification of musical
documents is founded on statistical distribution of
timbre or simple retrieval mechanisms like
comparison of melodic segments. Therefore often a
vast number of relevant and irrelevant hits including
multiple appearances of the same documents are
returned or the actual document can’t be revealed at
all. To improve this situation we propose a model for
recognition of music that enables identification and
comparison of musical documents without
dependence on their actual instantiation. The
resulting structures enclose musical meaning and can
be used for estimation of identity and semantic
relationship between musical documents."
38,Alexander Sheh;Daniel P. W. Ellis,Chord segmentation and recognition using EM-trained hidden markov models.,2003,https://doi.org/10.5281/zenodo.1416734,"Alexander Sheh, Columbia University, USA, education;Daniel P.W. Ellis, Columbia University, USA, education","Automatic extraction of content description from commercial audio recordings has a number of important applications, from indexing and retrieval through to novel musicological analyses based on very large corpora of recorded performances. Chord sequences are a description that captures much of the character of a piece in a compact form and using a modest lexicon. Chords also have the attractive property that a piece of music can (mostly) be segmented into time intervals that consist of a single chord, much as recorded speech can (mostly) be segmented into time intervals that correspond to specific words. In this work, we build a system for automatic chord transcription using speech recognition tools. For features we use “pitch class profile” vectors to emphasize the tonal content of the signal, and we show that these features far outperform cepstral coefficients for our task. Sequence recognition is accomplished with hidden Markov models (HMMs) directly analogous to subword models in a speech recognizer, and trained by the same Expectation-Maximization (EM) algorithm. Crucially, this allows us to use as input only the chord sequences for our training examples, without requiring the precise timings of the chord changes — which are determined automatically during training. Our results on a small set of 20 early Beatles songs show frame-level accuracy of around 75% on a forced-alignment task."
39,Jonah Shifrin;William P. Birmingham,Effectiveness of HMM-based retrieval on large databases.,2003,https://doi.org/10.5281/zenodo.1417187,"Jonah Shifrin, University of Michigan, USA, education;William Birmingham, University of Michigan, USA, education","""We have investigated the performance of a hidden Markov model QBH retrieval system on a large musical database. The database is synthetic, generated from statistics gleaned from our (smaller) database of musical excerpts from various genres. This paper reports the performance of several variations of our retrieval system against different types of synthetic queries on the large database, where we can control the errors injected into the queries. We note several trends, among the most interesting is that as queries get longer (i.e., more notes) the retrieval performance improves."""
40,Ferréol Soulez;Xavier Rodet;Diemo Schwarz,Improving polyphonic and poly-instrumental music to score alignment.,2003,https://doi.org/10.5281/zenodo.1415542,"Ferréol Soulez, IRCAM – Centre Pompidou, FRA, facility;Xavier Rodet, IRCAM – Centre Pompidou, FRA, facility;Diemo Schwarz, IRCAM – Centre Pompidou, FRA, facility","Music alignment links events in a score and points on the audio performance time axis. All the parts of a recording can be thus indexed according to score information. The automatic alignment presented in this paper is based on a dynamic time warping method. Local distances are computed using the signal’s spectral features through an attack plus sustain note modeling. The method is applied to mixtures of harmonic sustained instruments, excluding percussion for the moment. Good alignment has been obtained for polyphony of up to five instruments. The method is robust for difficulties such as trills, vibratos and fast sequences. It provides an accurate indicator giving position of score interpretation errors and extra or forgotten notes. Implementation optimizations allow aligning long sound files in a relatively short time. Evaluation results have been obtained on piano jazz recordings."
41,Haruto Takeda;Takuya Nishimoto;Shigeki Sagayama,Automatic rhythm transcription from multiphonic MIDI signals.,2003,https://doi.org/10.5281/zenodo.1415222,"Haruto Takeda, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Takuya Nishimoto, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education;Shigeki Sagayama, Graduate School of Information Science and Technology, The University of Tokyo, JPN, education","For automatically transcribing human-performed polyphonic music recorded in the MIDI format, rhythm and tempo are decomposed through probabilistic modeling using Viterbi search in HMM for recognizing the rhythm and EM Algorithm for estimating the tempo. Experimental evaluation are also presented."
42,Wei-Ho Tsai;Hsin-Min Wang;Dwight Rodgers;Shih-Sian Cheng;Hung-Ming Yu,Blind clustering of popular music recordings based on singer voice characteristics.,2003,https://doi.org/10.5281/zenodo.1415112,"Wei-Ho Tsai, Institute of Information Science, Academia Sinica, TWN, facility;Hsin-Min Wang, Institute of Information Science, Academia Sinica, TWN, facility;Dwight Rodgers, Institute of Information Science, Academia Sinica, TWN, facility;Shi-Sian Cheng, Institute of Information Science, Academia Sinica, TWN, facility;Hung-Ming Yu, Institute of Information Science, Academia Sinica, TWN, facility","This paper presents an effective technique for automatically clustering undocumented music recordings based on their associated singer. This serves as an indispensable step towards indexing and content-based information retrieval of music by singer. The proposed clustering system operates in an unsupervised manner, in which no prior information is available regarding the characteristics of singer voices, nor the population of singers. Methods are presented to separate vocal from non-vocal regions, to isolate the singers’ vocal characteristics from the background music, to compare the similarity between singers’ voices, and to determine the total number of unique singers from a collection of songs. Experimental evaluations conducted on a 200-track pop music database confirm the validity of the proposed system."
43,Robert J. Turetsky;Daniel P. W. Ellis,Ground-truth transcriptions of real music from force-aligned MIDI syntheses.,2003,https://doi.org/10.5281/zenodo.1417667,"Robert J. Turetsky, Columbia University, USA, education;Daniel P.W. Ellis, Columbia University, USA, education","Many modern polyphonic music transcription algorithms are presented in a statistical pattern recognition framework. But without a large corpus of real-world music transcribed at the note level, these algorithms are unable to take advantage of supervised learning methods and also have difﬁculty reporting a quantitative metric of their performance, such as a Note Error Rate. We attempt to remedy this situation by taking advantage of publicly-available MIDI transcriptions. By force-aligning synthesized audio generated from a MIDI transcription with the raw audio of the song it represents we can correlate note events within the MIDI data with the precise time in the raw audio where that note is likely to be expressed. Having these alignments will support the creation of a polyphonic transcription system based on labeled segments of produced music. But because the MIDI transcriptions we ﬁnd are of variable quality, an integral step in the process is automatically evaluating the integrity of the alignment before using the transcription as part of any training set of labeled examples. Comparing a library of 40 published songs to freely available MIDI ﬁles, we were able to align 31 (78%). We are building a collection of over 500 MIDI tran-scriptions matching songs in our commercial music collection, for a potential total of 35 hours of note-level transcriptions, or some 1.5 million note events."
44,Rainer Typke;Panos Giannopoulos;Remco C. Veltkamp;Frans Wiering;René van Oostrum,Using transportation distances for measuring melodic similarity.,2003,https://doi.org/10.5281/zenodo.1417513,"Rainer Typke, University of Utrecht, NLD, education;Panos Giannopoulos, University of Utrecht, NLD, education;Remco C. Veltkamp, University of Utrecht, NLD, education;Frans Wiering, University of Utrecht, NLD, education;René van Oostrum, University of Utrecht, NLD, education","Most of the existing methods for measuring melodic similarity use one-dimensional textual representations of music notation, so that melodic similarity can be measured by calculating editing distances. We view notes as weighted points in a two-dimensional space, with the coordinates of the points reflecting the pitch and onset time of notes and the weights of points depending on the corresponding notes’ duration and importance. This enables us to measure similarity by using the Earth Mover’s Distance (EMD) and the Proportional Transportation Distance (PTD), a pseudo-metric for weighted point sets which is based on the EMD. A comparison of our experiment results with earlier work shows that by using weighted point sets and the EMD/PTD instead of Howard’s method (1998) using the DARMS encoding for determining melodic similarity, it is possible to group together about twice as many known occurrences of a melody within the RISM A/II collection. Also, the percentage of successfully identified authors of anonymous incipits can almost be doubled by comparing weighted point sets instead of looking for identical representations in Plaine & Easie encoding as Schlichte did in 1990."
45,George Tzanetakis;Jun Gao;Peter Steenkiste,A scalable peer-to-peer system for music content and information retrieval.,2003,https://doi.org/10.5281/zenodo.1417451,"George Tzanetakis, Carnegie Mellon University, USA, education;Jun Gao, Carnegie Mellon University, USA, education;Peter Steenkiste, Carnegie Mellon University, USA, education","Currently a large percentage of Internet trafﬁc con-
sists of music ﬁles, typically stored in MP3 com-
pressed audio format, shared and exchanged over
Peer-to-Peer (P2P) networks. Searching for music is
performed by specifying keywords and naive string
matching techniques. In the past years the emerging
research area of Music Information Retrieval (MIR)
has produced a variety of new ways of looking at the
problem of music search. Such MIR techniques can
signiﬁcantly enhance the ways user search for music
over P2P networks. In order for that to happen there
are two main challenges that need to be addressed: 1)
scalability to large collections and number of peers, 2)
richer set of search semantics that can support MIR
especially when retrieval is content-based.
In this
paper, we describe a scalable P2P system that uses
Rendezvous Points (RPs) for music metadata regis-
tration and query resolution, that supports attribute-
value search semantics as well as content-based re-
trieval. The performance of the system has been eval-
uated in large scale usage scenarios using “real” au-
tomatically calculated musical content descriptors."
46,Alexandra L. Uitdenbogerd;Yaw Wah Yap,Was Parsons right? An experiment in usability of music representations for melody-based music retrieval.,2003,https://doi.org/10.5281/zenodo.1418225,"Alexandra L. Uitdenbogerd, RMIT University, AUS, education;Yaw Wah Yap, RMIT University, AUS, education","""In 1975 Parsons developed his dictionary of musical
themes based on a simple contour representation. The
motivation was that people with little training in mu-
sic would be able to identify pieces of music. We
decided to test whether people of various levels of
musical skill could indeed make use of a text repre-
sentation to describe a simple melody query. The re-
sults indicate that the task is beyond those who are
unmusical, and that a scale numeric representation is
easier than a contour one for those of moderate mu-
sical skill. Further, a common error when using the
scale representation still yields a more accurate con-
tour representation than if a user is asked to enter a
contour query. We observed an average query length
of about seven symbols for the retrieval task."""
47,Esko Ukkonen;Kjell Lemström;Veli Mäkinen,Geometric algorithms for transposition invariant content based music retrieval.,2003,https://doi.org/10.5281/zenodo.1417477,"Esko Ukkonen, University of Helsinki, FIN, education;Kjell Lemström, University of Helsinki, FIN, education;Veli Mäkinen, University of Helsinki, FIN, education","We represent music as sets of points or sets of horizontal line segments in the Euclidean plane. Via this geometric representation we cast transposition invariant content-based music retrieval problems as ones of matching sets of points or sets of horizontal line segments in plane under translations. For finding the exact occurrences of a point set (the query pattern) of size within another point set (representing the database) of size , we give an algorithm with running time , and for finding partial occurrences another algorithm with running time . We also use the total length of the overlap between the line segments of a translated query and a database (i.e., the shared time) as a quality measure of an occurrence and present an algorithm for finding translations giving the largest possible overlap. Some experimental results on the performance of the algorithms are reported."
48,Avery Wang,An Industrial Strength Audio Search Algorithm.,2003,https://doi.org/10.5281/zenodo.1416340,,
49,Gavin Wood;Simon O'Keefe,Quantitative comparisons into content-based music recognition with the self organising map.,2003,https://doi.org/10.5281/zenodo.1415644,"Gavin Wood, University of York, GBR, education;Simon O’Keefe, University of York, GBR, education","""With so much modern music being so widely avail- able both in electronic form and in more traditional physical formats, a great opportunity exists for the de- velopment of a general-purpose recognition and mu- sic classiﬁcation system. We describe an ongoing investigation into the subject of musical recognition purely by the sonic content from a standard record- ing."""
