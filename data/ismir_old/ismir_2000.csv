Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,David Bainbridge 0001,The role of Music IR in the New Zealand Digital Music Library project.,2000,https://doi.org/10.5281/zenodo.1416260,"David Bainbridge, University of Waikato, NZL, education","""This extended abstract describes the computer music work that forms part of the New Zealand Digital Library (NZDL) project.  In keeping with the scope of the general project, the music work investigates data acquisition, retrieval, presentation and scalability.  These parts are described in turn in the text below."""
1,Eloi Batlle;Pedro Cano,Automatic Segmentation for Music Classification using Competitive Hidden Markov Models.,2000,https://doi.org/10.5281/zenodo.1416764,"Eloi Batlle, Universitat Pompeu Fabra, ESP, education;Pedro Cano, Universitat Pompeu Fabra, ESP, education","Music information retrieval has become a major topic in the last few years and we can find a wide 
range of applications that use it. For this reason, audio databases start growing in size as more and 
more digital audio resources have become available. However, the usefulness of an audio 
database relies not only on its size but also on its organization and structure. Therefore, much 
effort must be spent in the labeling process whose complexity grows with database size and 
diversity. 

In this paper we introduce a new audio classification tool and we use its properties to develop an 
automatic system to segment audio material in a fully unsupervised way. The audio segments 
obtained with this process are automatically labeled in a way that two segments with similar 
psychoacoustics properties get the same label. By doing so, the audio signal is automatically 
segmented into a sequence of abstract acoustic events. This is specially useful to classify huge 
multimedia databases where a human driven segmentation is not practicable. This automatic 
classification allow a fast indexing and retrieval of audio fragments. This audio segmentation is 
done using competitive hidden Markov models as the main classification engine and, thus, no 
previous classified or hand-labeled data is needed. This powerful classification tool also has a 
great flexibility and offers the possibility to customize the matching criterion as well as the 
average segment length according to the application needs."
2,Juan Pablo Bello;Giuliano Monti;Mark B. Sandler,Techniques for Automatic Music Transcription.,2000,https://doi.org/10.5281/zenodo.1414872,"Juan Pablo Bello, King’s College London, GBR, education;Giuliano Monti, King’s College London, GBR, education;Mark Sandler, King’s College London, GBR, education","Two systems are reviewed than perform automatic music transcription. The first perform monophonic transcription using an autocorrelation pitch tracker. The algorithm takes advantage of some heuristic parameters related to the similarity between image and sound in the collector. The detection is correct between notes B1 to E6 and further timbre analysis will provide the necessary parameters to reproduce a similar copy of the original sound. The second system is able to analyse simple polyphonic tracks. It is composed of a blackboard system, receiving its input from a segmentation routine in the form of an averaged STFT matrix. The blackboard contents an hypotheses database, an scheduler and knowledge sources, one of which is a neural network chord recogniser with the ability to reconfigure the operation of the system, allowing it to output more than one note hypothesis at the time. Some examples are provided to illustrate the performance and the weaknesses of the current implementation. Next steps for further development are defined."
3,Daniel Bendor;Mark B. Sandler,Time Domain Extraction of Vibrato from Monophonic Instruments.,2000,https://doi.org/10.5281/zenodo.1416810,"Daniel Bendor, University of Maryland at College Park, USA, education;Mark Sandler, King's College London, GBR, education",""""""
4,Alain Bonardi,IR for Contemporary Music: What the Musicologist Needs.,2000,https://doi.org/10.5281/zenodo.1415912,"Alain Bonardi, IRCAM, FRA, facility","Active listening is the core of musical activity Listening does not only concern receiving musical information. On the contrary, it is “active” and based on a set of interactions between listeners and musical documents—including automatic music information research and extraction—so as to discover intentions. This recognition process is based on the observation of regularities and rules, in order to build “forms” from all indications, information and redundancies. The listener interprets all the signs that are meaningful for him as intentions, attributed to the composer."
5,Wei Chai;Barry Vercoe,Using User Models in Music Information Retrieval Systems.,2000,https://doi.org/10.5281/zenodo.1415898,"Wei Chai, Massachusetts Institute of Technology, USA, education;Barry Vercoe, Massachusetts Institute of Technology, USA, education","Most websites providing music services only support category-based browsing and/or text-based
searching. There has been some research to improve the interface either for pull applications, e.g.
query-by-humming systems, or for push applications, e.g. collaborative-filtering-based or feature-
based music recommendation systems. However, for content-based search or feature-based
filtering systems, one important problem is to describe music by its parameters or features, so that
search engines or information filtering agents can use them to measure the similarity of the target
(userÕs query or preference) and the candidates. MPEG7 (formally called ÒMultimedia Content
Description InterfaceÓ) is an international standard, which describes the multimedia content data
to allow universal indexing, retrieval, filtering, control, and other activities supported by rich
metadata. However, the metadata about the multimedia content itself are still insufficient, because
many features of multimedia content are quite perceptual and user-dependent. For example,
emotional features are very important for multimedia retrieval, but they are hard to be described
by a universal model since different users may have different emotional responses to the same
multimedia content. We therefore turn to user modeling techniques and representations to
describe the properties of each user, so that the retrieval will be more accurate. Besides, user
modeling can be used to reduce the search space, make push service easier and improve the user
interface."
6,Arbee L. P. Chen,"Music Representation, Indexing and Retrieval at NTHU.",2000,https://doi.org/10.5281/zenodo.1417981,"Arbee L.P. Chen, National Tsing Hua University, TWN, education",""""""
7,G. Sayeed Choudhury;M. Droetboom;Tim DiLauro;Ichiro Fujinaga;Brian Harrington,Optical Music Recognition System within a Large-Scale Digitization Project.,2000,https://doi.org/10.5281/zenodo.1415730,"G. Sayeed Choudhury, Johns Hopkins University, USA, education;Tim DiLauro, Johns Hopkins University, USA, education;Michael Droettboom, Johns Hopkins University, USA, education;Ichiro Fujinaga, Johns Hopkins University, USA, education;Brian Harrington, Johns Hopkins University, USA, education;Karl MacMillan, Johns Hopkins University, USA, education","""An adaptive optical music recognition system is being developed as part of an experiment in creating a comprehensive framework of tools to manage the workflow of large-scale digitization projects. This framework will support the path from physical object and/or digitized material into a digital library repository, and offer effective tools for incorporating metadata and perusing the content of the resulting multimedia objects."""
8,Michael Clausen;R. Engelbrecht;D. Meyer;J. Schmitz,PROMS: A Web-based Tool for Searching in Polyphonic Music.,2000,https://doi.org/10.5281/zenodo.1417139,"M. Clausen, Universität Bonn, DEU, education;R. Engelbrecht, Universität Bonn, DEU, education;D. Meyer, Universität Bonn, DEU, education;J. Schmitz, Universität Bonn, DEU, education","One major task of a digital music library (DML) is to provide techniques to locate a queried musical pattern in all pieces of music in the database containing that pattern. For a survey of several computational tasks related to this kind of data retrieval we refer to Crawford et al. [3]. Existing DMLs like MELDEX [1], Themeﬁnder [4], and the Sonoda-Muraoka-System [7] work with melody databases relying on score-like information. Retrieval and matching are performed in a fault-tolerant way by string-based methods which mainly take into account pitch information. Generally, rhythm plays only a subordinate role. The music dictionary of Barlow and Morgenstern [2] shows that music retrieval based on pitch information only leads to results with typically too many false matches. (An example of such absurd matches is given in Selfridge-Field [6], p. 27.) We are convinced that both pitch and rhythm are crucial for recognizing melodies. In the more general context of polyphonic music, one is even forced to consider pitch and rhythm information. PROMS, a web-based computer-music service under development at the University of Bonn, Germany, is part of the MiDiLiB project [5]. The aim of PROMS is to design and to implement PROcedures for Music Search. Our discussion will take place in a rather general setting: we assume that our database contains several kinds of music such as polyphonic and homophonic music as well as melodies. We also use score-like information. A query to the database is a fragment of a piece of music. This could be a melody or a certain ﬁgure of an accompaniment. The task is now to locate eﬃciently all occurences of this fragment in all pieces of music in the database."
9,Dave Cliff;Heppie Freeburn,Exploration of Point-Distribution Models for Similarity-based Classification and Indexing of Polyphonic Music.,2000,https://doi.org/10.5281/zenodo.1416572,"Dave Cliff, Hewlett-Packard Labs, GBR, company;Heppie Freeburn, Hewlett-Packard Labs, GBR, company","Similarity is an intuitive criterion for indexing and classification of digital audio files in music information retrieval systems. While significant work has been done on similarity-based approaches to monophonic music, methods for reliably dealing with databases of arbitrary polyphonic music remain elusive. In this paper we describe our ongoing research in exploring the use of high-order multivariate statistical techniques for similarity-based classification of polyphonic music in digital audio files. The statistical techniques we employ, known as point distribution models (PDMs), have recently proven to be of surprising value in computer vision research for rating visual similarity; here we are attempting to apply PDMs to musical similarity. This involves creating neural networks that approximate the statistical processing, to save on potentially explosive storage and processor requirements. This paper reports on work in progress: our results to date are inconclusive and somewhat negative. We describe our rationale for exploring PDMs in polyphonic music similarity-rating and discuss the problems we have encountered so far, with the intention of encouraging other members of the music information retrieval community to explore this and related approaches."
10,Maxime Crochemore;Costas S. Iliopoulos;Yoan J. Pinzón,Finding Motifs with Gaps.,2000,https://doi.org/10.5281/zenodo.1415986,"Maxime Crochemore, Université de Marne-la-Vallée, FRA, education;Wojciech Rytter, Uniwersytet Warszawski, POL, education, University of Liverpool, GBR, education;Costas S. Iliopoulos, King's College London, GBR, education, Curtin University of Technology, AUS, education;Yoan J. Pinzon, King's College London, GBR, education, Curtin University of Technology, AUS, education","This paper focuses on a set of string pattern-matching problems that arise in musical analysis, and
especially in musical information retrieval. A musical score can be viewed as a string: at a very
rudimentary level, the alphabet could simply be the set of notes in the chromatic or diatonic
notation, or the set of intervals that appear between notes (e.g. pitch may be represented as MIDI
numbers and pitch intervals as number of semitones)."
11,Jon W. Dunn,Beyond VARIATIONS: Creating a Digital Music Library.,2000,https://doi.org/10.5281/zenodo.1415148,"Jon W. Dunn, Indiana University, USA, education","This presentation will focus primarily on work being done at Indiana University in the area of digital music libraries, with some discussion of related efforts."
12,Jonathan Foote,ARTHUR: Retrieving Orchestral Music by Long-Term Structure.,2000,https://doi.org/10.5281/zenodo.1416644,"Jonathan Foote, FX Palo Alto Laboratory, Inc., USA, company",""""""
13,Anastasia Georgaki;Spyros Raptis;Stelios Bakamidis,A Music Interface for Visually Impaired People in the WEDELMUSIC Environment. Design and Architecture.,2000,https://doi.org/10.5281/zenodo.1417291,"Anastasia Georgaki, Institute for Language and Speech Processing, GRC, facility;Spyros Raptis, Institute for Language and Speech Processing, GRC, facility;Stelios Bakamidis, Institute for Language and Speech Processing, GRC, facility","""In this poster we present the architecture of a new music interface for blind musicians, integrated in the WEDELMUSIC1 environment which is under development at ILSP2. Our scope is to facilitate the access of visually impaired  persons  to musical databases (scores, audio and MIDI files) via Internet and give them the possibility  to edit  and create musical scores."""
14,Michael Good,Representing Music Using XML.,2000,https://doi.org/10.5281/zenodo.1415032,"Michael Good, Recordare, USA, company","Why does the world need another music representation language? Beyond MIDI describes over 
20 different languages or musical codes (Selfridge-Field, 1997). Most commercial music 
programs have their own internal, proprietary music representation and file format. Music's 
complexity has led to this proliferation of languages and formats. Sequencers, notation programs, 
analysis tools, and retrieval tools all need musical information optimized in different ways. 
 
Yet no music interchange language has been widely adopted since MIDI. MIDI has contributed to 
enormous growth in the electronic music industry, but has many well-known limitations for 
notation, analysis, and retrieval. These include its lack of representation of musical concepts such 
as rests and enharmonic pitches (distinguishing Db from C#), as well as notation concepts such as 
stem direction and beaming. Other interchange formats such as NIFF and SMDL overcome these 
restrictions, but have not been widely adopted. 
 
Successful interchange formats such as MIDI and HTML share a common trait that NIFF and 
SMDL lack. MIDI and HTML skillfully balance simplicity and power. They are simple enough 
for many people to learn, and powerful enough for many real-world applications. The simplicity 
makes it easy for software developers to implement the standards and to develop encoding tools 
for musicians. This helps circumvent the “chicken-and-egg” problem with new formats. 
 
XML (Extensible Markup Language) is a World Wide Web Consortium (W3C) recommendation 
for representing structured data in text, designed for ease of usage over the Internet by a wide 
variety of applications. XML is a meta-markup language that lets designers and communities 
develop their own representation languages for different applications. Like HTML and MIDI, it 
balances simplicity and power in a way that has made it very attractive to software developers. 
 
The common base of XML technology lets developers of new languages focus on representation 
issues instead of low-level software development. All XML-based languages can be processed by 
a variety of XML tools available from multiple vendors. Since XML files are text files, users of 
XML files always have generic text-based tools available as a lowest common denominator. 
XML documents are represented in Unicode, providing support for international score exchange. 
 
MusicXML is an XML-based music interchange language. It represents common western musical 
notation from the 17th century onwards, including both classical and popular music. The language 
is designed to be extensible to future coverage of early music and less standard 20th and 21st 
century scores. Non-western musical notations would use a separate XML language. As an 
interchange language, it is designed to be sufficient, not optimal, for diverse musical applications. 
MusicXML is not intended to supersede other languages that are optimized for specific musical 
applications, but to support sharing of musical data between applications."
15,Perfecto Herrera-Boyer;Xavier Amatriain;Eloi Batlle;Xavier Serra,Towards Instrument Segmentation for Music Content Description: a Critical Review of Instrument Classification Techniques.,2000,https://doi.org/10.5281/zenodo.1416768,"Perfecto Herrera, Pompeu Fabra University, ESP, education;Xavier Amatriain, Pompeu Fabra University, ESP, education;Eloi Batlle, Pompeu Fabra University, ESP, education;Xavier Serra, Pompeu Fabra University, ESP, education",""""""
16,David Huron,Perceptual and Cognitive Applications in Music Information Retrieval.,2000,https://doi.org/10.5281/zenodo.1414794,"David Huron, Ohio State University, USA, education","Music librarians and cataloguers have traditionally created indexes that allow users to access musical
works using standard reference information, such as the name of the composer or the title of the work.
While this basic information remains important, these standard reference tags have surprisingly limited
applicability in most music-related queries.
Music is used for an extraordinary variety of purposes: the restaurateur seeks music that targets a certain
clientele; the aerobics instructor seeks a certain tempo; the ﬁlm director seeks music conveying a certain
mood; an advertiser seeks a tune that is highly memorable; the physiotherapist seeks music that will
motivate a patient; the truck driver seeks music that will keep him/her alert. Although there are many
other uses for music, music’s preeminent functions are social and psychological. The most useful
retrieval indexes are those that facilitate searching according to such social and psychological functions.
Typically, such indexes will focus on stylistic, mood, and similarity information.
In attempting to build such musical indexes, two general questions arise: (1) What is the best taxonomic
system by which to classify moods, styles, and other musical characteristics? (2) How can we create
automated systems that will reliably characterize recordings or scores?
Internet-based music distribution has brought these two questions to the fore. In the case of proprietary
musical databases, the second problem can be centrally managed, and perhaps addressed using manual
methods. However, past experience with Internet access to text documents implies that non-proprietary
decentralized indexing is likely to prove more popular and successful. That is, future music indexes will
likely resemble web-wide search engines (like Infoseek or Google) rather than closed proprietary systems
(like Beatscape or Encyclopedia Britannica).
The problem of building musical web crawlers that traverse the web and index music-related ﬁles (such as
MP3) should prove challenging. The enabling technology for such musical web crawlers will need to
draw extensively on research in music perception and cognition. Consider two sample problems: music
summarization and mood characterization."
17,Mari Itoh,Subject Search for Music: Quantitative Analysis of Access Point Selection.,2000,https://doi.org/10.5281/zenodo.1414950,", ",""""""
18,Özgür Izmirli,Using a Spectral Flatness Based Feature for Audio Segmentation and Retrieval.,2000,https://doi.org/10.5281/zenodo.1416438,"Ozgur Izmirli, Center for Arts and Technology, Connecticut College, USA, education","A method that utilizes a spectral flatness based tonality feature for segmentation and content-based retrieval of audio is outlined. The method uses the tonality measure which is derived from the discrete bark spectrum as a means of detecting transitions between tonal and noise-like parts of the audio input. The meaning of ‘tonal’ in this context is different from the music-theoretical meaning and implies that there are dominant sinusoidal components in the spectrum, but, does not indicate that they are consonant or harmonic in any sense. Segmentation is performed by determining the times of these transitions, hence providing reference points for search purposes. Search is carried out by pivoting the query information on these reference points. The cumulative distance between the tonality pattern in successive frames of the query and the candidate sound fragments is used as a measure of similarity."
19,Kjell Lemström;Sami Perttu,SEMEX - An efficient Music Retrieval Prototype.,2000,https://doi.org/10.5281/zenodo.1415908,"Kjell Lemström, University of Helsinki, FIN, education;Sami Perttu, University of Helsinki, FIN, education","""We present an efficient prototype for music information retrieval. The prototype uses bit-parallel algorithms for locating transposition invariant matches of monophonic query melodies within monophonic or polyphonic music stored in a database. When dealing with monophonic music, we employ a fast approximate bit-parallel algorithm with special edit distance metrics. The fast scanning phase is succeeded by verification where a separate metrics is used for ranking matches. We also offer the possibility to search for exact occurrences of a ‘distributed’ melody within polyphonic databases via a bit-parallel filtering technique. In our experiments with a database of 2 million musical elements (notes in a monophonic and chords in a polyphonic database) the responses were obtained within one second in both cases. Furthermore, our prototype is capable of using various interval classes in matching, producing more approximation when it is needed."""
20,Francis J. Kiernan,Score-based Style Recognition Using Artificial Neural Networks.,2000,https://doi.org/10.5281/zenodo.1416626,"Francis J. Kiernan, University of Jyväskylä, FIN, education",""""""
21,Youngmoo E. Kim;Wei Chai;Ricardo García;Barry Vercoe,Analysis of a Contour-based Representation for Melody.,2000,https://doi.org/10.5281/zenodo.1416760,"Youngmoo E. Kim, MIT Media Lab, USA, education;Wei Chai, MIT Media Lab, USA, education;Ricardo Garcia, MIT Media Lab, USA, education;Barry Vercoe, MIT Media Lab, USA, education","Identifying a musical work from a melodic fragment is a task that most people are able to
accomplish with relative ease. For some time now researchers have worked to give computers
this ability as well, as it would be the cornerstone of any query-by-humming system. To
accomplish this, it is reasonable to study how humans are able to perform this task, and to assess
what features we use to determine melodic similarity. Research has shown that melodic contour is
an important feature in determining melodic similarity, but it is also clear that rhythmic
information is important as well. The goal of this research is to explore what variation of contour
and rhythmic information can result in the most efficient, robust, and scalable representation for
melody. We intend for this to be the basis of a query-by-humming system that will be used to test
the validity of our proposed representation."
22,Steve Larson,"Searching for Meaning: Melodic Patterns, Combinations, and Embellishments.",2000,https://doi.org/10.5281/zenodo.1415738,"Steve Larson, University of Oregon, USA, education","I am interested in the search for musical patterns -- not so much because I want to find particular patterns, but because I want to understand musical meaning and I believe that musical meaning is something that listeners create when they relate musical patterns to one another, and when they relate musical patterns to other sorts of patterns.   

I describe a theory of musical meaning that argues that experienced listeners of tonal music hear musical motion metaphorically, as purposeful action within a dynamic field of musical forces (musical gravity, magnetism, and inertia).  That theory has been used to clarify issues in Schenkerian theory, to analyze music in many styles, to improve the training of musicians, to account for experimental results in melodic expectation, to explain striking regularities in published analyses of tonal music, and even to illuminate the phenomenon of ""swing"" in jazz.   

The assumptions of that theory generate a small set of patterns and pattern combinations.  This small set of patterns crops up over and over again in tonal music.  Recognizing these patterns and their significance requires seeing how they are embellished in particular pieces. I illustrate these patterns, their combinations and embellishments, and something about their meaning by analyzing several folk songs, including ""Ah, vous dirai-je, Maman"" and Mozart's variations on it.   

The ubiquity of this small set of patterns raises interesting questions about searching for musical patterns, about the role of computers in information retrieval vs their role in musical artificial intelligence, and about musical meaning.  My presentation ends with a series of such questions.   "
23,Mary Levering,"Intellectual Property Rights in Musical Works: Overview, Digital Library Issues and Related Initiatives.",2000,https://doi.org/10.5281/zenodo.1416786,"Mary Levering, U.S. Copyright Office, Library of Congress, USA, facility","""Our nation’s Founding Fathers incorporated copyright principles into the U.S. Constitution in order to 
foster the creation and dissemination of intellectual works for the public good.1  The federal copyright law 
supports these goals by permitting authors to reap rewards from their creative efforts for limited periods of 
time, while also benefitting subsequent creators by allowing them to use and build on prior works under certain 
circumstances.    Thus, in order to stimulate originality and creativity, creators and owners of musical works are 
granted an exclusive bundle of rights in their copyrighted musical works for the enrichment of our society.  
Awareness of these rights is essential for all potential users, even for academics and scholars who wish to use 
these musical works for educational or other research purposes.  Many musical works, especially those 
embodied in phonorecords, CD-ROMs and other audio-visual formats, have multiple layers of intellectual 
property rights involved.2  Scholars and institutions must respect these rights when digitizing, transmitting, 
retrieving or otherwise using copyrighted musical works in electronic formats.  Even when underlying musical 
compositions are in the public domain, the version being used may include new copyrightable authorship that 
must be considered.  Such authorship could include new arrangements, revised lyrics or music, other editorial 
revisions of the musical work itself, or—where the work is fixed as a series of sounds—it could include all or 
some new sounds, a remix of sounds, and so forth. 
 
Understanding concepts such as (1) the whole range of rightsholders’ exclusive rights in musical 
works,3 (2) the statutory limitations on these rights,4 including how the Fair Use 5 doctrine can be applied 
reasonably for educational and scholarly purposes, (3) when authorization is needed, (4) who the rightsholders 
are,6 and (5) how to secure required permissions efficiently and easily,7 have all become increasingly important"""
24,Karen Lin;Tim Bell,Integrating Paper and Digital Music Information Systems.,2000,https://doi.org/10.5281/zenodo.1416544,"Karen Lin, University of Canterbury, NZL, education;Tim Bell, University of Canterbury, NZL, education","Active musicians generally rely on extensive personal paper-based music information retrieval systems containing scores, parts, compositions, and arrangements of published and hand-written music. Many have a bias against using computers to store, edit and retrieve music, and prefer to work in the paper domain rather than using digital documents, despite the flexibility and powerful retrieval opportunities available. In this paper we propose a model of operation that blurs the boundaries between the paper and digital domains, offering musicians the best of both worlds. A survey of musicians identifies the problems and potential of working with digital tools, and we propose a system using colour printing and scanning technology that simplifies the process of moving music documents between the two domains."
25,Beth Logan,Mel Frequency Cepstral Coefficients for Music Modeling.,2000,https://doi.org/10.5281/zenodo.1416444,", ",""""""
26,Donald MacLellan;Carola Boehm,MuTaTeD'll: A System for Music Information Retrieval of Encoded Music.,2000,https://doi.org/10.5281/zenodo.1417755,"Donald MacLellan, University of Glasgow, GBR, education;Carola Boehm, University of Glasgow, GBR, education","MuTaTeD'II started in November 1999, building on the results of the MuTaTeD project. Its aim is to design and implement a music information retrieval system with delivery/access services for encoded music. The prototype service will provide a user friendly, web-based search/browse/query interface to access musical content."
27,Jeremy Pickens,A Comparison of Language Modeling and Probabilistic Text Information Retrieval Approaches to Monophonic Music Retrieval.,2000,https://doi.org/10.5281/zenodo.1415100,"Jeremy Pickens, University of Massachusetts, USA, education","""With interest in music information retrieval increasing the need for retrieval systems unique to music is also growing. Despite its unique properties music shares many similarities with text. The goal of this paper is to explore some of the capabilities and limitations of current text information retrieval systems as applied to the task of music retrieval. Monophonic music is converted into text and retrieval experiments are run using two different text information retrieval systems in various conﬁgurations. Finally, we will discuss whether the techniques applied here are generalizable to the larger problem of polyphonic music retrieval."""
28,Perry Roland,XML4MIR: Extensible Markup Language for Music Information Retrieval.,2000,https://doi.org/10.5281/zenodo.1417167,"Perry Roland, University of Virginia, USA, education","""This paper evaluates the role of standards in information exchange and suggests the adoption of XML standards for music representation and meta-data to serve as the basis for music information retrieval."""
29,Jochen Schimmelpfennig;Frank Kurth,MCML - Music Contents Markup Language.,2000,https://doi.org/10.5281/zenodo.1415526,"Jochen Schimmelpfennig, University of Bonn, DEU, education;Frank Kurth, University of Bonn, DEU, education","""We present an XML-based description interface for various types of musical contents - MCML, Music Contents Markup Language. An application of  MCML currently developed within our group is a music browser system which enables a content based navigation in digital music files. Another major application of a music contents annotation interface is the description and handling of query results to digital music libraries."""
30,Eleanor Selfridge-Field,What Motivates a Musical Query?.,2000,https://doi.org/10.5281/zenodo.1415970,", ",""""""
31,Perry R. Cook;George Tzanetakis,Audio Information Retrieval (AIR) Tools.,2000,https://doi.org/10.5281/zenodo.1416716,,""""""
32,Alexandra L. Uitdenbogerd,"Music IR: Past, Present, and Future.",2000,https://doi.org/10.5281/zenodo.1417545,"Alexandra L. Uitdenbogerd, RMIT University, AUS, education;Abhijit Chattaraj, RMIT University, AUS, education;Justin Zobel, RMIT University, AUS, education","Music Information Retrieval has a longer history than most people realise, with systems developed in the 1960's.  The field has its roots in information retrieval, musicology and music psychology.  Information retrieval has provided us with a framework for evaluating retrieval systems. Musicologists have applied various techniques to measure stylistic parameters of composers and general similarity of musical works.  Music perception research has taught us that contour is the most important feature of melody for listeners (Dowling 1978).  Precursors to computerised music IR are the incipit and theme indexes such as Barlow and Morganstern's dictionary of musical themes (Barlow and Morganstern 1948), however, on-line collections with incipit indexes were soon to follow (for example Hudson 1970)."
33,Alexandra L. Uitdenbogerd;Justin Zobel,Music Ranking Techniques Evaluated.,2000,https://doi.org/10.5281/zenodo.1414990,"Alexandra L. Uitdenbogerd, RMIT University, AUS, education;Justin Zobel, RMIT University, AUS, education","""Several techniques have been proposed for matching melody queries to stored music. In previous work [2], we found that local alignment, a technique derived from bioinformatics, was more effective than the n-gram methods derived from information retrieval that are used in other work. In this paper we explore a broader range of n-gram techniques, and test them with both manual queries and queries automatically extracted from MIDI files. Our experiments show that alternative - indeed, simpler - n-gram matching techniques than those tested in earlier work can be as effective as local alignment; one highly effective technique is to simply count the number of 5-grams in common between query and stored piece of music. N-grams are particularly effective for short queries and manual queries, while local alignment is superior for the automatic queries."""
34,Thomas von Schroeter;Shyamala Doraisamy;Stefan M. Rüger,From Raw Polyphonic Audio to Locating Recurring Themes.,2000,https://doi.org/10.5281/zenodo.1416124,"Thomas von Schroeter, Imperial College of Science, Technology and Medicine, GBR, education;Shyamala Doraisamy, University Putra Malaysia, MYS, education;Stefan M Rüger, Imperial College of Science, Technology and Medicine, GBR, education","""We present research studies of two related strands in content-based music retrieval: the automatic transcription of raw audio from a single polyphonic instrument with discrete pitch (eg piano) and the location of recurring themes from a Humdrum score."""
