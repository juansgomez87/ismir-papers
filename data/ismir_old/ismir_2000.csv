Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,David Bainbridge 0001,The role of Music IR in the New Zealand Digital Music Library project.,2000,https://doi.org/10.5281/zenodo.1416260,"David Bainbridge, Department of Computer Science, University of Waikato","This extended abstract describes the computer music work that forms part of the New Zealand Digital Library (NZDL) project. The music work investigates data acquisition, retrieval, presentation, and scalability. The MELDEX system supports searching through text and sung queries, and browsing through automatically compiled lists of metadata. The system includes collections of popular tunes derived from sheet music, folksongs donated by other computer music projects, and MIDI files gathered from the web. The acquisition methods include automatic conversion of sheet music using Optical Music Recognition (OMR) software, online MIDI files, and existing databases of music in symbolic form. The OMR software has been extended to merge the reconstructed score with a MIDI rendition to boost accuracy rates."
1,Eloi Batlle;Pedro Cano,Automatic Segmentation for Music Classification using Competitive Hidden Markov Models.,2000,https://doi.org/10.5281/zenodo.1416764,"Eloi Batlle, Audiovisual Institute. Universitat Pompeu Fabra;Pedro Cano, Audiovisual Institute. Universitat Pompeu Fabra","Music information retrieval has become a major topic in recent years, leading to the growth of audio databases. However, the usefulness of these databases relies on their organization and structure. In this paper, we introduce a new audio classification tool that automatically segments audio material in a fully unsupervised way. The segments are labeled based on their psychoacoustic properties, allowing for fast indexing and retrieval of audio fragments. This segmentation is done using competitive hidden Markov models, which do not require previous classified or hand-labeled data. We also demonstrate that these models converge to a realistic segmentation architecture."
2,Juan Pablo Bello;Giuliano Monti;Mark B. Sandler,Techniques for Automatic Music Transcription.,2000,https://doi.org/10.5281/zenodo.1414872,"Juan Pablo Bello, Department of Electronic Engineering, King’s College London;Giuliano Monti, Department of Electronic Engineering, King’s College London;Mark Sandler, Department of Electronic Engineering, King’s College London","Two systems are reviewed than perform automatic music transcription. The first perform monophonic transcription using an autocorrelation pitch tracker. The algorithm takes advantage of some heuristic parameters related to the similarity between image and sound in the collector. The detection is correct between notes B1 to E6 and further timbre analysis will provide the necessary parameters to reproduce a similar copy of the original sound. The second system is able to analyse simple polyphonic tracks. It is composed of a blackboard system, receiving its input from a segmentation routine in the form of an averaged STFT matrix. The blackboard contents an hypotheses database, an scheduler and knowledge sources, one of which is a neural network chord recogniser with the ability to reconfigure the operation of the system, allowing it to output more than one note hypothesis at the time. Some examples are provided to illustrate the performance and the weaknesses of the current implementation. Next steps for further development are defined."
3,Daniel Bendor;Mark B. Sandler,Time Domain Extraction of Vibrato from Monophonic Instruments.,2000,https://doi.org/10.5281/zenodo.1416810,"Daniel Bendor, Undergraduate School of Electrical Engineering, University of Maryland at College Park;Mark Sandler, Department of Electronic Engineering, King's College London",""""""
4,Alain Bonardi,IR for Contemporary Music: What the Musicologist Needs.,2000,https://doi.org/10.5281/zenodo.1415912,"Alain Bonardi, IRCAM","Active listening is the core of musical activity. Listening is not passive, but rather an active process of interaction between listeners and musical documents. This process involves recognizing regularities and rules to interpret the intentions of the composer. Computer-assisted listening, such as in a digital library like IRCAM's, provides the musicologist with various tools and representations to aid in this process. The ability to associate different representations and contexts is crucial for the analysis and interpretation of music."
5,Wei Chai;Barry Vercoe,Using User Models in Music Information Retrieval Systems.,2000,https://doi.org/10.5281/zenodo.1415898,"Wei Chai, Media Laboratory, Massachusetts Institute of Technology;Barry Vercoe, Media Laboratory, Massachusetts Institute of Technology","Most websites providing music services only support category-based browsing and/or text-based searching. There has been some research to improve the interface either for pull applications, e.g. query-by-humming systems, or for push applications, e.g. collaborative-filtering-based or feature-based music recommendation systems. However, for content-based search or feature-based filtering systems, one important problem is to describe music by its parameters or features, so that search engines or information filtering agents can use them to measure the similarity of the target (user's query or preference) and the candidates. MPEG7 (formally called ""Multimedia Content Description Interface"") is an international standard, which describes the multimedia content data to allow universal indexing, retrieval, filtering, control, and other activities supported by rich metadata. However, the metadata about the multimedia content itself are still insufficient, because many features of multimedia content are quite perceptual and user-dependent. For example, emotional features are very important for multimedia retrieval, but they are hard to be described by a universal model since different users may have different emotional responses to the same multimedia content. We therefore turn to user modeling techniques and representations to describe the properties of each user, so that the retrieval will be more accurate. Besides, user modeling can be used to reduce the search space, make push service easier and improve the user interface."
6,Arbee L. P. Chen,"Music Representation, Indexing and Retrieval at NTHU.",2000,https://doi.org/10.5281/zenodo.1417981,"Arbee L.P. Chen, Department of Computer Science, National Tsing Hua University","In this extended abstract, our work on the representation, indexing and retrieval of music data is summarized. We treat the rhythm, melody, and chords of a music object as music features and develop various data structures and algorithms to efficiently perform approximate and partial matching for the retrieval of music data. In [Chen00a], we present the techniques for retrieving songs by music segments. A music segment consists of a segment type and the associated beat and pitch information. We also propose multi-feature index structures for exact and approximate searching on different features. The problem of feature extraction is also studied. The repeating pattern is defined as a sequence of notes, which appears more than once in music objects. Choosing repeating patterns as the feature to represent the music objects meets both efficiency and semantic-richness requirements for content-based music data retrieval. We propose approaches to efficiently discover the repeating patterns of music objects. We have also implemented Muse, a prototype system for content-based music data retrieval to illustrate the feasibility of the concepts we propose."
7,G. Sayeed Choudhury;M. Droetboom;Tim DiLauro;Ichiro Fujinaga;Brian Harrington,Optical Music Recognition System within a Large-Scale Digitization Project.,2000,https://doi.org/10.5281/zenodo.1415730,"G. Sayeed Choudhury, Digital Knowledge Center, Milton S. Eisenhower Library, Johns Hopkins University;Tim DiLauro, ;Michael Droettboom, ;Ichiro Fujinaga, ;Brian Harrington, ;Karl MacMillan, ;, Peabody Conservatory of Music, Johns Hopkins University","An adaptive optical music recognition system is being developed as part of an experiment in creating a comprehensive framework of tools to manage the workflow of large-scale digitization projects. This framework will support the path from physical object and/or digitized material into a digital library repository, and offer effective tools for incorporating metadata and perusing the content of the resulting multimedia objects."
8,Michael Clausen;R. Engelbrecht;D. Meyer;J. Schmitz,PROMS: A Web-based Tool for Searching in Polyphonic Music.,2000,https://doi.org/10.5281/zenodo.1417139,"M. Clausen, Institut f¨ur Informatik V, Universit¨at Bonn;R. Engelbrecht, Institut f¨ur Informatik V, Universit¨at Bonn;D. Meyer, Institut f¨ur Informatik V, Universit¨at Bonn;J. Schmitz, Institut f¨ur Informatik V, Universit¨at Bonn","One major task of a digital music library (DML) is to provide techniques to locate a queried musical pattern in all pieces of music in the database containing that pattern. For a survey of several computational tasks related to this kind of data retrieval we refer to Crawford et al. [3]. Existing DMLs like MELDEX [1], Themeﬁnder [4], and the Sonoda-Muraoka-System [7] work with melody databases relying on score-like information. Retrieval and matching are performed in a fault-tolerant way by string-based methods which mainly take into account pitch information. Generally, rhythm plays only a subordinate role. The music dictionary of Barlow and Morgenstern [2] shows that music retrieval based on pitch information only leads to results with typically too many false matches. (An example of such absurd matches is given in Selfridge-Field [6], p. 27.) We are convinced that both pitch and rhythm are crucial for recognizing melodies. In the more general context of polyphonic music, one is even forced to consider pitch and rhythm information. PROMS, a web-based computer-music service under development at the University of Bonn, Germany, is part of the MiDiLiB project [5]. The aim of PROMS is to design and to implement PROcedures for Music Search. Our discussion will take place in a rather general setting: we assume that our database contains several kinds of music such as polyphonic and homophonic music as well as melodies. We also use score-like information. A query to the database is a fragment of a piece of music. This could be a melody or a certain ﬁgure of an accompaniment. The task is now to locate eﬃciently all occurences of this fragment in all pieces of music in the database. We have designed and implemented a web-based computer-music service that enables seaching in polyphonic music. In contrast to the above mentioned systems, PROMS is not string-based but set-oriented. The basic objects within the PROMS system are single notes, speciﬁed by its onset time t, its pitch p, and its duration d. A piece of music is then a ﬁnite set M of notes. Our database consists of a sequence of N pieces of music in the MIDI format: D1, . . . , DN. Similarly, a query is itself a ﬁnite set Q of notes. Thus there is no principal diﬀerence between a piece Di of music in the database and a query Q. However, typically, Di is much larger than Q. An occurrence is a pair."
9,Dave Cliff;Heppie Freeburn,Exploration of Point-Distribution Models for Similarity-based Classification and Indexing of Polyphonic Music.,2000,https://doi.org/10.5281/zenodo.1416572,"Dave Cliff, Hewlett-Packard Labs;Heppie Freeburn, Hewlett-Packard Labs","Similarity-based classification and indexing of polyphonic music remains a challenge in music information retrieval systems. In this paper, we explore the use of high-order multivariate statistical techniques known as point distribution models (PDMs) for similarity-based classification of polyphonic music in digital audio files. Our results so far are inconclusive and somewhat negative, but we discuss the rationale behind exploring PDMs in polyphonic music similarity-rating and encourage others in the music retrieval community to explore this approach."
10,Maxime Crochemore;Costas S. Iliopoulos;Yoan J. Pinzón,Finding Motifs with Gaps.,2000,https://doi.org/10.5281/zenodo.1415986,"Maxime Crochemore, Institut Gaspard-Monge, Laboratoire d'informatique, Université de Marne-la-Vallée;Wojciech Rytter, Uniwersytet Warszawski, Banacha 2, 02--097, Warszawa, Poland, and Department of Computer Science, University of Liverpool, Liverpool L69 7ZF, UK.;Costas S. Iliopoulos and Yoan J. Pinzon, Dept. Computer Science, King's College London, London WC2R 2LS, UK, and School of Computing, Curtin University of Technology, GPO Box 1987 U, WA. Australia","This paper focuses on a set of string pattern-matching problems that arise in musical analysis, and especially in musical information retrieval. An important example of flexibility required in score searching arises from the nature of polyphonic music. Within a certain time span each of the simultaneously-performed voices in a musical composition does not, typically, contain the same number of notes. So ‘melodic events’ occurring in one voice may be separated from their neighbours in a score by intervening events in other voices. Since we cannot generally rely on voice information being present in the score we need to allow for temporal ‘gaps’ between events in the matched pattern. Typically, the magnitude of such a gap (which might be expressed as a maximum time value, or, more probably, as a maximum number of skipped event-time-slots) will be a parameter set by the user. In our mathematical treatment the allowance for gaps in the query and the score being searched is represented by the constant α."
11,Jon W. Dunn,Beyond VARIATIONS: Creating a Digital Music Library.,2000,https://doi.org/10.5281/zenodo.1415148,"Jon W. Dunn, Indiana University","This presentation will focus primarily on work being done at Indiana University in the area of digital music libraries, with some discussion of related efforts. Indiana University’s VARIATIONS system serves as both an early example of a working digital library supporting music content and an early application of World Wide Web technologies to music. Since April 1996, the system has provided online access within the William and Gayle Cook Music Library to sound recordings from the library’s collections. Unlike many early university-based digital library projects whose primary goals were to provide broader access to unique and/or archival collections, VARIATIONS has built its digital collection from standard musical repertoire identified as central to the teaching mission of the Indiana University School of Music."
12,Jonathan Foote,ARTHUR: Retrieving Orchestral Music by Long-Term Structure.,2000,https://doi.org/10.5281/zenodo.1416644,"Jonathan Foote, FX Palo Alto Laboratory, Inc.","We introduce an audio retrieval-by-example system for orchestral music. Unlike many other approaches, this system is based on analysis of the audio waveform and does not rely on symbolic or MIDI representations. ARTHUR retrieves audio on the basis of long-term structure, specifically the variation of soft and louder passages. The long-term structure is determined from envelope of audio energy versus time in one or more frequency bands. Similarity between energy profiles is calculated using dynamic programming. Given an example audio document, other documents in a collection can be ranked by similarity of their energy profiles. Experiments are presented for a modest corpus that demonstrate excellent results in retrieving different performances of the same orchestral work, given an example performance or short excerpt as a query."
13,Anastasia Georgaki;Spyros Raptis;Stelios Bakamidis,A Music Interface for Visually Impaired People in the WEDELMUSIC Environment. Design and Architecture.,2000,https://doi.org/10.5281/zenodo.1417291,"Anastasia Georgaki, Institute for Language and Speech Processing, Speech Technology Department;Spyros Raptis, Institute for Language and Speech Processing, Speech Technology Department;Stelios Bakamidis, Institute for Language and Speech Processing, Speech Technology Department","In this poster we present the architecture of a new music interface for blind musicians, integrated in the WEDELMUSIC1 environment which is under development at ILSP2. Our scope is to facilitate the access of visually impaired persons to musical databases (scores, audio and MIDI files) via Internet and give them the possibility to edit and create musical scores."
14,Michael Good,Representing Music Using XML.,2000,https://doi.org/10.5281/zenodo.1415032,"Michael Good, Recordare","Why does the world need another music representation language? Beyond MIDI describes over 20 different languages or musical codes (Selfridge-Field, 1997). Most commercial music programs have their own internal, proprietary music representation and file format. Music's complexity has led to this proliferation of languages and formats. Sequencers, notation programs, analysis tools, and retrieval tools all need musical information optimized in different ways. Yet no music interchange language has been widely adopted since MIDI. MIDI has contributed to enormous growth in the electronic music industry, but has many well-known limitations for notation, analysis, and retrieval. These include its lack of representation of musical concepts such as rests and enharmonic pitches (distinguishing Db from C#), as well as notation concepts such as stem direction and beaming. Other interchange formats such as NIFF and SMDL overcome these restrictions, but have not been widely adopted. Successful interchange formats such as MIDI and HTML share a common trait that NIFF and SMDL lack. MIDI and HTML skillfully balance simplicity and power. They are simple enough for many people to learn, and powerful enough for many real-world applications. The simplicity makes it easy for software developers to implement the standards and to develop encoding tools for musicians. This helps circumvent the “chicken-and-egg” problem with new formats. XML (Extensible Markup Language) is a World Wide Web Consortium (W3C) recommendation for representing structured data in text, designed for ease of usage over the Internet by a wide variety of applications. XML is a meta-markup language that lets designers and communities develop their own representation languages for different applications. Like HTML and MIDI, it balances simplicity and power in a way that has made it very attractive to software developers. The common base of XML technology lets developers of new languages focus on representation issues instead of low-level software development. All XML-based languages can be processed by a variety of XML tools available from multiple vendors. Since XML files are text files, users of XML files always have generic text-based tools available as a lowest common denominator. XML documents are represented in Unicode, providing support for international score exchange. MusicXML is an XML-based music interchange language. It represents common western musical notation from the 17th century onwards, including both classical and popular music. The language is designed to be extensible to future coverage of early music and less standard 20th and 21st century scores. Non-western musical notations would use a separate XML language. As an interchange language, it is designed to be sufficient, not optimal, for diverse musical applications. MusicXML is not intended to supersede other languages that are optimized for specific musical applications, but to support sharing of musical data between applications. The current MusicXML software runs on Windows. As of September 2000, it reads 100% of the MuseData format plus portions of NIFF and Finale’s Enigma Transportable Files (ETF). It writes to Standard MIDI Files in Format 1, MuseData files, and Sibelius. The NIFF, ETF, and MIDI converters use XML versions of these languages as intermediate structures. MusicXML is defined using an XML Document Type Definition (DTD) at www.musicxml.com/xml.html. XML Schemas address some shortcomings of DTDs, but are not yet a W3C recommendation."
15,Perfecto Herrera-Boyer;Xavier Amatriain;Eloi Batlle;Xavier Serra,Towards Instrument Segmentation for Music Content Description: a Critical Review of Instrument Classification Techniques.,2000,https://doi.org/10.5281/zenodo.1416768,"Perfecto Herrera, Audiovisual Institute - Pompeu Fabra University;Xavier Amatriain, Audiovisual Institute - Pompeu Fabra University;Eloi Batlle, Audiovisual Institute - Pompeu Fabra University;Xavier Serra, Audiovisual Institute - Pompeu Fabra University","A system capable of describing the musical content of any kind of sound file or sound stream, as it is supposed to be done in MPEG7-compliant applications, should provide an account of the different moments where a certain instrument can be listened to. In this paper we concentrate on reviewing the different techniques that have been so far proposed for automatic classification of musical instruments. As most of the techniques to be discussed are usable only in ""solo"" performances we will evaluate their applicability to the more complex case of describing sound mixes. We conclude this survey discussing the necessity of developing new strategies for classifying sound mixes without a priori separation of sound sources."
16,David Huron,Perceptual and Cognitive Applications in Music Information Retrieval.,2000,https://doi.org/10.5281/zenodo.1414794,"David Huron, Cognitive and Systematic Musicology Laboratory, School of Music, Ohio State University","Music librarians and cataloguers have traditionally created indexes for accessing musical works based on standard reference information. However, these standard reference tags have limited applicability in most music-related queries. Music serves a variety of purposes, such as targeting a certain clientele, setting a certain tempo, conveying a certain mood, or motivating a patient. The most useful retrieval indexes for music are those that facilitate searching according to social and psychological functions, focusing on stylistic, mood, and similarity information. Building musical web crawlers that index music-related files will require drawing on research in music perception and cognition. One specific challenge is music summarization, where a brief illustrative excerpt can be beneficial before downloading or streaming an entire work."
17,Mari Itoh,Subject Search for Music: Quantitative Analysis of Access Point Selection.,2000,https://doi.org/10.5281/zenodo.1414950,"Smiraglia, ",""""""
18,Özgür Izmirli,Using a Spectral Flatness Based Feature for Audio Segmentation and Retrieval.,2000,https://doi.org/10.5281/zenodo.1416438,"Ozgur Izmirli, Center for Arts and Technology, Department of Mathematics and Computer Science, Connecticut College","A method that utilizes a spectral flatness based tonality feature for segmentation and content-based retrieval of audio is outlined. The method uses the tonality measure which is derived from the discrete bark spectrum as a means of detecting transitions between tonal and noise-like parts of the audio input. Segmentation is performed by determining the times of these transitions, hence providing reference points for search purposes. Search is carried out by pivoting the query information on these reference points. The cumulative distance between the tonality pattern in successive frames of the query and the candidate sound fragments is used as a measure of similarity."
19,Kjell Lemström;Sami Perttu,SEMEX - An efficient Music Retrieval Prototype.,2000,https://doi.org/10.5281/zenodo.1415908,"Kjell Lemström, Department of Computer Science, University of Helsinki;Sami Perttu, Department of Computer Science, University of Helsinki","We present an efficient prototype for music information retrieval. The prototype uses bit-parallel algorithms for locating transposition invariant matches of monophonic query melodies within monophonic or polyphonic music stored in a database. When dealing with monophonic music, we employ a fast approximate bit-parallel algorithm with special edit distance metrics. The fast scanning phase is succeeded by verification where a separate metrics is used for ranking matches. We also offer the possibility to search for exact occurrences of a 'distributed' melody within polyphonic databases via a bit-parallel filtering technique. In our experiments with a database of 2 million musical elements (notes in a monophonic and chords in a polyphonic database) the responses were obtained within one second in both cases. Furthermore, our prototype is capable of using various interval classes in matching, producing more approximation when it is needed."
20,Francis J. Kiernan,Score-based Style Recognition Using Artificial Neural Networks.,2000,https://doi.org/10.5281/zenodo.1416626,"Francis J. Kiernan, Pythagoras Graduate School","The original idea was to develop a system for musicological analysis that was capable of assisting in the resolution of issues concerning compositional authenticity. Based on explicit rule-based interrogation of a musical score the system gathers statistical information by way of a data extraction engine, the subsequent neural network implicitly forms an abstract impression of habitual characteristics within the composition. It must not be assumed that this system aims towards the modeling of human musical perception, as it is the authorÕs belief that score-based analyses cannot adequately meet this task. Initially the system was developed to explore the authenticity of flute compositions attributed to Frederick II ÒThe GreatÓ. Since there has long been musicological debate concerning this matter it was decided to acquire information from both performers of period instruments and musicologists concerning the characteristics and signatures required in the discrimination task. Based on free and multiple-choice reports returned a rule base was compiled that was then implemented into the system. Methodology For the purpose of this study it was decided to create a corpus of score representations in ALMA1, an antiquated and relatively forgotten format. The primary reason for this was the ease of coding without the necessity to sacrifice any of the printed score attributes. Since the system is based on intervallic difference of note relations it was not necessary to transpose the selected material to a common key-signature, which appears to be common practice in similar studies. Aside from the standard frequency of note distribution statistics, horizontal pitch-class ÒsnapshotsÓ are used in order to obtain a rough image of the tonal contents of each measure. Other data is collected from functions stemming from Lerdahl & Jackendoff (1983) theories on tonal music. In a similar manner vertical pitch-class analysis is employed, this method involves the weighting of individual events based on their metric position to obtain a single vector. Weighting of importance of the vertical pitch-class data is crucial for the perceived tonality of each measure (Cook 2000). Strong-weak interplay between parts provides major individualistic cues in the identification process. Auxiliary and passing notes in this instance are not considered since the resolution is restricted to minimal values of 16th notes. Efforts to locate modulations were developed by monitoring the frequency of note occurrence over time. Having established the initial key a scan is run over the score to track any deviation, which is assumed if recurring accidental tones match ÒexpectedÓ modulatory practices. For example when a piece initially established as being in C-major displays a recurring F# it is highly likely that a modulation to the dominant key of G-major has occurred. The sequence recognition algorithm involves the staggered parsing of a back-to-back pair of arrays checking sequences of intervals on the major metric points of the melody. Their function is to identify recurring interval sequences; chromatic, diatonic or pentatonic. The sequences being sought must be concurrent. Motivic interplay as yet cannot be detected."
21,Youngmoo E. Kim;Wei Chai;Ricardo García;Barry Vercoe,Analysis of a Contour-based Representation for Melody.,2000,https://doi.org/10.5281/zenodo.1416760,"Youngmoo E. Kim, Machine Listening Group, MIT Media Lab;Wei Chai, Machine Listening Group, MIT Media Lab;Ricardo Garcia, Machine Listening Group, MIT Media Lab;Barry Vercoe, Machine Listening Group, MIT Media Lab","Identifying a musical work from a melodic fragment is a task that most people are able to accomplish with relative ease. For some time now researchers have worked to give computers this ability as well, as it would be the cornerstone of any query-by-humming system. To accomplish this, it is reasonable to study how humans are able to perform this task, and to assess what features we use to determine melodic similarity. Research has shown that melodic contour is an important feature in determining melodic similarity, but it is also clear that rhythmic information is important as well. The goal of this research is to explore what variation of contour and rhythmic information can result in the most efficient, robust, and scalable representation for melody. We intend for this to be the basis of a query-by-humming system that will be used to test the validity of our proposed representation."
22,Steve Larson,"Searching for Meaning: Melodic Patterns, Combinations, and Embellishments.",2000,https://doi.org/10.5281/zenodo.1415738,"Steve Larson, University of Oregon","I am interested in the search for musical patterns -- not so much because I want to find particular patterns, but because I want to understand musical meaning and I believe that musical meaning is something that listeners create when they relate musical patterns to one another, and when they relate musical patterns to other sorts of patterns. I describe a theory of musical meaning that argues that experienced listeners of tonal music hear musical motion metaphorically, as purposeful action within a dynamic field of musical forces (musical gravity, magnetism, and inertia). That theory has been used to clarify issues in Schenkerian theory, to analyze music in many styles, to improve the training of musicians, to account for experimental results in melodic expectation, to explain striking regularities in published analyses of tonal music, and even to illuminate the phenomenon of ""swing"" in jazz. The assumptions of that theory generate a small set of patterns and pattern combinations. This small set of patterns crops up over and over again in tonal music. Recognizing these patterns and their significance requires seeing how they are embellished in particular pieces. I illustrate these patterns, their combinations and embellishments, and something about their meaning by analyzing several folk songs, including ""Ah, vous dirai-je, Maman"" and Mozart's variations on it. The ubiquity of this small set of patterns raises interesting questions about searching for musical patterns, about the role of computers in information retrieval vs their role in musical artificial intelligence, and about musical meaning. My presentation ends with a series of such questions."
23,Mary Levering,"Intellectual Property Rights in Musical Works: Overview, Digital Library Issues and Related Initiatives.",2000,https://doi.org/10.5281/zenodo.1416786,"Mary Levering, U.S. Copyright Office, Library of Congress","Intellectual Property Rights in Musical Works
Our nation’s Founding Fathers incorporated copyright principles into the U.S. Constitution in order to foster the creation and dissemination of intellectual works for the public good. The federal copyright law supports these goals by permitting authors to reap rewards from their creative efforts for limited periods of time, while also benefitting subsequent creators by allowing them to use and build on prior works under certain circumstances. Thus, in order to stimulate originality and creativity, creators and owners of musical works are granted an exclusive bundle of rights in their copyrighted musical works for the enrichment of our society. Awareness of these rights is essential for all potential users, even for academics and scholars who wish to use these musical works for educational or other research purposes. Many musical works, especially those embodied in phonorecords, CD-ROMs and other audio-visual formats, have multiple layers of intellectual property rights involved. Scholars and institutions must respect these rights when digitizing, transmitting, retrieving or otherwise using copyrighted musical works in electronic formats. Even when underlying musical compositions are in the public domain, the version being used may include new copyrightable authorship that must be considered. Such authorship could include new arrangements, revised lyrics or music, other editorial revisions of the musical work itself, or—where the work is fixed as a series of sounds—it could include all or some new sounds, a remix of sounds, and so forth. Understanding concepts such as (1) the whole range of rightsholders’ exclusive rights in musical works, (2) the statutory limitations on these rights, including how the Fair Use doctrine can be applied reasonably for educational and scholarly purposes, (3) when authorization is needed, (4) who the rightsholders are, and (5) how to secure required permissions efficiently and easily, have all become increasingly important."
24,Karen Lin;Tim Bell,Integrating Paper and Digital Music Information Systems.,2000,https://doi.org/10.5281/zenodo.1416544,"Karen Lin, University of Canterbury, Christchurch, New Zealand;Tim Bell, University of Canterbury, Christchurch, New Zealand","Active musicians often prefer using paper-based music information retrieval systems over digital ones, despite the advantages of digital tools. In this paper, the authors propose a model that integrates paper and digital domains, offering musicians the benefits of both. They conducted a survey to identify the challenges and potential of working with digital tools, and propose a system that simplifies the process of moving music documents between the two domains using color printing and scanning technology."
25,Beth Logan,Mel Frequency Cepstral Coefficients for Music Modeling.,2000,https://doi.org/10.5281/zenodo.1416444,,""""""
26,Donald MacLellan;Carola Boehm,MuTaTeD'll: A System for Music Information Retrieval of Encoded Music.,2000,https://doi.org/10.5281/zenodo.1417755,"Donald MacLellan, Department of Music, University of Glasgow;Carola Boehm, Department of Music, University of Glasgow","MuTaTeD'II started in November 1999, building on the results of the MuTaTeD project. Its aim is to design and implement a music information retrieval system with delivery/access services for encoded music. The prototype service will provide a user friendly, web-based search/browse/query interface to access musical content."
27,Jeremy Pickens,A Comparison of Language Modeling and Probabilistic Text Information Retrieval Approaches to Monophonic Music Retrieval.,2000,https://doi.org/10.5281/zenodo.1415100,"Jeremy Pickens, Department of Computer Science, University of Massachusetts","With interest in music information retrieval increasing the need for retrieval systems unique to music is also growing. Despite its unique properties music shares many similarities with text. The goal of this paper is to explore some of the capabilities and limitations of current text information retrieval systems as applied to the task of music retrieval. Monophonic music is converted into text and retrieval experiments are run using two different text information retrieval systems in various configurations. Finally, we will discuss whether the techniques applied here are generalizable to the larger problem of polyphonic music retrieval."
28,Perry Roland,XML4MIR: Extensible Markup Language for Music Information Retrieval.,2000,https://doi.org/10.5281/zenodo.1417167,"Perry Roland, University of Virginia",Abstract: This paper evaluates the role of standards in information exchange and suggests the adoption of XML standards for music representation and meta-data to serve as the basis for music information retrieval.
29,Jochen Schimmelpfennig;Frank Kurth,MCML - Music Contents Markup Language.,2000,https://doi.org/10.5281/zenodo.1415526,"Jochen Schimmelpfennig and Frank Kurth, Department of Computer Science, University of Bonn","We present an XML-based description interface for various types of musical contents - MCML, Music Contents Markup Language. An application of MCML currently developed within our group is a music browser system which enables a content based navigation in digital music files. Another major application of a music contents annotation interface is the description and handling of query results to digital music libraries."
30,Eleanor Selfridge-Field,What Motivates a Musical Query?.,2000,https://doi.org/10.5281/zenodo.1415970,,The abstract is not available in this context.
31,Perry R. Cook;George Tzanetakis,Audio Information Retrieval (AIR) Tools.,2000,https://doi.org/10.5281/zenodo.1416716,,
32,Alexandra L. Uitdenbogerd,"Music IR: Past, Present, and Future.",2000,https://doi.org/10.5281/zenodo.1417545,"Alexandra L. Uitdenbogerd, Department of Computer Science, RMIT University;Abhijit Chattaraj, Department of Computer Science, RMIT University;Justin Zobel, Department of Computer Science, RMIT University","Music Information Retrieval (MIR) has a long history, dating back to the 1960s. It is rooted in information retrieval, musicology, and music psychology. Over the years, various techniques have been applied to measure stylistic parameters of composers and the similarity of musical works. The current trend in MIR research is the development of systems that can locate answers to queries presented as hummed melodies or entered in other ways. However, comparing these systems is challenging due to the lack of a common data set, queries, or relevance judgments. Evaluating MIR systems requires defining queries, answers, and relevance, which depends on the user's needs. Previous work has used MIDI files to collect queries and relevance judgments, but it remains an open question whether these judgments align with human relevance judgments. Recent work involves collecting manual queries from expert musicians and using listener judgments to evaluate system performance."
33,Alexandra L. Uitdenbogerd;Justin Zobel,Music Ranking Techniques Evaluated.,2000,https://doi.org/10.5281/zenodo.1414990,"Alexandra L. Uitdenbogerd, Department of Computer Science, RMIT University;Justin Zobel, Department of Computer Science, RMIT University","Several techniques have been proposed for matching melody queries to stored music. In this paper, we explore a broader range of n-gram techniques and test them with both manual queries and queries automatically extracted from MIDI files. Our experiments show that alternative n-gram matching techniques, such as simply counting the number of 5-grams in common between query and stored piece of music, can be as effective as local alignment. N-grams are particularly effective for short and manual queries, while local alignment is superior for automatic queries."
34,Thomas von Schroeter;Shyamala Doraisamy;Stefan M. Rüger,From Raw Polyphonic Audio to Locating Recurring Themes.,2000,https://doi.org/10.5281/zenodo.1416124,"Thomas von Schroeter, T H Huxley School of Environment, Earth Sciences and Engineering Imperial College of Science, Technology and Medicine Prince Consort Road, London SW7 2BZ, England;Shyamala Doraisamy, Department of Multimedia Faculty of Computer Science and Information Technology University Putra Malaysia, 43400 UPM Serdang, Selangor D.E., Malaysia;Stefan M R¨uger, Department of Computing Imperial College of Science, Technology and Medicine 180 Queen’s Gate, London SW7 2BZ, England",We present research studies of two related strands in content-based music retrieval: the automatic transcription of raw audio from a single polyphonic instrument with discrete pitch (eg piano) and the location of recurring themes from a Humdrum score.
