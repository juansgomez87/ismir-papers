Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,François Deliège;Torben Bach Pedersen,Fuzzy Song Sets for Music Warehouses.,2007,https://doi.org/10.5281/zenodo.1415770,"Franc¸ois Deli`ege, Aalborg University, DNK, education;Torben Bach Pedersen, Aalborg University, DNK, education","The emergence of music recommendation systems calls for the development of new data management technologies able to query vast music collections. In this paper, we deﬁne fuzzy song sets and an algebra to manipulate them. We present a music warehouse prototype able to perform efﬁcient nearest neighbor searches in an arbitrary song similarity space. Using fuzzy song sets, the music warehouse offers a practical solution to the all musical data management scenarios provided: song comparisons, user musical preferences and user feedback. We investigate three practical approaches to tackle the storage issues of fuzzy song sets: tables, arrays and bitmaps. Finally, we confront theoretical estimates to concrete implementation results and prove that, from a storage perspective, arrays and bitmaps are both effective data structure solutions."
1,Wei Peng 0001;Tao Li 0001;Mitsunori Ogihara,Music Clustering with Constraints.,2007,https://doi.org/10.5281/zenodo.1418087,"Wei Peng, Florida International University, USA, education;Tao Li, Florida International University, USA, education;Mitsunori Ogihara, University of Rochester, USA, education","This paper studies the problem of building clusters of music tracks in a collection of popular music in the presence of constraints. The constraints come naturally in the context of music applications. For example, constraints can be generated from the background knowledge (e.g., two artists share similar styles) and the user access patterns (e.g., two pieces of music share similar access patterns across multiple users). We present an approach based on the generalized constraint clustering algorithm by incorporating the constraints for grouping music by “similar” artists. The approach is evaluated on a data set consisting of 53 albums covering 41 popular artists. The “correctness” of the clusters generated is tested using artist similarity provided by All Music Guide."
2,Geoffroy Peeters,Sequence Representation of Music Structure Using Higher-Order Similarity Matrix and Maximum-Likelihood Approach.,2007,https://doi.org/10.5281/zenodo.1416748,"Geoffroy Peeters, Ircam Sound Analysis/Synthesis Team - CNRS STMS, FRA, facility","In this paper, we present a novel method for the automatic estimation of the structure of music tracks using a sequence representation. A set of timbre-related (MFCC and Spectral Contrast) and pitch-related (Pitch Class Profile) features are first extracted from the signal leading to three similarity matrices which are then combined. We then introduce the use of higher-order (2nd and 3rd order) similarity matrices in order to reinforce the diagonals corresponding to common repetitions and reduce the background noise. Segments are then detected and a maximum-likelihood approach is proposed in order to derive simultaneously the underlying sequence representation of the music track and the most representative segment of each sequence. The proposed method is evaluated positively on the MPEG-7 “melody repetition” test set."
3,Christophe Rhodes;Michael A. Casey,Algorithms for Determining and Labelling Approximate Hierarchical Self-Similarity.,2007,https://doi.org/10.5281/zenodo.1418095,"Christophe Rhodes, Goldsmiths University of London, GBR, education;Michael Casey, Goldsmiths University of London, GBR, education","We describe an algorithm for finding approximate sequence similarity at all scales of interest, being explicit about our modelling assumptions and the parameters of the algorithm. We further present an algorithm for producing section labels based on the sequence similarity, and compare these labels with some expert-provided ground truth for a particular set of recordings."
4,Meinard Müller;Michael Clausen,Transposition-Invariant Self-Similarity Matrices.,2007,https://doi.org/10.5281/zenodo.1414814,"Meinard Müller, Bonn University, DEU, education;Michael Clausen, Bonn University, DEU, education","Self-similarity matrices have become an important tool for visualizing the repetitive structure of a music recording. Transforming an audio data stream into a feature sequence, one obtains a self-similarity matrix by pairwise comparing all features of the sequence with respect to a local cost measure. The basic idea is that similar audio segments are revealed as paths of low cost along diagonals in the resulting self-similarity matrix. It is often the case, in particular for classical music, that certain musical parts are repeated in another key. In this paper, we introduce the concept of a transposition-invariant self-similarity matrix, which reveals the repetitive structure even in the presence of key transpositions. Furthermore, we introduce an associated transposition index matrix displaying harmonic relations within the music recording. As an application, we sketch how our concept can be used for the task of audio structure analysis."
5,Douglas Turnbull;Gert R. G. Lanckriet;Elias Pampalk;Masataka Goto,A Supervised Approach for Detecting Boundaries in Music Using Difference Features and Boosting.,2007,https://doi.org/10.5281/zenodo.1415082,"Douglas Turnbull, University of California, San Diego, USA, education;Gert Lanckriet, University of California, San Diego, USA, education;Elias Pampalk, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility","A musical boundary is a transition between two musical segments such as a verse and a chorus. Our goal is to automatically detect musical boundaries using temporally-local audio features. We develop a set of difference features that indicate when there are changes in perceptual aspects (e.g., timbre, harmony, melody, rhythm) of the music. We show that many individual difference features are useful for detecting boundaries. By combining these features and formulating the problem as a supervised learning problem, we can further improve performance. This is an alternative to previous work on music segmentation which has focused on unsupervised approaches based on notions of self-similarity computed over an entire song. We evaluate performance using a publicly available data set of 100 copyright-cleared pop/rock songs, each of which has been segmented by a human expert."
6,Alan Marsden,Automatic Derivation of Musical Structure: A Tool for Research on Schenkerian Analysis.,2007,https://doi.org/10.5281/zenodo.1415814,"Alan Marsden, Lancaster Institute for the Contemporary Arts, Lancaster University, UK, education","""This paper describes software to facilitate research on the automatic derivation of hierarchical (Schenkerian) musical structures from a musical surface. Many MIR tasks require information about musical structure, or would perform better if such information were available. Automatic derivation of musical structure faces two significant obstacles. Firstly, the solution space of possible structural analyses of a piece is very large. Secondly, pieces can have more than one valid structural analysis, and there is little firm agreement among music theorists about how to distinguish a good analysis. To circumvent the first of these obstacles, software has been developed which derives a tractable ‘matrix’ of possibilities from a musical surface (i.e., MIDI-like note-time information). The matrix is somewhat like the intermediate results of a dynamic-programming algorithm, and in a similar way it is possible to extract a particular structural analysis from the matrix by following the appropriate path from the top level to the surface. It therefore provides a tool to facilitate research on the second obstacle by allowing candidate ‘goodness’ metrics to be incorporated into the software and tested on actual music."""
7,Thomas Lidy;Andreas Rauber;Antonio Pertusa;José Manuel Iñesta Quereda,Improving Genre Classification by Combination of Audio and Symbolic Descriptors Using a Transcription Systems.,2007,https://doi.org/10.5281/zenodo.1416344,"Thomas Lidy, Vienna University of Technology, Austria, education;Andreas Rauber, Vienna University of Technology, Austria, education;Antonio Pertusa, University of Alicante, Spain, education;José Manuel Iñesta, University of Alicante, Spain, education","""Recent research in music genre classification hints at a glass ceiling being reached using timbral audio features. To overcome this, the combination of multiple different feature sets bearing diverse characteristics is needed. We propose a new approach to extend the scope of the features: We transcribe audio data into a symbolic form using a transcription system, extract symbolic descriptors from that representation and combine them with audio features. With this method, we are able to surpass the glass ceiling and to further improve music genre classification, as shown in the experiments through three reference music databases and comparison to previously published performance results."""
8,Xiao Hu 0001;J. Stephen Downie,"Exploring Mood Metadata: Relationships with Genre, Artist and Usage Metadata.",2007,https://doi.org/10.5281/zenodo.1415126,"Xiao Hu, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education","""There is a growing interest in developing and then evaluating Music Information Retrieval (MIR) systems that can provide automated access to the mood dimension of music. Mood as a music access feature, however, is not well understood in that the terms used to describe it are not standardized and their application can be highly idiosyncratic. To better understand how we might develop methods for comprehensively developing and formally evaluating useful automated mood access techniques, we explore the relationships that mood has with genre, artist and usage metadata. Statistical analyses of term interactions across three metadata collections (AllMusicGuide.com, epinions.com and Last.fm) reveal important consistencies within the genre-mood and artist-mood relationships. These consistencies lead us to recommend a cluster-based approach that overcomes specific term-related problems by creating a relatively small set of data-derived “mood spaces” that could form the ground-truth for a proposed MIREX “Automated Mood Classification” task."""
9,Alastair J. D. Craft;Geraint A. Wiggins;Tim Crawford,How Many Beans Make Five? The Consensus Problem in Music-Genre Classification and a New Evaluation Method for Single-Genre Categorisation Systems.,2007,https://doi.org/10.5281/zenodo.1414982,"Alastair J. D. Craft, Goldsmiths, University of London, GBR, education;Geraint A. Wiggins, Goldsmiths, University of London, GBR, education;Tim Crawford, Goldsmiths, University of London, GBR, education","""Genre deﬁnition and attribution is generally considered to be subjective. This makes evaluation of any genre- labelling system intrinsically difﬁcult, as the ground-truth against which it is compared is based upon subjective responses, with little inter-participant consensus. This paper presents a novel method of analysing the results of a genre-labelling task, and demonstrates that there are groups of genre-labelling behaviour which are self- consistent. It is proposed that the evaluation of any genre classiﬁcation system uses this modiﬁed analysis method."""
10,Christopher DeCoro;Zafer Barutçuoglu;Rebecca Fiebrink,Bayesian Aggregation for Hierarchical Genre Classification.,2007,https://doi.org/10.5281/zenodo.1416012,"Christopher DeCoro, Princeton University, USA, education;Zafer Barutcuoglu, Princeton University, USA, education;Rebecca Fiebrink, Princeton University, USA, education","Hierarchical taxonomies of classes arise in the analysis of many types of musical information, including genre, as a means of organizing overlapping categories at varying levels of generality. However, incorporating hierarchical structure into conventional machine learning systems presents a challenge: the use of independent binary classifiers for each class in the hierarchy can produce hierarchically inconsistent predictions. That is, an example may be assigned to a class, and not assigned to the parent of that class. This paper applies a Bayesian framework to combine, or aggregate, a hierarchy of multiple binary classifiers in a principled manner, and consequently improves performance over the hierarchy as a whole. Furthermore, such an approach allows for an arbitrarily complex hierarchy, and does not suffer from classes that are too broad or too refined. Experiments on the MIREX 2005 symbolic genre classification dataset show that our Bayesian Aggregation algorithm provides significant improvement over independent classifiers, and demonstrates superior performance compared to previous work. Our method also improves similarity search by ranking songs by similarity of hierarchical predictions to those of a query song."
11,Sally Jo Cunningham;David Bainbridge 0001;Dana McKay,Finding New Music: A Diary Study of Everyday Encounters with Novel Songs.,2007,https://doi.org/10.5281/zenodo.1417083,"Sally Jo Cunningham, University of Waikato, NZL, education;David Bainbridge, University of Waikato, NZL, education;Dana McKay, Swinburne University of Technology, AUS, education","""This paper explores how we, as individuals, purposefully or serendipitously encounter “new music” (that is, music that we haven’t heard before) and relates these behaviours to music information retrieval activities such as music searching and music discovery via use of recommender systems. 41 participants participated in a three-day diary study, in which they recorded all incidents that brought them into contact with new music. The diaries were analyzed using a Grounded Theory approach. The results of this analysis are discussed with respect to location, time, and whether the music encounter was actively sought or occurred passively. Based on these results, we outline design implications for music information retrieval software, and suggest an extension of “laid back” searching."""
12,Kazuyoshi Yoshii;Masataka Goto;Kazunori Komatani;Tetsuya Ogata;Hiroshi G. Okuno,Improving Efficiency and Scalability of Model-Based Music Recommender System Based on Incremental Training.,2007,https://doi.org/10.5281/zenodo.1416880,"Kazuyoshi Yoshii, Graduate School of Informatics, Kyoto University, JPN, education, JSPS Research Fellow (DC1), JPN, facility;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Kazunori Komatani, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuya Ogata, Graduate School of Informatics, Kyoto University, JPN, education;Hiroshi G. Okuno, Graduate School of Informatics, Kyoto University, JPN, education","We aimed at improving the efﬁciency and scalability of a hybrid music recommender system based on a proba- bilistic generative model that integrates both collaborative data (rating scores provided by users) and content-based data (acoustic features of musical pieces). Although the hybrid system was proved to make accurate recommen- dations, it lacks efﬁciency and scalability. In other words, the entire model needs to be re-trained from scratch when- ever a new score, user, or piece is added. Furthermore, the system cannot deal with practical numbers of users and pieces on an enterprise scale. To improve efﬁciency, we propose an incremental method that partially updates the model at low computational cost. To enhance scalability, we propose a method that ﬁrst constructs a small “core” model over fewer virtual representatives created from real users and pieces, and then adds the real users and pieces to the core model by using the incremental method. The ex- perimental results revealed that the proposed system was not only efﬁcient and scalable but also outperformed the original system in terms of accuracy."
13,Amelie Anglade;Marco Tiemann;Fabio Vignoli,Virtual Communities for Creating Shared Music Channels.,2007,https://doi.org/10.5281/zenodo.1414710,"Amélie Anglade, Philips Research Europe, NLD, company;Marco Tiemann, Philips Research Europe, NLD, company;Fabio Vignoli, Philips Research Europe, NLD, company","We present an approach to automatically create virtual communities of users with similar music tastes. Our goal is to create personalized music channels for these communities in a distributed way, so that they can for example be used in peer-to-peer networks. To ﬁnd suitable techniques for creating these communities we analyze graphs created from real-world recommender datasets and identify speciﬁc properties of these datasets. Based on these properties we select and evaluate different graph-based community-extraction techniques. We select a technique that exploits identiﬁed properties to create clusters of music listeners. We validate the suitability of this technique using a music dataset and a large movie dataset. On a graph of 6,040 peers, the selected technique assigns at least 85% of the peers to optimal communities, and obtains a mean classiﬁcation error of less than 0.05 over the remaining peers that are not assigned to the best community."
14,Elias Pampalk;Masataka Goto,MusicSun: A New Approach to Artist Recommendation.,2007,https://doi.org/10.5281/zenodo.1417487,"Elias Pampalk, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility",MusicSun is a graphical user interface to discover artists. Artists are recommended based on one or more artists selected by the user. The recommendations are computed by combining 3 different aspects of similarity. The users can change the impact of each of these aspects. In addition words are displayed which describe the artists selected by the user. The user can select one of these words to focus the search on a specific direction.
15,Jesper Højvang Jensen;Daniel P. W. Ellis;Mads Græsbøll Christensen;Søren Holdt Jensen,Evaluation of Distance Measures Between Gaussian Mixture Models of MFCCs.,2007,https://doi.org/10.5281/zenodo.1415752,"Jesper Højvang Jensen, Aalborg University, DNK, education;Daniel P.W. Ellis, Columbia University, USA, education;Mads G. Christensen, Aalborg University, DNK, education;Søren Holdt Jensen, Aalborg University, DNK, education","""In music similarity and in the related task of genre classification, a distance measure between Gaussian mixture models is frequently needed. We present a comparison of the Kullback-Leibler distance, the earth movers distance and the normalized L2 distance for this application. Although the normalized L2 distance was slightly inferior to the Kullback-Leibler distance with respect to classification performance, it has the advantage of obeying the triangle inequality, which allows for efficient searching."""
16,Carlos Gómez;Soraya Abad-Mota;Edna Ruckhaus,An Analysis of the Mongeau-Sankoff Algorithm for Music Information Retrieval.,2007,https://doi.org/10.5281/zenodo.1417931,"Carlos Gómez, Universidad Simón Bolívar, VEN, education;Soraya Abad-Mota, Universidad Simón Bolívar, VEN, education;Edna Ruckhaus, Universidad Simón Bolívar, VEN, education","An essential problem in music information retrieval is to determine the similarity between two given melodies; there are several melodic similarity measures that have been proposed, among others, the Mongeau-Sankoff measure. In this work we implemented a modiﬁed version of the Mongeau-Sankoff measure. We conducted an experimental study to compare the implemented measure with other similarity measures; this evaluation was done in the context of the 2005 edition of the MIREX symbolic melodic similarity competition. The most relevant result of our work is an implementation of the Mongeau-Sankoff measure that presents greater effectiveness when compared to other current melodic similarity measures."
17,Alberto Novello;Martin F. McKinney,Assessment of Perceptual Music Similarity.,2007,https://doi.org/10.5281/zenodo.1415050,"Alberto Novello, Philips Research Laboratories, Eindhoven, NLD, facility;Martin McKinney, Philips Research Laboratories, Eindhoven, NLD, facility","""This paper extends a study on music similarity perception presented at ISMIR last year, in which subjects ranked the similarity of excerpt-pairs presented in triads [1]. The larger number of subjects and stimuli in the current study required a modiﬁcation of the methodological strategy. We use here two nested incomplete block designs in order to cover the full set of song-excerpts comparisons (tri- ads) while limiting the experimental time per subject. In addition to the two variable factors of the previous experiment, tempo and genre, we examine here the effect of prevalent instrument timbre. We found that 69 of 78 subjects where signiﬁcantly consistent in their judgments of repeated triads. Furthermore, we found signiﬁcant across- subject consistency on all 10 repeated triads. A signif- icant difference was found in the distributions of inter- and intra-genre excerpt distances. The stress values in the Shepard’s plot shows evidence of increased complexity in the present study compared to the previous smaller study."""
18,Cory McKay;Ichiro Fujinaga,jWebMiner: A Web-Based Feature Extractor.,2007,https://doi.org/10.5281/zenodo.1417679,"Cory McKay, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","jWebMiner is a software package for extracting cultural features from the web. It is designed to be used for arbitrary types of MIR research, either as a stand-alone application or as part of the jMIR suite. It emphasizes extensibility, generality and an easy-to-use interface. At its most basic level, the software operates by using web services to extract hit counts from search engines. Functionality is available for calculating a variety of statistical features based on these counts, for variably weighting web sites or limiting searches only to particular sites, for excluding hits that do not contain particular filter terms, for defining synonym relationships between certain search strings, and for applying a number of additional search configurations."
19,Tim Pohle;Peter Knees;Markus Schedl;Gerhard Widmer,Meaningfully Browsing Music Services.,2007,https://doi.org/10.5281/zenodo.1417777,"Tim Pohle, Johannes Kepler University, AUT, education;Peter Knees, Johannes Kepler University, AUT, education;Markus Schedl, Johannes Kepler University, AUT, education;Gerhard Widmer, Johannes Kepler University, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility","""We present a browser application that offers the user an enhanced access to the content of music web services. Most importantly, the technique we apply aims at making it feasible to add to the automated suggestion of similar artists some intentional spin, or direction. At the heart of the algorithm, automatically derived artist descriptions are analyzed for common topics or aspects, and each artist is described by the extent to which it is associated with each of these topics. The browser application enables the user to formulate a query by means of these underlying topics by simply adjusting slider positions. The best matching artist is shown, and its web page found on the web music service is displayed."""
20,Markus Schedl;Gerhard Widmer;Tim Pohle;Klaus Seyerlehner,Web-Based Detection of Music Band Members and Line-Up.,2007,https://doi.org/10.5281/zenodo.1418325,"Markus Schedl, Johannes Kepler University, AUT, education;Gerhard Widmer, Johannes Kepler University, AUT, education; Austrian Research Institute for Artificial Intelligence, AUT, facility;Tim Pohle, Johannes Kepler University, AUT, education;Klaus Seyerlehner, Johannes Kepler University, AUT, education","We present ﬁrst steps towards the automatic detection of music band members and instrumentation using web content mining techniques. To this end, we combine a named entity detection method with rule-based linguistic text analysis. We report on preliminary evaluation results and discuss limitations of the current method."
21,Gijs Geleijnse;Jan H. M. Korst,Tool Play Live: Dealing with Ambiguity in Artist Similarity Mining from the Web.,2007,https://doi.org/10.5281/zenodo.1416430,"Gijs Geleijnse, Philips Research, NLD, facility;Jan Korst, Philips Research, NLD, facility","As methods in artist similarity identification using Web Music Information Retrieval perform well on known evaluation sets, we investigate the application of such a method to a more realistic data set. We notice that ambiguous artist names lead to unsatisfying results. We present a simple, efficient and unsupervised method to deal with ambiguous artist names."
22,Bin Wei;Chengliang Zhang;Mitsunori Ogihara,Keyword Generation for Lyrics.,2007,https://doi.org/10.5281/zenodo.1418369,"Bin Wei, U. Rochester, USA, education;Chengliang Zhang, U. Rochester, USA, education;Mitsunori Ogihara, U. Rochester, USA, education",This paper proposes a scheme for content based keyword generation of song lyrics. Syntactic as well semantic similarity is used for sentence level clustering to separate the topic from the background of a song. A method is proposed to search for a center in the semantic graph of WordNet for generating keywords not contained in original text.
23,Ian Knopke;Donald Byrd,Towards Musicdiff: A Foundation for Improved Optical Music Recognition Using Multiple Recognizers.,2007,https://doi.org/10.5281/zenodo.1416522,"Ian Knopke, Indiana University, USA, education;Donald Byrd, Indiana University, USA, education","This paper presents work towards a “musicdiff” program for comparing files representing different versions of the same piece, primarily in the context of comparing versions produced by different optical music recognition (OMR) programs. Previous work by the current authors and others strongly suggests that using multiple recognizers will make it possible to improve OMR accuracy substantially. The basic methodology requires several stages: documents must be scanned and submitted to several OMR programs, programs whose strengths and weaknesses have previously been evaluated in detail. We discuss techniques we have implemented for normalization, alignment and rudimentary error correction. We also describe a visualization tool for comparing multiple versions on a measure-by-measure basis."
24,Olivier Lartillot;Petri Toiviainen,MIR in Matlab (II): A Toolbox for Musical Feature Extraction from Audio.,2007,https://doi.org/10.5281/zenodo.1417145,"Olivier Lartillot, University of Jyväskylä, FIN, education;Petri Toiviainen, University of Jyväskylä, FIN, education","""We present the MIRtoolbox, an integrated set of functions written in Matlab, dedicated to the extraction of musical features from audio ﬁles. The design is based on a mod- ular framework: the different algorithms are decomposed into stages, formalized using a minimal set of elementary mechanisms, and integrating different variants proposed by alternative approaches – including new strategies we have developed –, that users can select and parametrize. This paper offers an overview of the set of features, re- lated, among others, to timbre, tonality, rhythm or form, that can be extracted with the MIRtoolbox. One particular analysis is provided as an example. The toolbox also in- cludes functions for statistical analysis, segmentation and clustering. Particular attention has been paid to the design of a syntax that offers both simplicity of use and transpar- ent adaptiveness to a multiplicity of possible input types. Each feature extraction method can accept as argument an audio ﬁle, or any preliminary result from intermediary stages of the chain of operations. Also the same syntax can be used for analyses of single audio ﬁles, batches of ﬁles, series of audio segments, multi-channel signals, etc. For that purpose, the data and methods of the toolbox are organised in an object-oriented architecture."""
25,Christian Fremerey;Frank Kurth;Meinard Müller;Michael Clausen,A Demonstration of the SyncPlayer System.,2007,https://doi.org/10.5281/zenodo.1415586,"Christian Fremerey, Bonn University, DEU, education;Frank Kurth, Bonn University, DEU, education;Meinard Müller, Bonn University, DEU, education;Michael Clausen, Bonn University, DEU, education","The SyncPlayer system is an advanced audio player for multimodal presentation, browsing, and retrieval of music data. The system has been extended signiﬁcantly in the last few years. In this contribution, we describe the current state of the system and demonstrate the functionalities and interactions of the novel SyncPlayer components including combined inter- and intra-document music browsing."
26,Neil J. Hurley;Félix Balado;Elizabeth P. McCarthy;Guenole C. M. Silvestre,Performance of Philips Audio Fingerprinting under Desynchronisation.,2007,https://doi.org/10.5281/zenodo.1416068,"Neil J. Hurley, University College Dublin, IRL, education;F´elix Balado, University College Dublin, IRL, education;Elizabeth P. McCarthy, University College Dublin, IRL, education;Gu´enol´e C.M. Silvestre, University College Dublin, IRL, education",An audio ﬁngerprint is a compact representation (robust hash) of an audio signal which is linked to its perceptual content. Perceptually equivalent instances of the signal must lead to the same hash value. Fingerprinting ﬁnds application in efﬁcient indexing of music databases. We present a theoretical analysis of the Philips audio ﬁngerprinting method under desynchronisation for correlated stationary Gaussian sources.
27,Mehryar Mohri;Pedro J. Moreno;Eugene Weinstein,"Robust Music Identification, Detection, and Analysis.",2007,https://doi.org/10.5281/zenodo.1418043,"Mehryar Mohri, Courant Institute of Mathematical Sciences, USA, education, Google Inc., USA, company;Pedro Moreno, Google Inc., USA, company;Eugene Weinstein, Courant Institute of Mathematical Sciences, USA, education, Google Inc., USA, company","In previous work, we presented a new approach to music identiﬁcation based on ﬁnite-state transducers and Gaussian mixture models. Here, we expand this work and study the performance of our system in the presence of noise and distortions. We also evaluate a song detection method based on a universal background model in combination with a support vector machine classiﬁer and provide some insight into why our transducer representation allows for accurate identiﬁcation even when only a short song snippet is available."
28,Michaël Betser;Patrice Collen;Jean-Bernard Rault,Audio Identification Using Sinusoidal Modeling and Application to Jingle Detection.,2007,https://doi.org/10.5281/zenodo.1416890,"Michaël Betser, France Télécom R&D, FRA, company;Patrice Collen, France Télécom R&D, FRA, company;Jean-Bernard Rault, France Télécom R&D, FRA, company","""This article presents a new descriptor dedicated to Audio Identification (audioID), based on sinusoidal modeling. The core idea is an appropriate selection of the sinusoidal components of the signal to be detected. This new descriptor is robust against usual distortions found in audioID tasks. It has several advantages compared to classical subband-based descriptors including an increased robustness to additive noise, especially non-random noise such as additional speech, and a robust detection of short audio events.  This descriptor is compared to a classical subband-based feature for a jingle detection task on broadcast radio. It is shown that the new introduced descriptor greatly improves the performance in terms of recall/precision."""
29,Jérôme Lebossé;Luc Brun,Audio Fingerprint Identification by Approximate String Matching.,2007,https://doi.org/10.5281/zenodo.1417927,"Jerome Lebosse, France Telecom R&D, FRA, company;Luc Brun, GREYC UMR 6072, FRA, education",An audio ﬁngerprint is a small digest of an audio ﬁle which allows to identify it among a database of candidates. This paper ﬁrst presents a ﬁngerprint extraction algorithm. The identiﬁcation task is performed by a new identiﬁcation scheme which combines string matching algorithms and q-grams ﬁltration.
30,Yushen Han;Christopher Raphael,Desoloing Monaural Audio Using Mixture Models.,2007,https://doi.org/10.5281/zenodo.1417507,"Yushen Han, Indiana Univ., USA, education;Christopher Raphael, Indiana Univ., USA, education","""We describe a new approach to the “desoloing” problem, in which one tries to isolate the accompanying instruments from a monaural recording of a soloist with accompaniment. Our approach is based on explicit knowledge of the audio in the form of a score match – a correspondence between a symbolic score and the music audio, giving the times of all musical events. We employ the familiar idea of masking the short time Fourier transform to eliminate the solo part. The ideal mask is estimated by fitting a model to the data, whose note-based components are derived from the score match. The parameters for our probabilistic model are estimated using the EM algorithm."""
31,Juan José Burred;Thomas Sikora,Monaural Source Separation from Musical Mixtures Based on Time-Frequency Timbre Models.,2007,https://doi.org/10.5281/zenodo.1416396,"Juan Jos´e Burred, Technical University of Berlin, DEU, education;Thomas Sikora, Technical University of Berlin, DEU, education","We present a system for source separation from monaural musical mixtures based on sinusoidal modeling and on a library of timbre models trained a priori. The models, which rely on Principal Component Analysis, serve as time-frequency probabilistic templates of the spectral envelope. They are used to match groups of sinusoidal tracks and assign them to a source, as well as to reconstruct overlapping partials. The proposed method does not make any assumptions on the harmonicity of the sources, and does not require a previous multipitch estimation stage. Since the timbre matching stage detects the instruments present on the mixture, the system can also be used for classification and segmentation."
32,Alberto Pinto;Reinier H. van Leuken;M. Fatih Demirci;Frans Wiering;Remco C. Veltkamp,Indexing Music Collections Through Graph Spectra.,2007,https://doi.org/10.5281/zenodo.1416744,"Alberto Pinto, Universiteit Utrecht, NLD, education, Università degli Studi di Milano, ITA, education;Reinier H. van Leuken, Universiteit Utrecht, NLD, education;M. Fatih Demirci, Universiteit Utrecht, NLD, education;Frans Wiering, Universiteit Utrecht, NLD, education;Remco C. Veltkamp, Universiteit Utrecht, NLD, education","Content based music retrieval opens up large collections,
both for the general public and music scholars. It basically
enables the user to ﬁnd (groups of) similar melodies, thus
facilitating musicological research of many kinds.
We
present a graph spectral approach, new to the music re-
trieval ﬁeld, in which melodies are represented as graphs,
based on the intervals between the notes they are com-
posed of. These graphs are then indexed into a database
using their laplacian spectra as a feature vector. This lapla-
cian spectrum is known to be very informative about the
graph, and is therefore a good representative of the orig-
inal melody. Consequently, range searching around the
query spectrum returns similar melodies.
We present an experimental evaluation of this approach,
together with a comparison with two known retrieval tech-
niques. On our test corpus, a subset of a well documented
and annotated collection of Dutch folk songs, this eval-
uation demonstrates the effectiveness of the overall ap-
proach."
33,Catherine Lai;Ichiro Fujinaga;David Descheneau;Michael Frishkopf;Jenn Riley;Joseph Hafner;Brian McMillan,Metadata Infrastructure for Sound Recordings.,2007,https://doi.org/10.5281/zenodo.1415224,"Catherine Lai, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education;David Descheneau, University of Alberta, CAN, education;Michael Frishkopf, University of Alberta, CAN, education;Jenn Riley, Indiana University, USA, education;Joseph Hafner, McGill University, CAN, education;Brian McMillan, McGill University, CAN, education","""This paper describes the first iteration of a working model for searching heterogeneous distributed metadata repositories for sound recording collections, focusing on techniques used for real-time querying and harmonizing diverse metadata models. The initial model for a metadata infrastructure presented here is the first of its kind for sound recordings."""
34,Christian Landone;Joseph Harrop;Josh Reiss,"Enabling Access to Sound Archives Through Integration, Enrichment and Retrieval: The EASAIER Project.",2007,https://doi.org/10.5281/zenodo.1415584,"Christian Landone, Queen Mary, University of London, GBR, education;Joseph Harrop, Royal Scottish Academy of Music and Drama, GBR, education;Josh Reiss, Queen Mary, University of London, GBR, education","""Many  digital  sound  archives  suffer  from  problems 
concerning on-line access: sound materials are often held 
separately from other related media, they are not easily 
browsed and little opportunity to search the actual audio 
content of the material is provided.
The  EASAIER  project  aims  to  alleviate  these 
problems, offering a number of solutions to support sound 
archive  managers  and  users.  EASAIER  will  enable 
enhanced access to sound archives, providing multiple 
methods  of  retrieval,  integration  with  other  media 
archives, content enrichment and enhanced access tools."""
35,Polina Proutskova,Musical Memory of the World - Data Infrastructure in Ethnomusicological Archives.,2007,https://doi.org/10.5281/zenodo.1416316,"Polina Proutskova, Goldsmiths, University of London, Computing department, GBR, education","Ethnomusicological archives build the musical memory of the world, covering the geographical and the historical aspects of music worldwide. This article gives a brief description of the nature and the functionality of ethnomusicological archives. It reflects the current state of data infrastructure (policy and technology), addressing issues of access to archives’ holdings, of online visibility of music collections and of interoperability between archives. An outlook of a mutual involvement and a resulting influence at each others work between MIR community and ethnomusicological archives is given."
36,Rosana S. G. Lanzelotte;Adriana O. Ballesté;Martha Ulhoa,A Digital Collection of Brazilian Lundus.,2007,https://doi.org/10.5281/zenodo.1415634,"Rosana S. G. Lanzelotte, Universidade Federal do Estado do Rio de Janeiro, BRA, education;Adriana O. Ballesté, Laboratório Nacional de Computação Científica, BRA, facility;Martha Ulhoa, Universidade Federal do Estado do Rio de Janeiro, BRA, education","Lundu is a typical Brazilian popular musical form at the 
19th century. The distinguished musicologist Mozart de 
Araújo devoted himself to studying lundus and other 
forms of that period. He collected 48 lundus, which are 
nowadays stored in a private library, unavailable to 
public access. The present work describes the 
implementation of a digital collection of those lundus, 
using Dspace as the repository. Dspace is chosen in 
order to guarantee interoperability through the OAI-
PMH protocol. Metadata is generated using Dublin Core 
elements, fully compatible with Dspace. The digital 
collection provides access to the lundu score images, 
incipits and midi files, as well as metadata. It is the first 
time such a rare collection of 19th Brazilian popular 
music will be available on the web. As Dspace enables 
interoperation among repositories, a broad community 
may access the collection.  "
37,Beinan Li;Simon de Leon;Ichiro Fujinaga,Alternative Digitization Approach for Stereo Phonograph Records Using Optical Audio Reconstruction.,2007,https://doi.org/10.5281/zenodo.1415746,"Beinan Li, Schulich School of Music, McGill University, CAN, education;Simon de Leon, Schulich School of Music, McGill University, CAN, education;Ichiro Fujinaga, Schulich School of Music, McGill University, CAN, education","This paper presents the first Optical Audio Reconstruction (OAR) approach for the long-term digital preservation of stereo phonograph records. OAR uses precision metrology and digital image processing to obtain and convert groove contour data into digital audio for access and preservation. This contactless and imaging-based approach has considerable advantages over the traditional mechanical methods, such as being the only optical method with the potential to restore broken stereo records. Although past efforts on monophonic phonograph records have been successful, no attempts on 33rpm long-playing stereo records (LPs) have been reported."
38,Stefan Leitich;Martin Topf,Globe of Music - Music Library Visualization Using Geosom.,2007,https://doi.org/10.5281/zenodo.1416930,"Stefan Leitich, University of Vienna, AUT, education;Martin Topf, University of Vienna, AUT, education","Music collections are commonly represented as plain textual lists of artist, title, album etc. for each contained music track. The large volume of personal music libraries makes them difﬁcult to browse and access for users. In respect to possible information visualization techniques, no established convenient user interfaces exist. By using a spherical self-organizing map algorithm on low level audio features and processing the resulting map data, a Geographic Information System is used to visualize a music collection. This results in an aspiring music library visualization, which can be handled intuitively by the user and even provides new possibilities for accessing a music collection in the digital domain."
39,Adam R. Tindale;David Sprague;George Tzanetakis,Strike-A-Tune: Fuzzy Music Navigation Using a Drum Interface.,2007,https://doi.org/10.5281/zenodo.1418243,"Adam R. Tindale, University of Victoria, CAN, education;David Sprague, University of Victoria, CAN, education;George Tzanetakis, University of Victoria, CAN, education","A traditional music library system controlled by a mouse
and keyboard is precise, allowing users to select their de-
sired song. Alternatively, randomized playlist or shufﬂes
are used when users have no particular music in mind. We
present a new interface and visualization system called Strike-
A-Tune for fuzzy music navigation.
Fuzzy navigation is
an imprecise navigation approach allowing users to choose
preference related items. We believe this will help users to
play music they want to hear and re-discover infrequently
played songs in their music library, thus combining the best
aspects of precision navigation and shufﬂes. We have de-
signed an interface using an electronic drum to communi-
cate with a visualization and playback system."
40,Paul Lamere;Douglas Eck,Using 3D Visualizations to Explore and Discover Music.,2007,https://doi.org/10.5281/zenodo.1415022,"Paul Lamere, Sun Microsystems, USA, company;Douglas Eck, Sun Microsystems, USA, company","""This paper presents Search Inside the Music an application for exploring and discovering new music. Search Inside the Music uses a music similarity model and 3D visual- izations to provide a user with new tools for exploring and interacting with a music collection. With Search Inside the Music, a music listener can ﬁnd new music, generate interesting playlists, and interact with their music collec- tion."""
41,Stephen Hitchner;Jennifer Murdoch;George Tzanetakis,Music Browsing Using a Tabletop Display.,2007,https://doi.org/10.5281/zenodo.1415896,"Stephen Hitchner, Univeristy of Victoria, CAN, education;Jennifer Murdoch, University of Victoria, CAN, education;George Tzanetakis, University of Victoria, CAN, education","The majority of work in Music Information Retrieval (MIR) follows a search/retrieval paradigm. More recently, the importance of browsing as an interaction paradigm has been realized, and several novel interfaces have been proposed. In this paper, we describe two novel interaction schemes for content-aware browsing of music collections that use a graphical tabletop interface. We further present findings from qualitative user studies. We describe our work in the context of two primary themes: music collection browsing, and collaborative (multiple simultaneous users) interaction and involvement during the browsing/selection process."
42,Peter Knees,Search & Select - Intuitively Retrieving Music from Large Collections.,2007,https://doi.org/10.5281/zenodo.1416456,"Peter Knees, Johannes Kepler University Linz, AUT, education","A retrieval system for large-scale collections that allows users to search for music using natural language queries and relevance feedback is presented. In contrast to existing music search engines that are either restricted to manually annotated meta-data or based on a query-by-example variant, the presented approach describes audio pieces via a traditional term vector model and allows therefore to retrieve relevant music pieces by issuing simple free-form text queries. Term vector descriptors for music pieces are derived by applying Web-based and audio-based similarity measures. Additionally, as the user selects music pieces that he/she likes, the subsequent results are adapted to accommodate to the user’s preferences. Real-world performance of the system is indicated by a small user study."
43,Marco Tiemann;Steffen Pauws;Fabio Vignoli,Ensemble Learning for Hybrid Music Recommendation.,2007,https://doi.org/10.5281/zenodo.1417781,"Marco Tiemann, Philips Research Europe, NLD, facility;Steffen Pauws, Philips Research Europe, NLD, facility;Fabio Vignoli, Philips Research Europe, NLD, facility","We investigate ensemble learning methods for hybrid music recommenders, combining a social and a content-based recommender algorithm in an initial experiment by applying a simple combination rule to merge recommender results. A first experiment suggests that such a combination can reduce the mean absolute prediction error compared to the used recommenders’ individual errors."
44,Justin Donaldson;Ian Knopke,Music Recommendation Mapping and Interface Based on Structural Network Entropy.,2007,https://doi.org/10.5281/zenodo.1417329,"Justin Donaldson, Indiana University School of Informatics, USA, education;Ian Knopke, Indiana University School of Informatics, USA, education","Recommendation systems generally produce the results of their output to their users in the form of an ordinal list. In the interest of simplicity, these lists are often obscure, abstract, or omit many relevant metrics pertaining to the measured strength of the recommendations or the relationships the recommended items share with each other. This information is often useful for coming to a better understanding of the nature of how the items are structured according to the recommendation data. This paper describes the ZMDS algorithm, a novel way of analyzing the fundamental network structure of recommendation results. Furthermore, it also describes a dynamic plot interaction method as a recommendation browsing utility. A novel “Recommendation Map” web application implements both the ZMDS algorithm and the plot interface and are offered as an example of both components working together."
45,Teemu Tuomas Ahmaniemi,Influence of Tempo and Subjective Rating of Music in Step Frequency of Running.,2007,https://doi.org/10.5281/zenodo.1418107,", ",""""""
46,Daniel McEnnis;Sally Jo Cunningham,Sociology and Music Recommendation Systems.,2007,https://doi.org/10.5281/zenodo.1414854,"Daniel McEnnis, Waikato University, NZL, education;Sally Jo Cunningham, Waikato University, NZL, education","Music recommendation systems have centred on two
different approaches: content based analysis and collabo-
rative ﬁltering. Little attention has been paid to the rea-
sons why these techniques have been effective.
Fortu-
nately, the social sciences have asked these questions. One
of the ﬁndings of this research is that social context is
much more important than previously thought. This pa-
per introduces this body of research from sociology and
its relevance to music recommendation algorithms."
47,Arpi Mardirossian;Elaine Chew,Visualizing Music: Tonal Progressions and Distributions.,2007,https://doi.org/10.5281/zenodo.1417773,"Arpi Mardirossian, University of Southern California Viterbi School of Engineering, USA, education;Elaine Chew, University of Southern California Viterbi School of Engineering, USA, education","""This paper presents a music visualization tool that shows the tonal progression in, and tonal distribution of, a piece of music on Lerdahl’s two-dimensional tonal pitch space. The method segments a piece into uniform time slices, and determines the most likely key in each slice. It then generates the visualization by dynamically showing the sequence of keys as translucent, growing discs on the two-dimensional plane. The frequency of a key is indicated by the size of its colored disc. Each color and position corresponds to a key, and related keys are shown in proximity with related colors. The visual result effectively presents the changing distribution of the keys employed. The proposed visualization is an improvement over more basic charting methods, such as histograms, and it maintains standards of information design in the form of added dimensionality, color, and animation. We show that the visualization is invariant under music transformations that preserve the piece’s identity. We conclude by illustrating how this method may be used to visually distinguish between tonal progression and distribution patterns in western classical versus Armenian folk music."""
48,Özgür Izmirli,Localized Key Finding from Audio Using Nonnegative Matrix Factorization for Segmentation.,2007,https://doi.org/10.5281/zenodo.1417197,"Özgür İzmirli, Connecticut College, USA, education","A model for localized key finding from audio is proposed. Besides being able to estimate the key in which a piece starts, the model can also identify points of modulation and label multiple sections with their key names throughout a single piece. The front-end employs an adaptive tuning stage prior to spectral analysis and calculation of chroma features. The segmentation stage uses groups of contiguous chroma vectors as input and identifies sections that are candidates for unique local keys in relation to their neighboring key centers. Non-negative matrix factorization with additional sparsity constraints and additive updates is used for segmentation. The use of segmentation is demonstrated for single and multiple key estimation problems. A correlational model of key finding is applied to the candidate segments to estimate the local keys. Evaluation is given on three different data sets and a range of analysis parameters."
49,Gabi Teodoru;Christopher Raphael,Pitch Spelling with Conditionally Independent Voices.,2007,https://doi.org/10.5281/zenodo.1414946,"Gabi Teodoru, Indiana University, USA, education;Christopher Raphael, Indiana University, USA, education","We introduce a new approach for pitch spelling from MIDI data based on a probabilistic model. The model uses a hidden sequence of variables, one for each measure, describing the local key of the music. The spellings in the voices evolve as conditionally independent Markov chains, given the hidden keys. The model represents both vertical relations through the shared key and horizontal voice-leading relations through the explicit Markov models for the voices. This conditionally independent voice model leads to an efficient dynamic programming algorithm for finding the most likely configuration of hidden variables — spellings and harmonic sequence. The model is also straightforward to train from unlabeled data, though we have not been able to demonstrate any improvement in performance due to training. Our results compare favorably with others when tested on Meredith’s corpus, designed specifically for this problem."
50,Gabriel Gatzsche;Markus Mehnert;David Gatzsche;Karlheinz Brandenburg,A Symmetry Based Approach for Musical Tonality Analysis.,2007,https://doi.org/10.5281/zenodo.1416214,"G. Gatzsche, Fraunhofer IDMT, DEU, facility;M. Mehnert, Technische Universität Ilmenau, DEU, education;D. Gatzsche, Hochschule für Musik Franz Liszt Weimar, DEU, education;K. Brandenburg, Technische Universität Ilmenau, DEU, education","We present a geometric approach for tonality analysis called symmetry model. To derive the symmetry model, Carol L. Krumhansl and E.J. Kessler’s toroidal Multi Dimensional Scaling (MDS) solution is separated into a key spanning and a key related component. While the key spanning component represents relationships between diﬀerent keys, the key related component is suitable for the analysis of inner relationships of diatonic keys, for example tension or resolution tendencies, or functional relationships. These features are directly related to the symmetric organisation of tones around the tonal center, which is particularly visualized by the key related component."
51,Luis Gustavo Martins;Juan José Burred;George Tzanetakis;Mathieu Lagrange,Polyphonic Instrument Recognition Using Spectral Clustering.,2007,https://doi.org/10.5281/zenodo.1415074,"Luis Gustavo Martins, INESC Porto, PRT, facility;Juan Jos´e Burred, Technical University of Berlin, DEU, education;George Tzanetakis, University of Victoria, CAN, education;Mathieu Lagrange, University of Victoria, CAN, education","The identification of the instruments playing in a polyphonic music signal is an important and unsolved problem in Music Information Retrieval. In this paper, we propose a framework for the sound source separation and timbre classification of polyphonic, multi-instrumental music signals. The sound source separation method is inspired by ideas from Computational Auditory Scene Analysis and formulated as a graph partitioning problem. It utilizes a sinusoidal analysis front-end and makes use of the normalized cut, applied as a global criterion for segmenting graphs. Timbre models for six musical instruments are used for the classification of the resulting sound sources. The proposed framework is evaluated on a dataset consisting of mixtures of a variable number of simultaneous pitches and instruments, up to a maximum of four concurrent notes."
52,Olivier Gillet;Gaël Richard,Supervised and Unsupervised Sequence Modelling for Drum Transcription.,2007,https://doi.org/10.5281/zenodo.1417237,"Olivier Gillet, GET / T´el´ecom Paris (ENST), CNRS LTCI, FRA, education;Ga¨el Richard, GET / T´el´ecom Paris (ENST), CNRS LTCI, FRA, education","""We discuss in this paper two post-processings for drum transcription systems, which aim to model typical properties of drum sequences. Both methods operate on a symbolic representation of the sequence, which is obtained by quantizing the onsets of drum strokes on an optimal tatum grid, and by fusing the posterior probabilities produced by the drum transcription system. The first proposed method is a generalization of the N-gram model. We discuss several training and recognition strategies (style-dependent models, local models) in order to maximize the reliability and the specificity of the trained models. Alternatively, we introduce a novel unsupervised algorithm based on a complexity criterion, which finds the most regular and well-structured sequence compatible with the acoustic scores produced by the transcription system. Both approaches are evaluated on a subset of the ENST-drums corpus, and yield performance improvements."""
53,Jouni Paulus;Anssi Klapuri,Combining Temporal and Spectral Features in HMM-Based Drum Transcription.,2007,https://doi.org/10.5281/zenodo.1417257,"Jouni Paulus, Tampere University of Technology, FIN, education;Anssi Klapuri, Tampere University of Technology, FIN, education","To date several methods for transcribing drums from polyphonic music have been published. Majority of the features used in the transcription systems are “spectral”: parameterising some property of the signal spectrum in a relatively short time frames. It has been shown that utilising narrow-band features describing long-term temporal evolution in conjunction with the more traditional features can improve the overall performance in speech recognition. We investigate similar utilisation of temporal features in addition to the HMM baseline. The effect of the proposed extension is evaluated with simulations on acoustic data, and the results suggest that temporal features do improve the result slightly. Demonstrational signals of the transcription results are available at http://www.cs.tut.ﬁ/sgn/arg/paulus/demo/."
54,Pierre Roy;François Pachet;Sergio Krakowski,Improving the Classification of Percussive Sounds with Analytical Features: A Case Study.,2007,https://doi.org/10.5281/zenodo.1417875,"Pierre Roy, Sony CSL, FRA, company;François Pachet, Sony CSL Paris, FRA, company;Sergio Krakowski, Sony CSL Paris, FRA, company","There is an increasing need for automatically classifying 
sounds for MIR and interactive music applications. In the 
context of supervised classification, we conducted experi-
ments with so-called analytical features, an approach that 
improves the performance of the general bag-of-frame 
scheme without loosing its generality. These analytical 
features are better, in a sense we define precisely than 
standard, general features, or even than ad hoc features 
designed by hand for specific problems. Our method al-
lows us to build a large number of these features, evaluate 
and select them automatically for arbitrary audio classi-
fication problems.
We present here a specific study concerning the analy-
sis of Pandeiro (Brazilian tambourine) sounds. Two prob-
lems are considered: the classification of entire sounds, 
for MIR applications, and the classification of attack por-
tions of the sound only, for interactive music applica-
tions. We evaluate precisely the gain obtained by analyti-
cal features on these two problems, in comparison with 
standard approaches."
55,Pierre Leveau;David Sodoyer;Laurent Daudet,Automatic Instrument Recognition in a Polyphonic Mixture Using Sparse Representations.,2007,https://doi.org/10.5281/zenodo.1414984,"Pierre Leveau, GET-ENST (Télécom Paris), FRA, education, University Pierre et Marie Curie, FRA, education;David Sodoyer, University Pierre et Marie Curie, FRA, education;Laurent Daudet, University Pierre et Marie Curie, FRA, education","""In this paper, we introduce a method to address automatic instrument recognition in polyphonic music. It is based on the decomposition of the music signal with instrument-specific harmonic atoms, yielding an approximate object representation of the signal. A post-processing is then applied to exhibit ensemble saliences that give clues about the number of instruments and their labels. The whole algorithm is then applied on artificial mixes of solo performances. The identification of the number of instrument reaches 73 % on 10-s segments and the fully blind problem of identification of the ensemble label without prior knowledge on the number of instruments is 17 %."""
56,Juan Pablo Bello,"Audio-Based Cover Song Retrieval Using Approximate Chord Sequences: Testing Shifts, Gaps, Swaps and Beats.",2007,https://doi.org/10.5281/zenodo.1417911,"Juan Pablo Bello, New York University, USA, education","""This paper presents a variation on the theme of using string alignment for MIR in the context of cover song identiﬁcation in audio collections. Here, the strings are derived from audio by means of HMM-based chord estimation. The characteristics of the cover-song ID problem and the nature of common chord estimation errors are carefully considered. As a result strategies are proposed and systematically evaluated for key shifting, the cost of gap insertions and character swaps in string alignment, and the use of a beat-synchronous feature set. Results support the view that string alignment, as a mechanism for audio-based retrieval, cannot be oblivious to the problems of robustly estimating musically-meaningful data from audio."""
57,Kyogu Lee;Malcolm Slaney,A Unified System for Chord Transcription and Key Extraction Using Hidden Markov Models.,2007,https://doi.org/10.5281/zenodo.1415208,"Kyogu Lee, Center for Computer Research in Music and Acoustics, Stanford University, USA, education;Malcolm Slaney, Yahoo! Research, USA, company","A new approach to acoustic chord transcription and key extraction is presented. As in an isolated word recognizer in automatic speech recognition systems, we treat a musical key as a word and build a separate hidden Markov model for each key in 24 major/minor keys. In order to acquire a large set of labeled training data for supervised training, we ﬁrst perform harmonic analysis on symbolic data to extract the key information and the chord labels with precise segment boundaries. In parallel, we synthesize audio from the same symbolic data whose harmonic progression are in perfect alignment with the automatically generated annotations. We then estimate the model parameters directly from the labeled training data, and build 24 key-speciﬁc HMMs. The experimental results show that the proposed model not only successfully estimates the key, but also yields higher chord recognition accuracy than a universal, key-independent model."
58,John Ashley Burgoyne;Laurent Pugin;Corey Kereliuk;Ichiro Fujinaga,A Cross-Validated Study of Modelling Strategies for Automatic Chord Recognition in Audio.,2007,https://doi.org/10.5281/zenodo.1416816,"John Ashley Burgoyne, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, facility;Laurent Pugin, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, facility;Corey Kereliuk, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, facility;Ichiro Fujinaga, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, facility","""Although automatic chord recognition has generated a number of recent papers in MIR, nobody to date has done a proper cross validation of their recognition results. Cross validation is the most common way to establish baseline standards and make comparisons, e.g., for MIREX competitions, but a lack of labelled aligned training data has rendered it impractical. In this paper, we present a comparison of several modelling strategies for chord recognition, hidden Markov models (HMMs) and conditional random fields (CRFs), on a new set of aligned ground truth for the Beatles data set of Sheh and Ellis (2003). Consistent with previous work, our models use pitch class profile (PCP) vectors for audio modelling. Our results show improvement over previous literature, provide precise estimates of the performance of both old and new approaches to the problem, and suggest several avenues for future work."""
59,Matthias Mauch;Simon Dixon;Christopher Harte;Michael A. Casey;Benjamin Fields,Discovering Chord Idioms Through Beatles and Real Book Songs.,2007,https://doi.org/10.5281/zenodo.1415564,"Matthias Mauch, Queen Mary, University of London, GBR, education;Simon Dixon, Queen Mary, University of London, GBR, education;Christopher Harte, Queen Mary, University of London, GBR, education;Michael Casey, Goldsmiths, University of London, GBR, education;Benjamin Fields, Goldsmiths, University of London, GBR, education","""Modern collections of symbolic and audio music content provide unprecedented possibilities for musicological research, but traditional qualitative evaluation methods cannot realistically cope with such amounts of data. We are interested in harmonic analysis and propose key-independent chord idioms derived from a bottom-up analysis of musical data as a new subject of musicological interest. In order to motivate future research on audio chord idioms and on probabilistic models of harmony we perform a quantitative study of chord progressions in two popular music collections. In particular, we extract common subsequences of chord classes from symbolic data, independent of key and context, and order them by frequency of occurrence, thus enabling us to identify chord idioms. We make musicological observations on selected chord idioms from the collections."""
60,Frank Kurth;Meinard Müller;Christian Fremerey;Yoon-ha Chang;Michael Clausen,Automated Synchronization of Scanned Sheet Music with Audio Recordings.,2007,https://doi.org/10.5281/zenodo.1416918,"Frank Kurth, Bonn University, DEU, education;Meinard Müller, Bonn University, DEU, education;Christian Fremerey, Bonn University, DEU, education;Yoon-ha Chang, Bonn University, DEU, education;Michael Clausen, Bonn University, DEU, education","In this paper, we present a procedure for automatically synchronizing scanned sheet music with a corresponding CD audio recording, where suitable regions (given in pixels) of the scanned digital images are linked to time positions of the audio file. In a first step, we extract note parameters and 2D position information from the scanned images using standard software for optical music recognition (OMR). We then use a chroma-based synchronization algorithm to align the note parameters to the given audio recording. Our experiments show that even though the output of current OMR software is often erroneous, the music parameters extracted from the digital images still suffice to derive a reasonable alignment with the audio data stream. The resulting link structure can be used to highlight the current position in the scanned score or to automatically turn pages during playback of an audio recording. Such functionalities have been realized as plug-in for the SyncPlayer, which is a free prototypical software framework for bringing together various MIR techniques and applications."
61,Paul H. Peeling;Ali Taylan Cemgil;Simon J. Godsill,A Probabilistic Framework for Matching Music Representations.,2007,https://doi.org/10.5281/zenodo.1417677,"Paul Peeling, Cambridge University, GBR, education;A. Taylan Cemgil, Cambridge University, GBR, education;Simon Godsill, Cambridge University, GBR, education","In this paper we introduce a probabilistic framework for matching different music representations (score, MIDI, audio) by incorporating models of how one musical representation might be rendered from another. We propose a dynamical hidden Markov model for the score pointer as a prior, and two observation models, the first based on matching spectrogram data to a trained template, the second detecting damped sinusoids within a frame of audio by subspace methods. The resulting Bayesian framework is robust to local variations in tempo, and can be used for a wide variety of applications. We evaluate both methods in a score alignment context by inferring the posterior distribution of the current position in the score exactly. The spectrogram method is shown to infer the score position reliably with minimal computation, and the damped sinusoid model is able to pinpoint the positions of score events in the audio with a high level of timing accuracy."
62,Riccardo Miotto;Nicola Orio,A Methodology for the Segmentation and Identification of Music Works.,2007,https://doi.org/10.5281/zenodo.1415952,"Riccardo Miotto, University of Padova, ITA, education;Nicola Orio, University of Padova, ITA, education","The identiﬁcation of unknown recordings is a challenging problem that has several applications. In this paper, we focus on the identiﬁcation of alternative releases of a given music work. To this end, a statistical model of the possible performances of a given score is built from the recording of a single performance. The methodology is based on the automatic segmentation of audio recordings, exploiting a technique that has been proposed for text segmentation. The segmentation is followed by the automatic extraction of a set of relevant audio features from each segment. Identiﬁcation is then carried out using an application of hidden Markov models. The approach has been tested with a collection of orchestral music, showing good results in the identiﬁcation of acoustic performances."
63,Wei You;Roger B. Dannenberg,Polyphonic Music Note Onset Detection Using Semi-Supervised Learning.,2007,https://doi.org/10.5281/zenodo.1417385,"Wei You, Carnegie Mellon University, USA, education;Roger B. Dannenberg, Carnegie Mellon University, USA, education","Automatic note onset detection is particularly difﬁcult in orchestral music (and polyphonic music in general). Machine learning offers one promising approach, but it is limited by the availability of labeled training data. Score-to-audio alignment, however, offers an economical way to locate onsets in recorded audio, and score data is freely available for many orchestral works in the form of standard MIDI ﬁles. Thus, large amounts of training data can be generated quickly, but it is limited by the accuracy of the alignment, which in turn is ultimately related to the problem of onset detection. Semi-supervised or bootstrapping techniques can be used to iteratively reﬁne both onset detection functions and the data used to train the functions. We show that this approach can be used to improve and adapt a general purpose onset detection algorithm for use with orchestral music."
64,Masatoshi Hamanaka;Keiji Hirata;Satoshi Tojo,ATTA: Implementing GTTM on a Computer.,2007,https://doi.org/10.5281/zenodo.1418269,"Masatoshi Hamanaka, University of Tsukuba, JPN, education;Keiji Hirata, NTT Communication Science Laboratories, JPN, company;Satoshi Tojo, Japan Advanced Institute of Science and Technology, JPN, education","We have been discussing the design principle for the implementation of GTTM and presented the semi-automatic generation techniques of grouping structure, metrical structure, and time-span tree, and the searching method for the optimal parameter value assignments. In ISMIR2007, we organize a tutorial session on the techniques for implementing music theory GTTM for summarizing our work and report it to relevant participants of the conference. Since the time of the tutorial session is not enough, we demonstrate a working automatic time-span tree analyzer ATTA in a demo session. ATTA is an integration of our work done so far; by looking at the ATTA demonstration or using ATTA, people will be able to understand the techniques for implementing GTTM as well as GTTM itself in more detail."
65,Tillman Weyde;Jens Wissmann;Kerstin Neubarth,An Experiment on the Role of Pitch Intervals in Melodic Segmentation.,2007,https://doi.org/10.5281/zenodo.1417591,"Tillman Weyde, City University London, GBR, education;Jens Wissmann, City University London, GBR, education;Kerstin Neubarth, City University London, GBR, education","""This paper presents the results of an experiment to test the inﬂuence of IOI, dynamics, pitch change, and pitch direction change on melodic segmentation, extending an an earlier experiment [4]. The new results show little to no signiﬁcant inﬂuence of pitch, when evaluated by a lin- ear or log-linear statistical model with regression. This supports the earlier ﬁndings, which are in contrast to the commonly made assumption that greater pitch intervals lead to melodic segmentation."""
66,Mika Kuuskankare;Mikael Laurson,Vivo - Visualizing Harmonic Progressions and Voice-Leading in PWGL.,2007,https://doi.org/10.5281/zenodo.1418189,"Mika Kuuskankare, Sibelius Academy, CMT, education;Mikael Laurson, Sibelius Academy, CMT, education","This paper describes a novel tool called VIVO (VIsual VOice-leading) that allows to visually deﬁne harmonic progressions and voice-leading rules. VIVO comprises of a compiler and a collection of specialized visualization devices. VIVO takes advantage of several music related applications collected under the umbrella of PWGL (PWGL is a free cross-platform visual programming language for music and sound related applications). Our music notation application–Expressive Notation Package or ENP–is used here to build the user-interface used to visually deﬁne harmony and voice-leading rules. These visualizations are converted to textual rules by the VIVO compiler. Finally, our rule-based compositional system, PWGLConstraints, is used generate the ﬁnal musical output using these rules."
67,Klaus Frieler,Visualizing Music on the Metrical Circle.,2007,https://doi.org/10.5281/zenodo.1416798,"Klaus Frieler, University of Hamburg, DEU, education","""In this paper we propose a novel method, called Metrical Circle Map, for exploring the cyclic aspects of musical time. To this end, we give a short formalization introducing the notion of Metrical Markov Chains as transition probabilities of segments on the metrical circle. As an illustration we present a compact visualization of the zeroth- and ﬁrst order metrical Markov transitions of 61 Irish folk songs."""
68,Anja Volk;Jörg Garbers;Peter van Kranenburg;Frans Wiering;Remco C. Veltkamp;Louis P. Grijp,Applying Rhythmic Similarity Based on Inner Metric Analysis to Folksong Research.,2007,https://doi.org/10.5281/zenodo.1416830,"Anja Volk, Jörg Garbers, Peter van Kranenburg, Frans Wiering, Remco C. Veltkamp, Utrecht University, NLD, education;Louis P. Grijp, Meertens Institute, Amsterdam, NLD, facility","""In this paper we investigate the role of rhythmic similarity as part of melodic similarity in the context of Folksong research. We deﬁne a rhythmic similarity measure based on Inner Metric Analysis and apply it to groups of similar melodies. The comparison with a similarity measure of the SIMILE software shows that the two models agree on the number of melodies that are considered very similar, but disagree on the less similar melodies. In general, we achieve good results with the retrieval of melodies using rhythmic information, which demonstrates that rhythmic similarity is an important factor to consider in melodic similarity."""
69,Iasonas Antonopoulos;Aggelos Pikrakis;Sergios Theodoridis;Olmo Cornelis;Dirk Moelants;Marc Leman,Music Retrieval by Rhythmic Similarity Applied on Greek and African Traditional Music.,2007,https://doi.org/10.5281/zenodo.1417503,"Iasonas Antonopoulos, University Of Athens, GRC, education;Aggelos Pikrakis, University Of Athens, GRC, education;Sergios Theodoridis, University Of Athens, GRC, education;Olmo Cornelis, Ghent University, BEL, education;Dirk Moelants, Ghent University, BEL, education;Marc Leman, Ghent University, BEL, education","""This paper presents a method for retrieving music recordings by means of rhythmic similarity in the context of traditional Greek and African music. To this end, Self Similarity Analysis is applied either on the whole recording or on instances of a music thumbnail that can be extracted from the recording with an optional thumbnailing scheme. This type of analysis permits the extraction of a rhythmic signature per music recording. Similarity between signatures is measured with a standard Dynamic Time Warping technique. The proposed method was evaluated on corpora of Greek and African traditional music where human improvisation plays a key role and music recordings exhibit a variety of music meters, tempi and instrumentation."""
70,Aggelos Pikrakis;Sergios Theodoridis,An Application of Empirical Mode Decomposition on Tempo Induction from Music Recordings.,2007,https://doi.org/10.5281/zenodo.1418103,"Aggelos Pikrakis, University of Athens, GRC, education;Sergios Theodoridis, University of Athens, GRC, education","""This paper presents an application of Empirical Mode Decomposition (EMD) on the induction of notated tempo from music recordings. At a first stage, EMD is employed as a means to segment music recordings into segments that exhibit similar rhythmic characteristics. At a second stage, EMD is used in order to analyze the diagonals of the Self-Similarity Matrix of each segment, so as to estimate the tempo of the recording. The proposed method has been employed on various music genres with music meters of 2 4, 3 4 and 4 4. Tempo has been assumed to remain approximately constant throughout each recording, ranging from 60bpm up to 220bpm."""
71,Ching-Hua Chuan;Elaine Chew,A Dynamic Programming Approach to the Extraction of Phrase Boundaries from Tempo Variations in Expressive Performances.,2007,https://doi.org/10.5281/zenodo.1416584,"Ching-Hua Chuan, University of Southern California Viterbi School of Engineering, USA, education;Elaine Chew, University of Southern California Viterbi School of Engineering, USA, education","We present an approach to phrase segmentation that starts with an expressive music performance. Previous research has shown that phrases are delineated by tempo speedups and slowdowns. We propose a dynamic programming algorithm for extracting phrases from tempo information. We test two hypotheses for modeling phrase tempo shapes: a quadratic model, and a spline curve. We test the two models on phrase extraction from performances of entire classical romantic pieces namely, Chopin’s Preludes Nos. 1 and 7. The algorithms determined 21 of the 26 phrase boundaries correctly from Arthur Rubinstein’s and Evgeny Kissin’s performances. We observe that not all tempo slowdowns signify a boundary (some are agogic accents), and multiple levels of phrasing strategies should be considered for detailed interpretation analyses."
72,Xiao Hu 0001;Mert Bay;J. Stephen Downie,Creating a Simplified Music Mood Classification Ground-Truth Set.,2007,https://doi.org/10.5281/zenodo.1416920,"Xiao Hu, University of Illinois at Urbana-Champaign, USA, education;Mert Bay, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education","""A standardized mood classification testbed is needed for formal cross-algorithm comparison and evaluation. In this poster, we present a simplification of the problems associated with developing a ground-truth set for the evaluation of mood-based Music Information Retrieval (MIR) systems. Using a dataset derived from Last.fm tags and the USPOP audio collection, we have applied a K-means clustering method to create a simple yet meaningful cluster-based set of high-level mood categories as well as a ground-truth dataset."""
73,Matthias Varewyck;Jean-Pierre Martens,Assessment of State-of-the-Art Meter Analysis Systems with an Extended Meter Description Model.,2007,https://doi.org/10.5281/zenodo.1417367,"Matthias Varewyck, Ghent University, BEL, education;Jean-Pierre Martens, Ghent University, BEL, education","An extended meter description model capturing the hierarchical metrical structure of Western music is proposed. The model is applied for the quantitative evaluation of four state-of-the-art automatic meter analysis algorithms of musical audio. Evaluation results suggest that the best beat trackers reach a reasonable level of performance, but that none of the tested algorithms has the potential to perform a reliable bar onset tracking. Moreover, the front-ends of the best over-all systems not necessarily seem to have the front-ends best encoding the time signature in their output. Therefore, further improvements of these systems should be attainable by a better combination of ideas that can be borrowed from existing algorithms."
74,Arshia Cont;Diemo Schwarz;Norbert Schnell;Christopher Raphael,Evaluation of Real-Time Audio-to-Score Alignment.,2007,https://doi.org/10.5281/zenodo.1416304,"Arshia Cont, Ircam UMR CNRS 9912, FRA, facility, CRCA, UCSD, USA, education;Diemo Schwarz, Ircam–Centre Pompidou, Paris, FRA, facility, UMR CNRS 9912, FRA, facility;Norbert Schnell, Ircam–Centre Pompidou, Paris, FRA, facility, UMR CNRS 9912, FRA, facility;Christopher Raphael, Indiana University, USA, education","This article explains evaluation methods for real-time au-
dio to score alignment, or score following, that allow for
the quantitative assessment of the robustness and precise-
ness of an algorithm. The published ground truth data
base and the evaluation framework, including ﬁle formats
for the score and the reference alignments, are presented.
The work, started for MIREX 2006, is meant as a ﬁrst step
towards a standardized evaluation process contributing to
the exchange and progress in this ﬁeld."
75,Daniel Müllensiefen;David Lewis 0001;Christophe Rhodes;Geraint A. Wiggins,Evaluating a Chord-Labelling Algorithm.,2007,https://doi.org/10.5281/zenodo.1417779,"Daniel M¨ullensiefen, Goldsmiths, University of London, GBR, education;David Lewis, Goldsmiths, University of London, GBR, education;Christophe Rhodes, Goldsmiths, University of London, GBR, education;Geraint Wiggins, Goldsmiths, University of London, GBR, education","""This paper outlines a method for evaluating a new chord-labelling algorithm using symbolic data as input. Excerpts from full-score transcriptions of 40 pop songs are used. The accuracy of the algorithm’s output is compared with that of chord labels from published song books, as assessed by experts in pop music theory. We are interested not only in the accuracy of the two sets of labels but also in the question of potential harmonic ambiguity as reﬂected the judges’ assessments. We focus, in this short paper, on outlining the general approach of this research project."""
76,Joan Serrà,A Qualitative Assessment of Measures for the Evaluation of a Cover Song Identification System.,2007,https://doi.org/10.5281/zenodo.1415174,"Joan Serr`a, Universitat Pompeu Fabra, ESP, education","""The evaluation of effectiveness in Information Retrieval systems has been developed in parallel to its evolution, generating a great amount of proposals to achieve this process. This paper focuses on a particular task of Music Information Retrieval: a system for Cover Song Identification. We present a concrete example and then try to elucidate which metrics work best to evaluate such a system. We end up with two evaluation measures suitable for this problem: bpref and Normalized Lift Curves."""
77,Andreas F. Ehmann;J. Stephen Downie;M. Cameron Jones,"The Music Information Retrieval Evaluation Exchange ""Do-It-Yourself"" Web Service.",2007,https://doi.org/10.5281/zenodo.1417949,"Andreas F. Ehmann, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;M. Cameron Jones, University of Illinois at Urbana-Champaign, USA, education","The Do-It-Yourself (DIY) web service of the Music Information Retrieval Evaluation eXchange (MIREX) represents a means by which researchers can remotely submit, execute, and evaluate their Music Information Retrieval (MIR) algorithms against standardized datasets that are not otherwise freely distributable. Since its inception in 2005 at the International Music Information Retrieval Systems Evaluation Laboratory (IMIRSEL), MIREX has, to date, required heavy interaction by IMIRSEL team members in the execution, debugging, and validation of submitted code. The goal of the MIREX DIY web service is to put such responsibilities squarely into the hands of submitters, and also enable the evaluations of algorithms year-round, as opposed to annual exchanges."
78,Jin Ha Lee;J. Stephen Downie;M. Cameron Jones,Preliminary Analyses of Information Features Provided by Users for Identifying Music.,2007,https://doi.org/10.5281/zenodo.1415860,"Jin Ha Lee, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;M. Cameron Jones, University of Illinois at Urbana-Champaign, USA, education","""This paper presents preliminary findings based on the analyses of user-provided information features found in 566 queries seeking help in the identification of particular music works or artists. Queries were drawn from the answers.google.com (Google Answers) website. The types and frequency of occurrences of different information features are compared with the results from previous studies of music queries. New feature types have also been developed to obtain a more comprehensive understanding of the kinds of information present in queries including such things as indications of uncertainty, associated use, and the “aboutness” of the underlying musical work. The presence of erroneous information in the queries is also discussed."""
79,Elizabeth Davis,Finding Music in Scholarly Sets and Series: The Index to Printed Music (IPM).,2007,https://doi.org/10.5281/zenodo.1417747,"Elizabeth Davis, Columbia University, USA, education","The Index to Printed Music (IPM) provides access to sets and series of  music published beginning  in the 19th century.  Prepared by scholars and researchers, these titles  vary  considerably  in length  (single  to multiple volumes), types (topical, pedagogical, historical, etc.), format   (treatises,  dissertations,  editions,  etc.),  and geographic origin (chiefly Europe and North America). Bibliographical access to their contents is not readily available through library cataloging or reference works. IPM provides title, format, genre, instrumentation, and other  metadata  access  to  these  publications  in  three inter-connected  databases:  Bibliography,  Index,  and Names,  available  by  subscription  through  NISC International, Inc.  The Index Database now contains over 255,000 entries, the Bibliography Database over 10,000 entries, and the Names Database over 15,000 authority records.  Having built this groundwork, future steps involve linking to full-text score images where available  through  non-commercial  projects,  and partnerships with publishers and commercial vendors."
80,Alexander Duda;Andreas Nürnberger;Sebastian Stober,Towards Query by Singing/Humming on Audio Databases.,2007,https://doi.org/10.5281/zenodo.1414804,"Alexander Duda, Otto-von-Guericke-University Magdeburg, Germany, education;Andreas Nürnberger, Otto-von-Guericke-University Magdeburg, Germany, education;Sebastian Stober, Otto-von-Guericke-University Magdeburg, Germany, education","Current work on Query-by-Singing/Humming (QBSH) focuses mainly on databases that contain MIDI files. Here, we present an approach that works on real audio recordings that bring up additional challenges. To tackle the problem of extracting the melody of the lead vocals from recordings, we introduce a method inspired by the popular “karaoke effect” exploiting information about the spatial arrangement of voices and instruments in the stereo mix. The extracted signal time series are aggregated into symbolic strings preserving the local approximated values of a feature and revealing higher-level context patterns. This allows distance measures for string pattern matching to be applied in the matching process. A series of experiments are conducted to assess the discrimination and robustness of this representation. They show that the proposed approach provides a viable baseline for further development and point out several possibilities for improvement."
81,David Little;David Raffensperger;Bryan Pardo,A Query by Humming System that Learns from Experience.,2007,https://doi.org/10.5281/zenodo.1416642,"David Little, Northwestern University, USA, education;David Raffensperger, Northwestern University, USA, education;Bryan Pardo, Northwestern University, USA, education","""Query-by-Humming (QBH) systems transcribe a sung or hummed query and search for related musical themes in a database, returning the most similar themes. Since it is not possible to predict all individual singer profiles before system deployment, a robust QBH system should be able to adapt to different singers after deployment. Currently deployed systems do not have this capability. We describe a new QBH system that learns from user provided feedback on the search results, letting the system improve while deployed, after only a few queries.  This is made possible by a trainable note segmentation system, an easily parameterized singer error model and a straight-forward genetic algorithm. Results show significant improvement in performance given only ten example queries from a particular user."""
82,Daniel P. W. Ellis,Classifying Music Audio with Timbral and Chroma Features.,2007,https://doi.org/10.5281/zenodo.1416906,"Daniel P. W. Ellis, Columbia University, USA, education","Music audio classiﬁcation has most often been addressed by modeling the statistics of broad spectral features, which, by design, exclude pitch information and reﬂect mainly in- strumentation. We investigate using instead beat-synchronous chroma features, designed to reﬂect melodic and harmonic content and be invariant to instrumentation. Chroma fea- tures are less informative for classes such as artist, but contain information that is almost entirely independent of the spectral features, and hence the two can be proﬁtably combined: Using a simple Gaussian classiﬁer on a 20-way pop music artist identiﬁcation task, we achieve 54% accu- racy with MFCCs, 30% with chroma vectors, and 57% by combining the two. All the data and Matlab code to obtain these results are available."
83,Arthur Flexer,A Closer Look on Artist Filters for Musical Genre Classification.,2007,https://doi.org/10.5281/zenodo.1415668,"Arthur Flexer, Medical University of Vienna, Austria, education",Musical genre classiﬁcation is the automatic classiﬁca- tion of audio signals into user deﬁned labels describing pieces of music. A problem inherent to genre classiﬁca- tion experiments in music information retrieval research is the use of songs from the same artist in both training and test sets. We show that this does not only lead to over- optimistic accuracy results but also selectively favours par- ticular classiﬁcation approaches. The advantage of using models of songs rather than models of genres vanishes when applying an artist ﬁlter. The same holds true for the use of spectral features versus ﬂuctuation patterns for preprocessing of the audio ﬁles.
84,Janto Skowronek;Martin F. McKinney;Steven van de Par,A Demonstrator for Automatic Music Mood Estimation.,2007,https://doi.org/10.5281/zenodo.1417669,"Janto Skowronek, Philips Research Laboratories, NLD, facility;Martin McKinney, Philips Research Laboratories, NLD, facility;Steven van de Par, Philips Research Laboratories, NLD, facility","Interest in automatic music mood classiﬁcation is increasing because it could enable people to browse and manage their music collections by means of the music’s emotional expression complementary to the widely used music genres. We continue our work on designing a well deﬁned ground-truth database for music mood classiﬁcation and show a demonstrator of automatic mood estimation. While a subjective evaluation of this algorithm on arbitrary music is ongoing, the initial classiﬁcation results are encouraging and suggest that an automatic predicition of music mood is possible."
85,Sten Govaerts;Nik Corthaut;Erik Duval,Mood-ex-Machina: Towards Automation of Moody Tunes.,2007,https://doi.org/10.5281/zenodo.1415918,"Sten Govaerts, Katholieke Universiteit Leuven, BEL, education;Nik Corthaut, Katholieke Universiteit Leuven, BEL, education;Erik Duval, Katholieke Universiteit Leuven, BEL, education","In 2006, the rockanango system was developed for music annotation by music experts. The system allows these experts to create new musical parameters within a flat data structure [1]. Rockanango is deployed in a commercial environment of hotels, restaurants and cafés. One of the main concerns is the time it takes to manually annotate the music and to introduce new parameters. In this paper, we investigate the possibilities to assist the experts by means of automatic metadata generation. Two case studies are described. One focuses on the use of association rules, in combination with lower level metadata like mode and key. The other case study concerns the generation of a topic or subject marker for songs through harvested lyrics and a keyword generator. From our evaluation, we conclude that the generated keywords are relevant and that the music experts value them higher then laymen. Data mining techniques provide means for monitoring the metadata in terms of interparametric relationships that can be used to generate metadata."
86,Ajay Kapur;Graham Percival;Mathieu Lagrange;George Tzanetakis,Pedagogical Transcription for Multimodal Sitar Performance.,2007,https://doi.org/10.5281/zenodo.1417127,"Ajay Kapur, University of Victoria, CAN, education;Graham Percival, University of Victoria, CAN, education;Mathieu Lagrange, University of Victoria, CAN, education;George Tzanetakis, University of Victoria, CAN, education","""Most automatic music transcription research is concerned with producing sheet music from the audio signal alone. However, the audio data does not include certain perfor- mance data which is vital for the preservation of instru- ment performance techniques and the creation of anno- tated guidelines for students. We propose the use of mod- iﬁed traditional instruments enhanced with sensors which can obtain such data; as a case study we examine the sitar."""
87,Arnaud Moreau;Arthur Flexer,Drum Transcription in Polyphonic Music Using Non-Negative Matrix Factorisation.,2007,https://doi.org/10.5281/zenodo.1417455,"Arnaud Moreau, The Austrian Research Institute for Artificial Intelligence, AUT, facility;Arthur Flexer, Medical University of Vienna, AUT, education","""We present a system that is based on the non-negative matrix factorisation (NMF) algorithm and is able to transcribe drum onset events in polyphonic music. The magnitude spectrogram representation of the input music is divided by the NMF algorithm into source spectra and corresponding time-varying gains. Each of these source components is classified as a drum instrument or non-drum sound and a peak-picking algorithm determines the onset times."""
88,Alia Al Kasimi;Eric Nichols;Christopher Raphael,A Simple Algorithm for Automatic Generation of Polyphonic Piano Fingerings.,2007,https://doi.org/10.5281/zenodo.1415880,"Alia Al Kasimi, Indiana University, USA, education;Eric Nichols, Indiana University, USA, education;Christopher Raphael, Indiana University, USA, education","We present a novel method for assigning fingers to notes in a polyphonic piano score. Such a mapping (called a “fingering”) is of great use to performers. To accommodate performers’ unique hand shapes and sizes, our method relies on a simple, user-adjustable cost function. We use dynamic programming to search the space of all possible fingerings for the optimal fingering under this cost function. Despite the simplicity of the algorithm we achieve reasonable and useful results."
89,Karin Dressler;Sebastian Streich,Tuning Frequency Estimation Using Circular Statistics.,2007,https://doi.org/10.5281/zenodo.1416294,"Karin Dressler, Fraunhofer IDMT, DEU, facility;Sebastian Streich, Pompeu Fabra University, ESP, education","In this document a new approach on tuning frequency
estimation based on circular statistics is presented. Two
methods are introduced: the calculation of the tuning fre-
quency over an entire audio piece, and the estimation of
an adapting reference frequency for a single voice.
The results for the tuning frequency estimation look
very good for audio pieces where the dominant voices are
tuned close to the equal-temperament scale and exhibit
only moderate frequency dynamics. For the analysis of
popular western music, the method does not achieve very
robust results due to the strong frequency dynamics of the
human singing voice. Nevertheless, the method could be
improved by excluding the singing voice from the calcu-
lation taking only the accompaniment into account.
The main advantage of the proposed method lies espe-
cially in the easy computation of an adaptive reference fre-
quency using an exponential moving average. This adap-
tive reference can for example be used in the quantization
of the singing voice into a note representation."
90,Edith L. M. Law;Luis von Ahn;Roger B. Dannenberg;Mike Crawford,TagATune: A Game for Music and Sound Annotation.,2007,https://doi.org/10.5281/zenodo.1415568,"Edith L. M. Law, Carnegie Mellon University, USA, education;Luis von Ahn, Carnegie Mellon University, USA, education;Roger B. Dannenberg, Carnegie Mellon University, USA, education;Mike Crawford, Carnegie Mellon University, USA, education","Annotations of audio ﬁles can be used to search and in- dex music and sound databases, provide data for system evaluation, and generate training data for machine learn- ing. Unfortunately, the cost of obtaining a comprehensive set of annotations manually is high. One way to lower the cost of labeling is to create games with a purpose that peo- ple will voluntarily play, producing useful metadata as a by-product. TagATune is an audio-based online game that aims to extract descriptions of sounds and music from hu- man players. This paper presents the rationale, design and preliminary results from a pilot study using a prototype of TagATune to label a subset of the FreeSound database."
91,Michael I. Mandel;Daniel P. W. Ellis,A Web-Based Game for Collecting Music Metadata.,2007,https://doi.org/10.5281/zenodo.1414768,"Michael I Mandel, Columbia University, USA, education;Daniel P W Ellis, Columbia University, USA, education","""We have designed a web-based game to make collecting descriptions of musical excerpts fun, easy, useful, and ob- jective. Participants describe 10 second clips of songs and score points when their descriptions match those of other participants. The rules were designed to encourage users to be thorough and the clip length was chosen to make judgments more objective and speciﬁc. Analysis of pre- liminary data shows that we are able to collect objective and speciﬁc descriptions of clips and that players tend to agree with one another."""
92,Douglas Eck;Thierry Bertin-Mahieux;Paul Lamere,Autotagging Music Using Supervised Machine Learning.,2007,https://doi.org/10.5281/zenodo.1417869,"Douglas Eck, Sun Microsystems, USA, company;Thierry Bertin-Mahieux, Univ. of Montreal, CAN, education;Paul Lamere, Sun Microsystems, USA, company",Social tags are an important component of “Web2.0” mu- sic recommendation websites. In this paper we propose a method for predicting social tags using audio features and supervised learning. These automatically-generated tags (or “autotags”) can furnish information about music that is untagged or poorly tagged. The tags can also serve to smooth the tag space from which similarities and rec- ommendations are made by providing a set of comparable baseline tags for all tracks in a recommender system.
93,Matthias Gruhne;Christian Dittmar;Konstantin Schmidt,Phoneme Recognition in Popular Music.,2007,https://doi.org/10.5281/zenodo.1417111,"Matthias Gruhne, Fraunhofer IDMT, DEU, facility;Konstantin Schmidt, Fraunhofer IDMT, DEU, facility;Christian Dittmar, Fraunhofer IDMT, DEU, facility","Automatic lyrics synchronization for karaoke applications is a major challenge in the ﬁeld of music information re- trieval. An important pre-requisite in order to precisely synchronize the music and corresponding text is the de- tection of single phonemes in the vocal part of polyphonic music. This paper describes a system, which detects the phonemes based on a state-of-the-art audio information retrieval system with harmonics extraction and synthesiz- ing as pre-processing method. The extraction algorithm is based on common speech recognition low-level fea- tures, such as MFCC and LPC. In order to distinguish phonemes, three different classiﬁcation techniques (SVM, GMM and MLP) have been used and their results are de- picted in the paper."
94,Yasunori Ohishi;Masataka Goto;Katunobu Itou;Kazuya Takeda,A Stochastic Representation of the Dynamics of Sung Melody.,2007,https://doi.org/10.5281/zenodo.1414732,"Yasunori OHISHI, Nagoya University, JPN, education;Masataka GOTO, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Katunobu ITOU, Hosei University, JPN, education;Kazuya TAKEDA, Nagoya University, JPN, education","""In this paper, we propose a stochastic representation of a sung melodic contour, called stochastic phase representation (SPR), which can characterize both musical-note information and the dynamics of singing behaviors included in the melodic contour. The SPR is constructed by fitting probability distribution functions to F0 trajectories in the F0-∆F0 phase plane. Since fluctuations in singing can be easily separated by using SPR, we applied SPR to a melodic similarity measure for query-by-humming (QBH) applications. Our experimental results showed that the SPR-based similarity measure was superior to a conventional dynamic-programming-based method."""
95,Chuan Cao;Ming Li 0026;Jian Liu;Yonghong Yan 0002,Singing Melody Extraction in Polyphonic Music by Harmonic Tracking.,2007,https://doi.org/10.5281/zenodo.1414708,"Chuan Cao, Institute of Acoustics, Chinese Academy of Sciences, CHN, facility;Ming Li, Institute of Acoustics, Chinese Academy of Sciences, CHN, facility;Jian Liu, Institute of Acoustics, Chinese Academy of Sciences, CHN, facility;Yonghong Yan, Institute of Acoustics, Chinese Academy of Sciences, CHN, facility","This paper proposes an effective method for automatic melody extraction in polyphonic music, especially vocal melody songs. The method is based on subharmonic summation spectrum and harmonic structure tracking strategy. Performance of the method is evaluated using the LabROSA database 1 . The pitch extraction accuracy of our method is 82.2% on the whole database, while 79.4% on the vocal part."
96,Annamaria Mesaros;Tuomas Virtanen;Anssi Klapuri,Singer Identification in Polyphonic Music Using Vocal Separation and Pattern Recognition Methods.,2007,https://doi.org/10.5281/zenodo.1417395,"Annamaria Mesaros, Tampere University of Technology, Institute of Signal Processing, FIN, education;Tuomas Virtanen, Tampere University of Technology, Institute of Signal Processing, FIN, education;Anssi Klapuri, Tampere University of Technology, Institute of Signal Processing, FIN, education","This paper evaluates methods for singer identiﬁcation in polyphonic music, based on pattern classiﬁcation together with an algorithm for vocal separation. Classiﬁcation strategies include the discriminant functions, Gaussian mixture model (GMM)-based maximum likelihood classiﬁer and nearest neighbour classiﬁers using Kullback-Leibler divergence between the GMMs. A novel method of estimating the symmetric Kullback-Leibler distance between two GMMs is proposed. Two different approaches to singer identiﬁcation were studied: one where the acoustic features were extracted directly from the polyphonic signal and one where the vocal line was ﬁrst separated from the mixture using a predominant melody transcription system. The methods are evaluated using a database of songs where the level difference between the singing and the accompaniment varies. It was found that vocal line separation enables robust singer identiﬁcation down to 0dB and -5dB singer-to-accompaniment ratios."
97,Stanislaw Andrzej Raczynski;Nobutaka Ono;Shigeki Sagayama,Multipitch Analysis with Harmonic Nonnegative Matrix Approximation.,2007,https://doi.org/10.5281/zenodo.1417809,"Stanisław A. Raczyński, The University of Tokyo, JPN, education;Nobutaka Ono, The University of Tokyo, JPN, education;Shigeki Sagayama, The University of Tokyo, JPN, education","""This paper presents a new approach to multipitch analysis by utilizing the Harmonic Nonnegative Matrix Approximation, a harmonically-constrained and penalized version of the Nonnegative Matrix Approximation (NNMA) method. It also includes a description of a note onset, offset and amplitude retrieval procedure based on that technique. Compared with the previous NNMA approaches, specific initialization of the basis matrix is employed – the basis matrix is initialized with zeros everywhere but at positions corresponding to harmonic frequencies of consequent notes of the equal temperament scale. This results in the basis containing nothing but harmonically structured vectors, even after the learning process, and the activity matrix’s rows containing peaks corresponding to note onset times and amplitudes. Furthermore, additional penalties of mutual uncorrelation and sparseness of rows are placed upon the activity matrix. The proposed method is able to uncover the underlying musical structure better than the previous NNMA approaches and makes the note detection process very straightforward."""
98,Eric Nichols;Christopher Raphael,Automatic Transcription of Music Audio Through Continuous Parameter Tracking.,2007,https://doi.org/10.5281/zenodo.1416162,"Eric Nichols, Indiana Univ., USA, education;Christopher Raphael, Indiana Univ., USA, education","We present a method for transcribing arbitrary pitched music into a piano-roll-like representation that also tracks the amplitudes of the notes over time. We develop a probabilistic model that gives the likelihood of a frame of audio data given a vector of amplitudes for the possible notes. Using an approximation of the log likelihood function, we develop an objective function that is quadratic in the time-varying amplitude variables, while also depending on the discrete piano-roll variables. We optimize this function using a variant of dynamic programming, by repeatedly growing and pruning our histories. We present results on a variety of different examples using several measures of performance including an edit-distance measure as well as a frame-by-frame measure."
99,Chunghsin Yeh;Niels Bogaards;Axel Röbel,Synthesized Polyphonic Music Database with Verifiable Ground Truth for Multiple F0 Estimation.,2007,https://doi.org/10.5281/zenodo.1415732,"Chunghsin Yeh, IRCAM / CNRS-STMS, FRA, facility;Niels Bogaards, IRCAM, FRA, facility;Axel Roebel, IRCAM / CNRS-STMS, FRA, facility","To study and to evaluate a multiple F0 estimation algorithm, a polyphonic database with verifiable ground truth is necessary. Real recordings with manual annotation as ground truth are often used for evaluation. However, ambiguities arise during manual annotation, which are often set up by subjective judgements. Therefore, in order to have access to verifiable ground truth, we propose a systematic method for creating a polyphonic music database. Multiple monophonic tracks are rendered from a given MIDI file, in which rendered samples are separated to prevent overlaps and to facilitate automatic annotation. F0s can then be reliably extracted as ground truth, which are stored using SDIF."
100,Jayme Garcia Arnal Barbedo;Amauri Lopes;Patrick J. Wolfe,High Time-Resolution Estimation of Multiple Fundamental Frequencies.,2007,https://doi.org/10.5281/zenodo.1415972,"Jayme Garcia Arnal Barbedo, Harvard University, USA, education; State University of Campinas, BRA, education;Amauri Lopes, State University of Campinas, BRA, education;Patrick J. Wolfe, Harvard University, USA, education","This paper presents a high time-resolution strategy to estimate multiple fundamental frequencies in musical signals. The signal is first divided into overlapping blocks, and a high-resolution estimate made of the short-term spectrum. The resulting spectrum is modified such that only the most relevant spectral components are considered, and an iterative algorithm based on earlier work by Klapuri is used to identify candidate fundamental frequencies. Finally, a context-based rule is used to improve the accuracy of fundamental frequency estimates. The performance of this technique is investigated under both noiseless and noisy conditions, and its accuracy is examined in cases where the polyphony is known and unknown a priori."
101,David A. Torres;Douglas Turnbull;Luke Barrington;Gert R. G. Lanckriet,Identifying Words that are Musically Meaningful.,2007,https://doi.org/10.5281/zenodo.1417175,"David Torres, University of California, San Diego, USA, education;Douglas Turnbull, University of California, San Diego, USA, education;Luke Barrington, University of California, San Diego, USA, education;Gert Lanckriet, University of California, San Diego, USA, education","A musically meaningful vocabulary is one of the keystones
in building a computer audition system that can model the
semantics of audio content. If a word in the vocabulary is
inconsistently used by human annotators, or the word is
not clearly represented by the underlying acoustic repre-
sentation, the word can be considered as noisy and should
be removed from the vocabulary to denoise the model-
ing process.
This paper proposes an approach to con-
struct a vocabulary of predictive semantic concepts based
on sparse canonical component analysis (sparse CCA) .
Experimental results illustrate that, by identifying musi-
cally meaningful words, we can improve the performance
of a previously proposed computer audition system for
music annotation and retrieval."
102,Mark Levy;Mark B. Sandler,A Semantic Space for Music Derived from Social Tags.,2007,https://doi.org/10.5281/zenodo.1415628,"Mark Levy, Centre for Digital Music, Queen Mary, University of London, GBR, education;Mark Sandler, Centre for Digital Music, Queen Mary, University of London, GBR, education","""In this paper we investigate social tags as a novel high-volume source of semantic metadata for music, using techniques from the ﬁelds of information retrieval and multivariate data analysis. We show that, despite the ad hoc and informal language of tagging, tags deﬁne a low-dimensional semantic space that is extremely well-behaved at the track level, in particular being highly organised by artist and musical genre. We introduce the use of Correspondence Analysis to visualise this semantic space, and show how it can be applied to create a browse-by-mood interface for a psychologically-motivatedtwo-dimensional subspace representing musical emotion."""
103,Yves Raimond;Samer A. Abdallah;Mark B. Sandler;Frederick Giasson,The Music Ontology.,2007,https://doi.org/10.5281/zenodo.1415966,"Yves Raimond, Queen Mary, University of London, GBR, education;Samer Abdallah, Queen Mary, University of London, GBR, education;Mark Sandler, Queen Mary, University of London, GBR, education;Frederick Giasson, Zitgist LLC, USA, company","""In this paper, we overview some Semantic Web technolo-
gies and describe the Music Ontology: a formal frame-
work for dealing with music-related information on the
Semantic Web, including editorial, cultural and acous-
tic information. We detail how this ontology can act as a
grounding for more domain-speciﬁc knowledge represen-
tation. In addition, we describe current projects involving
the Music Ontology and interlinked repositories of music-
related knowledge."""
104,Jean-Julien Aucouturier;François Pachet;Pierre Roy;Anthony Beurivé,Signal + Context = Better Classification.,2007,https://doi.org/10.5281/zenodo.1416852,"Jean-Julien Aucouturier, The University of Tokyo, JPN, education;Franc¸ois Pachet, SONY CSL Paris, FRA, company;Pierre Roy, SONY CSL Paris, FRA, company;Anthony Beuriv´e, SONY CSL Paris, FRA, company","Typical signal-based approaches to extract musical descriptions from audio only have limited precision. A possible explanation is that they do not exploit context, which provides important cues in human cognitive processing of music: e.g. electric guitar is unlikely in 1930s music, children choirs rarely perform heavy metal, etc. We propose an architecture to train a large set of binary classifiers simultaneously, for many different musical metadata (genre, instrument, mood, etc.), in such a way that correlation between metadata is used to reinforce each individual classifier. The system is iterative: it uses classification decisions it made on some classification problems as new features for new, harder problems; and hybrid: it uses a signal classifier based on timbre similarity to bootstrap symbolic inference with decision trees. While further work is needed, the approach seems to outperform signal-only algorithms by 5% precision on average, and sometimes up to 15% for traditionally difficult problems such as cultural and subjective categories."
105,Parag Chordia;Alex Rae,Raag Recognition Using Pitch-Class and Pitch-Class Dyad Distributions.,2007,https://doi.org/10.5281/zenodo.1416888,"Parag Chordia, Georgia Institute of Technology, USA, education;Alex Rae, Georgia Institute of Technology, USA, education","""We describe the results of the ﬁrst large-scale raag recog-
nition experiment. Raags are the central structure of In-
dian classical music, each consisting of a unique set of
complex melodic gestures. We construct a system to rec-
ognize raags based on pitch-class distributions (PCDs)
and pitch-class dyad distributions (PCDDs) calculated di-
rectly from the audio signal. A large, diverse database
consisting of 20 hours of recorded performances in 31 dif-
ferent raags by 19 different performers was assembled to
train and test the system. Classiﬁcation was performed us-
ing support vector machines, maximum a posteriori (MAP)
rule using a multivariate likelihood model (MVN), and
Random Forests. When classiﬁcation was done on 60s
segments, a maximum classiﬁcation accuracy of 99.0%
was attained in a cross-validation experiment. In a more
difﬁcult unseen generalization experiment, accuracy was
75%. The current work clearly demonstrates the effective-
ness of PCDs and PCDDs in discriminating raags, even
when musical differences are subtle."""
106,Pedro J. Ponce de León;David Rizo;José Manuel Iñesta Quereda,Towards a Human-Friendly Melody Characterization by Automatically Induced Rules.,2007,https://doi.org/10.5281/zenodo.1414902,"Pedro J. Ponce de León, Universidad de Alicante, Spain, education;David Rizo, Universidad de Alicante, Spain, education;José M. Iñesta, Universidad de Alicante, Spain, education","There is an increasing interest in music information retrieval for reference, motive, or thumbnail extraction from a piece in order to have a compact and representative representation of the information to be retrieved. One of the main references for music is its melody. In a practical environment of symbolic format collections the information can be found in standard MIDI file format, structured as a number of tracks, usually one of them containing the melodic line, while the others contain the accompaniment. The goal of this work is to analyse how statistical rules can be used to characterize a melody in such a way that one can understand the solution of an automatic system for selecting the track containing the melody in such files."
107,George Tzanetakis;Randy Jones;Kirk McNally,Stereo Panning Features for Classifying Recording Production Style.,2007,https://doi.org/10.5281/zenodo.1417537,"George Tzanetakis, University of Victoria, CAN, education;Randy Jones, University of Victoria, CAN, education;Kirk McNally, University of Victoria, CAN, education","Recording engineers, mixers and producers play important yet often overlooked roles in defining the sound of a particular record, artist or group. The placement of different sound sources in space using stereo panning information is an important component of the production process. Audio classification systems typically convert stereo signals to mono and to the best of our knowledge have not utilized information related to stereo panning. In this paper we propose a set of audio features that can be used to capture stereo information. These features are shown to provide statistically important information for non-trivial audio classification tasks and are compared with the traditional Mel-Frequency Cepstral Coefficients. The proposed features can be viewed as a first attempt to capture extra-musical information related to the production process through music information retrieval techniques."
108,Ioannis Karydis;Alexandros Nanopoulos;Apostolos N. Papadopoulos;Emilios Cambouropoulos,VISA: The Voice Integration/Segregation Algorithm.,2007,https://doi.org/10.5281/zenodo.1416552,"Ioannis Karydis, Aristotle University of Thessaloniki, GRC, education;Alexandros Nanopoulos, Aristotle University of Thessaloniki, GRC, education;Apostolos N. Papadopoulos, Aristotle University of Thessaloniki, GRC, education;Emilios Cambouropoulos, Aristotle University of Thessaloniki, GRC, education","Listeners are capable to perceive multiple voices in music. Adopting a perceptual view of musical ‘voice’ that corresponds to the notion of auditory stream, a computational model is developed that splits musical scores (symbolic musical data) into different voices. A single ‘voice’ may consist of more than one synchronous notes that are perceived as belonging to the same auditory stream; in this sense, the proposed algorithm, may separate a given musical work into fewer voices than the maximum number of notes in the greatest chord. This is paramount, among other, for developing MIR systems that enable pattern recognition and extraction within musically pertinent ‘voices’ (e.g. melodic lines). The algorithm is tested against a small dataset that acts as groundtruth."
109,Jörg Garbers;Peter van Kranenburg;Anja Volk;Frans Wiering;Remco C. Veltkamp;Louis P. Grijp,Using Pitch Stability Among a Group of Aligned Query Melodies to Retrieve Unidentified Variant Melodies.,2007,https://doi.org/10.5281/zenodo.1418191,"Jörg Garbers, Utrecht University, NLD, education;Peter van Kranenburg, Utrecht University, NLD, education;Anja Volk, Utrecht University, NLD, education;Frans Wiering, Utrecht University, NLD, education;Remco C. Veltkamp, Utrecht University, NLD, education;Louis P. Grijp, Meertens Institute, Amsterdam, NLD, facility","Melody identiﬁcation is an important task in folk song variation research. In this paper we develop methods and tools that support researchers in ﬁnding melodies in a database that belong to the same variant group as a set of given melodies. The basic approach is to derive from the pitches of the known variants per onset a weighted pitch distribution, which quantiﬁes pitch stability. We allow for partial matching and AND and OR queries. Technically we do so by deﬁning a distance measure between weighted pitch distribution sequences. It is based on two applications of the Earth Mover’s Distance, which is a distribution distance. We set up a distance framework and discuss musically meaningful parameterizations for two tasks: a) Study the inner-group distances between the group as a whole and single members of the group. b) Use the group’s weighted pitch distribution sequence to query for variant melodies. The ﬁrst experimental results seem very promising: a) The inner-group distances correlate to expert assigned subgroups. b) For variant retrieval our method works better than last year’s MIREX winner."
110,Christian André Romming;Eleanor Selfridge-Field,Algorithms for Polyphonic Music Retrieval: The Hausdorff Metric and Geometric Hashing.,2007,https://doi.org/10.5281/zenodo.1417615,"Christian André Romming, Stanford University, USA, education;Eleanor Selfridge-Field, Stanford University, USA, education","We consider two formulations of the computational problem of transposition-invariant, time-offset tolerant, meter-invariant, and time-scale invariant polyphonic music retrieval. We provide algorithms for both that are scalable in the sense that space requirements are asymptotically linear and queries are efficient for large databases of music. The focus is on cases where a query pattern M consisting of m events is to be matched against a database N consisting of n events, and m ≪ n. The database is assumed to be polyphonic, and the algorithms support polyphonic queries. We are interested in finding exact and proximate occurrences of the query pattern. The first problem considered is that of finding the minimum directed Hausdorff distance from M to N. We give a (2 + ǫ)-approximation algorithm that solves this problem in O (nm) query time and O (n) space. The second problem is that of finding all maximal subset matches of M in N, and we give an algorithm that solves this problem in O  m3 (k + 1)  query time and O  w2n  space, where w represents the maximum window size and k is the number of matches. Using the same method, the problem can be solved in O (m (k + 1)) query time and O (wn) space if we do not require the time-scale invariance property. The latter query time is asymptotically optimal for the given problem."
111,Keiichiro Hoashi;Hiromi Ishizaki;Kazunori Matsumoto;Fumiaki Sugaya,Content-Based Music Retrieval Using Query Integration for Users with Diverse Preferences.,2007,https://doi.org/10.5281/zenodo.1416004,"Keiichiro Hoashi, KDDI R&D Laboratories, Inc., JPN, company;Hiromi Ishizaki, KDDI R&D Laboratories, Inc., JPN, company;Kazunori Matsumoto, KDDI R&D Laboratories, Inc., JPN, company;Fumiaki Sugaya, KDDI R&D Laboratories, Inc., JPN, company","This paper proposes content-based music information retrieval (MIR) methods based on user preferences, which aim to improve the accuracy of MIR for users with “diverse” preferences, i.e., users whose preferences range in songs with a wide variety of features. The proposed MIR method dynamically generates an optimal set of query vectors from the sample set of songs submitted by the user to express their preferences, based on the similarity of the songs in the sample set. Experiments conducted on a music collection with subjective user ratings verify that our proposal is effective to improve the accuracy of content-based MIR. Furthermore, by implementing a two-step MIR algorithm which utilizes song clustering results, the efficiency of the proposed MIR method is significantly improved."
112,Hiromasa Fujihara;Masataka Goto,A Music Information Retrieval System Based on Singing Voice Timbre.,2007,https://doi.org/10.5281/zenodo.1416228,"Hiromasa Fujihara, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility","We developed a music information retrieval system based on singing voice timbre, i.e., a system that can search for songs in a database that have similar vocal timbres. To achieve this, we developed a method for extracting feature vectors that represent characteristics of singing voices and calculating the vocal-timbre similarity between two songs by using a mutual information content of their feature vectors. We operated the system using 75 songs and confirmed that the system worked appropriately. According to the results of a subjective experiment, 80% of subjects judged that compared with a conventional method using MFCC, our method finds more appropriate songs that have similar vocal timbres."
113,Hamish Allan;Daniel Müllensiefen;Geraint A. Wiggins,Methodological Considerations in Studies of Musical Similarity.,2007,https://doi.org/10.5281/zenodo.1416956,"Hamish Allan, Goldsmiths, University of London, GBR, education;Daniel M¨ullensiefen, Goldsmiths, University of London, GBR, education;Geraint Wiggins, Goldsmiths, University of London, GBR, education","There are many different aspects of musical similarity [7]. Some relate to acoustic properties, such as melodic [5], rhythmic [10], harmonic [9] and timbral [2]. Others are bound up in cultural aspects: artists involved in creation, year of ﬁrst release, subject matter of lyrics, demograph- ics of listeners, etc. In judgments about musical similar- ity, the relative importance of each of these aspects will change, not only for different listeners, but also for the same listener in different contexts [11]. Extra care must therefore be taken when designing studies in musical sim- ilarity to ensure that the context is an explicit variable. This paper describes the methodology behind our work in context-based musical similarity; introduces a novel sys- tem through which users can specify by example the con- text and focus of their retrieval needs; and details the de- sign of a study to ﬁnd parameters for our system which can also be adapted to test the system as a whole."
114,Malcolm Slaney;William White,Similarity Based on Rating Data.,2007,https://doi.org/10.5281/zenodo.1416402,"Malcolm Slaney, Yahoo! Research, USA, company;William White, Yahoo! Media Innovation, USA, company","""This paper describes an algorithm to measure the similar-
ity of two multimedia objects, such as songs or movies,
using users’ preferences. Much of the previous work on
query-by-example (QBE) or music similarity uses detailed
analysis of the object’s content. This is difﬁcult and it is
often impossible to capture how consumers react to the
music. We argue that a large collection of user’s pref-
erences is more accurate, at least in comparison to our
benchmark system, at ﬁnding similar songs. We describe
an algorithm based the song’s rating data, and show how
this approach works by measuring its performance using
an objective metric based on whether the same artist per-
formed both songs. Our similarity results are based on 1.5
million musical judgments by 380,000 users. We test our
system by generating playlists using a content-based sys-
tem, our rating-based system, and a random list of songs.
Music listeners greatly preferred the ratings-based playlists
over the content-based and random playlists."""
115,Jeremy Reed;Chin-Hui Lee,A Study on Attribute-Based Taxonomy for Music Information Retrieval.,2007,https://doi.org/10.5281/zenodo.1414910,"Jeremy Reed, Georgia Institute of Technology, USA, education;Chin-Hui Lee, Georgia Institute of Technology, USA, education","""We propose an attribute-based taxonomy approach to providing alternative labels to music.  Labels, such as genre, are often used as ground-truth for describing song similarity in music information retrieval (MIR) systems.  A consistent labelling scheme is usually a key in determining quality of classifier learning in training and performance in testing of an MIR system.  We examine links between conventional genre-based taxonomies and acoustical attributes available in text-based descriptions of songs. We show that the vector representation of each song based on these acoustic attributes enables a framework for unsupervised clustering of songs to produce alternative labels and quantitative measures of similarity between songs. Our experimental results demonstrate that this new set of labels are meaningful and classifiers based on these labels achieve similar or better results than those designed with existing genre-based labels."""
116,Wietse Balkema,Variable-Size Gaussian Mixture Models for Music Similarity Measures.,2007,https://doi.org/10.5281/zenodo.1415506,"Wietse Balkema, Robert Bosch GmbH, DEU, company","An algorithm to efﬁciently determine an appropriate num-
ber of components for a Gaussian mixture model is pre-
sented. For determining the optimal model complexity
we do not use a classical iterative procedure, but use the
strong correlation between a simple clustering method
(BSAS [13]) and an MDL-based method [6]. This ap-
proach is computationally efﬁcient and prevents the model
from representing statistically irrelevant data.
The performance of these variable size mixture mod-
els is evaluated with respect to hub occurrences, genre
classiﬁcation and computational complexity. Our variable
size modelling approach marginally reduces the number
of hubs, yields 3-4% better genre classiﬁcation precision
and is approximately 40% less computationally expen-
sive."
117,Craig Stuart Sapp,Comparative Analysis of Multiple Musical Performances.,2007,https://doi.org/10.5281/zenodo.1417693,"Craig Stuart Sapp, Royal Holloway, University of London, GBR, education, Centre for the History and Analysis of Recorded Music (CHARM), GBR, facility","A technique for comparing numerous performances of an identical selection of music is described. The basic methodology is to split a one-dimensional sequence into all possible sequential sub-sequences, perform some operation on these sequences, and then display a summary of the results as a two-dimensional plot; the horizontal axis being time and the vertical axis being sub-sequence length (longer lengths on top by convention). Most types of timewise data extracted from performances can be compared with this technique, although the current focus is on beat-level information for tempo and dynamics as well as commixtures of the two. The primary operation used on each sub-sequence is correlation between a reference performance and analogous segments of other performances, then selecting the best correlated performances for the summary display. The result is a useful navigational aid for coping with large numbers of performances of the same piece of music and for searching for possible influence between performances."
118,Jürgen Diet;Frank Kurth,The Probado Music Repository at the Bavarian State Library.,2007,https://doi.org/10.5281/zenodo.1417527,"Jürgen Diet, Bavarian State Library, DEU, facility;Frank Kurth, University of Bonn, DEU, education","""In this paper, we describe the Probado music repository which is currently set up at the Bavarian State Library, Munich, as part of the larger German Probado digital library initiative. Based on the FRBR approach, we propose a novel work-centric metadata model for organizing the document collection. The primary data contained in the repository currently consists of scanned sheet music and digitized audio recordings. The repository can be searched using both classical and content-based retrieval mechanisms. To this end, we propose a workflow for automated content-based document analysis and indexing."""
119,Peter van Kranenburg;Jörg Garbers;Anja Volk;Frans Wiering;Louis P. Grijp;Remco C. Veltkamp,Towards Integration of MIR and Folk Song Research.,2007,https://doi.org/10.5281/zenodo.1414754,"Peter van Kranenburg, Utrecht University, NLD, education;Jörg Garbers, Utrecht University, NLD, education;Anja Volk, Utrecht University, NLD, education;Frans Wiering, Utrecht University, NLD, education;Louis Grijp, Meertens Institute, Amsterdam, NLD, facility;Remco C. Veltkamp, Utrecht University, NLD, education","""Folk song research (FSR) often deals with large collections of tunes that have various types of relations to each other. Computational methods can support the study of the contents of these collections. Music Information Retrieval (MIR) research provides such methods. Yet a fruitful cooperation of both disciplines is difficult to achieve. We present a role-model to structure this cooperation in which tasks and responsibilities are distributed among the roles of MIR, Computational Musicology (CM) and FSR."""
120,John Ashley Burgoyne;Laurent Pugin;Greg Eustace;Ichiro Fujinaga,A Comparative Survey of Image Binarisation Algorithms for Optical Recognition on Degraded Musical Sources.,2007,https://doi.org/10.5281/zenodo.1418203,"John Ashley Burgoyne, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, education;Laurent Pugin, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, education;Greg Eustace, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, education;Ichiro Fujinaga, Centre for Interdisciplinary Research in Music and Media Technology, Schulich School of Music of McGill University, CAN, education","Binarisation of greyscale images is a critical step in optical music recognition (OMR) preprocessing. Binarising mu- sic documents is particularly challenging because of the nature of music notation, even more so when the sources are degraded, e.g., with ink bleed-through from the other side of the page. This paper presents a comparative eval- uation of 25 binarisation algorithms tested on a set of 100 music pages. A real-world OMR infrastructure for early music (Aruspix) was used to perform an objective, goal- directed evaluation of the algorithms’ performance. Our results differ signiﬁcantly from the ones obtained in stud- ies on non-music documents, which highlights the impor- tance of developing tools speciﬁc to our community."
121,Laurent Pugin;John Ashley Burgoyne;Ichiro Fujinaga,MAP Adaptation to Improve Optical Music Recognition of Early Music Documents Using Hidden Markov Models.,2007,https://doi.org/10.5281/zenodo.1415922,"Laurent Pugin, Centre for Interdisciplinary Research in Music Media and Technology, Schulich School of Music of McGill University, CAN, education;John Ashley Burgoyne, Centre for Interdisciplinary Research in Music Media and Technology, Schulich School of Music of McGill University, CAN, education;Ichiro Fujinaga, Centre for Interdisciplinary Research in Music Media and Technology, Schulich School of Music of McGill University, CAN, education","Despite steady improvement in optical music recognition (OMR), early documents remain challenging because of the high variability in their contents. In this paper, we present an original approach using maximum a posteriori (MAP) adaptation to improve an OMR tool for early typographic prints dynamically based on hidden Markov models. Taking advantage of the fact that during the normal usage of any OMR tool, errors will be corrected, and thus ground-truth produced, the system can be adapted in real-time. We experimented with five 16th-century music prints using 250 pages of music and two procedures in applying MAP adaptation. With only a handful of pages, both recall and precision rates improved even when the baseline was above 95 percent."
122,Klaus Seyerlehner;Gerhard Widmer;Dominik Schnitzer,From Rhythm Patterns to Perceived Tempo.,2007,https://doi.org/10.5281/zenodo.1418373,"Klaus Seyerlehner, Johannes Kepler University Linz, AUT, education;Gerhard Widmer, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence, AUT, facility;Dominik Schnitzer, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence, AUT, facility","There are many MIR applications for which we would like to be able to determine the perceived tempo of a song automatically. However, automatic tempo extraction itself is still an open problem. In general there are two tempo extraction methods, either based on the estimation of inter-onset intervals or based on self similarity computations. To predict a tempo the most significant time-lag or the most significant inter-onset-interval is used. We propose to use existing rhythm patterns and reformulate the tempo extraction problem in terms of a nearest neighbor classification problem. Our experiments, based on three different datasets, show that this novel approach performs at least comparably to state-of-the-art tempo extraction algorithms and could be useful to get a deeper insight into the relation between perceived tempo and rhythm patterns."
123,Gijs Geleijnse;Markus Schedl;Peter Knees,The Quest for Ground Truth in Musical Artist Tagging in the Social Web Era.,2007,https://doi.org/10.5281/zenodo.1416582,"Gijs Geleijnse, Philips Research, NLD, company;Markus Schedl, Johannes Kepler University, AUT, education;Peter Knees, Johannes Kepler University, AUT, education","Research in Web music information retrieval traditionally focuses on the classiﬁcation, clustering or categorizing of music into genres or other subdivisions. However, cur- rent community-based web sites provide richer descrip- tors (i.e. tags) for all kinds of products. Although tags have no well-deﬁned semantics, they have proven to be an effective mechanism to label and retrieve items. More- over, these tags are community-based and hence give a description of a product through the eyes of a community rather than an expert opinion. In this work we focus on Last.fm, which is currently the largest music community web service. We investigate whether the tagging of artists is consistent with the artist similarities found with collab- orative ﬁltering techniques. As the Last.fm data shows to be both consistent and descriptive, we propose a method to use this community-based data to create a ground truth for artist tagging and artist similarity."
124,Mohamed Sordo;Cyril Laurier;Òscar Celma,Annotating Music Collections: How Content-Based Similarity Helps to Propagate Labels.,2007,https://doi.org/10.5281/zenodo.1415708,"Mohamed Sordo, Universitat Pompeu Fabra, ESP, education;Cyril Laurier, Universitat Pompeu Fabra, ESP, education;`Oscar Celma, Universitat Pompeu Fabra, ESP, education","In this paper we present a way to annotate music collections by exploiting audio similarity. Similarity is used to propose labels (tags) to yet unlabeled songs, based on the content–based distance between them. The main goal of our work is to ease the process of annotating huge music collections, by using content-based similarity distances as a way to propagate labels among songs."
125,Douglas Turnbull;Ruoran Liu;Luke Barrington;Gert R. G. Lanckriet,A Game-Based Approach for Collecting Semantic Annotations of Music.,2007,https://doi.org/10.5281/zenodo.1416464,"Douglas Turnbull, University of California, San Diego, USA, education;Ruoran Liu, University of California, San Diego, USA, education;Luke Barrington, University of California, San Diego, USA, education;Gert Lanckriet, University of California, San Diego, USA, education","Games based on human computation are a valuable tool for collecting semantic information about images. We show how to transfer this idea into the music domain in order to collect high-quality semantic information about songs. We present Listen Game, a online, multiplayer game that measures the semantic relationship between music and words. In the normal mode, a player sees a list of semantically related words (e.g., instruments, emo- tions, usages, genres) and is asked to pick the best and worst word to describe a song. In the freestyle mode, a user is asked to suggest a new word that describes the music. Each player receives realtime feedback about the agreement amongst all players. We show that we can use the data collected during a two-week pilot study of Lis- ten Game to learn a supervised multiclass labeling (SML) model. We show that this SML model can annotate a novel song with meaningful words and retrieve relevant songs from a database of audio content."
126,M. Cameron Jones;J. Stephen Downie;Andreas F. Ehmann,Human Similarity Judgments: Implications for the Design of Formal Evaluations.,2007,https://doi.org/10.5281/zenodo.1416126,"M. Cameron Jones, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;Andreas F. Ehmann, University of Illinois at Urbana-Champaign, USA, education","This paper presents findings of a series of analyses of human similarity judgments from the Symbolic Melodic Similarity, and Audio Music Similarity tasks from the Music Information Retrieval Evaluation Exchange (MIREX) 2006. The categorical judgment data generated by the evaluators is analyzed with regard to judgment stability, inter-grader reliability, and patterns of disagreement, both within and between the two tasks. An exploration of this space yields implications for the design of MIREX-like evaluations."
