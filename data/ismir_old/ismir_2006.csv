Unnamed: 0,Authors,Title,Year,Link,Authors with Affiliations,Abstract
0,Catherine Lai;Ichiro Fujinaga,Data Dictionary: Metadata for Phonograph Records.,2006,https://doi.org/10.5281/zenodo.1417423,"Catherine Lai, Schulich School of Music, McGill University, CAN, education;Ichiro Fujinaga, Schulich School of Music, McGill University, CAN, education","""The creation and maintenance of a metadata data dictionary is essential to large-scale digital repositories. It assists the process of data entry, ensures consistency of records, facilitates semantic compatibility and interoperability between systems, and, most importantly, forms the foundation for efficient and effective information retrieval infrastructure. In this paper we explain in detail the necessity of metadata data dictionaries to digitization projects and digital library retrieval services. We also describe the development process of our Data Dictionary for phonograph records. We then present the underlying data model of our Data Dictionary and provide information about the meaning and use of semantic units defined in the Data Dictionary. We stress the usefulness of the generation and maintenance of our Data Dictionary for MIR as it provides a means to ensure accurate, consistent, and comprehensive metadata annotation. For maximum interoperability between systems, digital repositories not only need to agree on the same metadata fields, but also the meanings of the fields. To this end, we believe our Data Dictionary is the cornerstone of optimal retrieval of music information about phonograph records."""
1,Daniel McEnnis;Cory McKay;Ichiro Fujinaga,Overview of OMEN.,2006,https://doi.org/10.5281/zenodo.1418171,"Daniel McEnnis, McGill University, CAN, education;Cory McKay, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","""This paper introduces OMEN (On-demand Metadata Extraction Network), which addresses a fundamental problem in MIR: the lack of universal access to a large dataset containing significant amounts of copyrighted music. This is accomplished by utilizing the large collections of digitized music available at many libraries. Using OMEN, libraries will be able to perform on-demand feature extraction on site, returning feature values to researchers instead of providing direct access to the recordings themselves. This avoids copyright difficulties, since the underlying music never leaves the library that owns it. The analysis is performed using grid-style computation on library machines that are otherwise under-used (e.g., devoted to patron web and catalogue use)."""
2,Jenn Riley;Constance A. Mayer,Ask a Librarian: The Role of Librarians in the Music Information Retrieval Community.,2006,https://doi.org/10.5281/zenodo.1414986,"Jenn Riley, Indiana University, USA, education;Constance A. Mayer, University of Maryland, USA, education","Participation from music librarians has been sparse in the 
first six ISMIR conferences, despite many potential areas 
of common interest. This paper makes an argument for the 
benefit to both the library and Music IR communities of 
increased representation of librarians at ISMIR. An 
analysis of conference programs and primary publications 
of two music library organizations to determine topics 
from the library literature relevant to Music IR research is 
presented. A discussion follows of expertise music 
librarians could potentially contribute to Music IR research 
and the ways in which Music IR research could further the 
work of music librarians, in each of the topics represented 
in the library literature."
3,Xiao Hu 0001;J. Stephen Downie;Andreas F. Ehmann,Exploiting Recommended Usage Metadata: Exploratory Analyses.,2006,https://doi.org/10.5281/zenodo.1415998,"Xiao Hu, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education;Andreas F. Ehmann, University of Illinois at Urbana-Champaign, USA, education","""In this paper, we conduct a series of exploratory analyses 
on the user-recommended usages of music as generated by 
1,042 reviewers who have posted to www.epinions.com.  
Using hierarchical clustering methods on data derived 
from the co-occurrence analyses of usage and genre, usage 
and artist, and usage and album, we are able to conclude 
that further investigation of user-recommended usage 
metadata is warranted, especially with regard to its 
implications for future iterations of the Music Information 
Retrieval Evaluation eXchange (MIREX)."""
4,Jarno Seppänen;Antti J. Eronen;Jarmo Hiipakka,Joint Beat & Tatum Tracking from Music Signals.,2006,https://doi.org/10.5281/zenodo.1417319,"Jarno Sepp¨anen, Nokia Research Center, Finland, facility;Antti Eronen, Nokia Research Center, Finland, facility;Jarmo Hiipakka, Nokia Research Center, Finland, facility","This paper presents a method for extracting two key metrical properties, the beat and the tatum, from acoustic signals of popular music. The method is computationally very efficient while performing comparably to earlier methods. High efficiency is achieved through multirate accent analysis, discrete cosine transform periodicity analysis, and phase estimation by adaptive comb filtering. During analysis, the music signals are first represented in terms of accentuation on four frequency subbands, and then the accent signals are transformed into periodicity domain. Beat and tatum periods and phases are estimated in a probabilistic setting, incorporating primitive musicological knowledge of beat–tatum relations, the prior distributions, and the temporal continuities of beats and tatums. In an evaluation with 192 songs, the beat tracking accuracy of the proposed method was found comparable to the state of the art. Complexity evaluation showed that the computational cost is less than 1% of earlier methods. The authors have written a real-time implementation of the method for the S60 smartphone platform."
5,Nick Whiteley;Ali Taylan Cemgil;Simon J. Godsill,Bayesian Modelling of Temporal Structure in Musical Audio.,2006,https://doi.org/10.5281/zenodo.1415138,"Nick Whiteley, University of Cambridge, GBR, education;A.Taylan Cemgil, University of Cambridge, GBR, education;Simon Godsill, University of Cambridge, GBR, education","""This paper presents a probabilistic model of temporal structure in music which allows joint inference of tempo, meter and rhythmic pattern. The framework of the model naturally quantifies these three musical concepts in terms of hidden state-variables, allowing resolution of otherwise apparent ambiguities in musical structure. At the heart of the system is a probabilistic model of a hypothetical ‘bar-pointer’ which maps an input signal to one cycle of a latent, periodic rhythmical pattern. The system flexibly accommodates different input signals via two observation models: a Poisson points model for use with MIDI onset data and a Gaussian process model for use with raw audio signals. The discrete state-space permits exact computation of posterior probability distributions for the quantities of interest. Results are presented for both observation models, demonstrating the ability of the system to correctly detect changes in rhythmic pattern and meter, whilst tracking tempo."""
6,Frank Kurth;Thorsten Gehrmann;Meinard Müller,The Cyclic Beat Spectrum: Tempo-Related Audio Features for Time-Scale Invariant Audio Identification.,2006,https://doi.org/10.5281/zenodo.1414980,"Frank Kurth, University of Bonn, DEU, education;Thorsten Gehrmann, University of Bonn, DEU, education;Meinard Müller, University of Bonn, DEU, education","""In this paper, we present a novel set of tempo-related audio features for applications in audio retrieval. As opposed to existing feature sets commonly used in the retrieval domain which mainly focus on local spectral characteristics of the audio signal, our features capture its local temporal behaviour w.r.t. tempo, rhythm, and meter. As a key component to obtaining a high level of feature robustness we introduce the cyclic beat spectrum (CBS) consisting of residual tempo classes which are constructed similarly to the well-known pitch chroma classes. We illustrate the use of the newly constructed features by applying them to robust time-scale invariant audio identification."""
7,Donald Byrd;Megan Schindele,Prospects for Improving OMR with Multiple Recognizers.,2006,https://doi.org/10.5281/zenodo.1418307,"Donald Byrd, Indiana University, USA, education;Megan Schindele, Indiana University, USA, education","OMR (Optical Music Recognition) programs have been 
available for years, but they still leave much to be desired 
in terms of accuracy. We studied the feasibility of 
achieving substantially better accuracy by using the output 
of several programs to “triangulate” and get better results 
than any of the individual programs; this multiple-
recognizer approach has had some success with other 
media but, to our knowledge, has never been tried for 
music. A major obstacle is that the complexity of music 
notation is such that evaluating OMR accuracy is difficult 
for any but the simplest music. Nonetheless, existing 
programs have serious enough limitations that the multiple-
recognizer approach is promising."
8,David Bainbridge 0001;Tim Bell,Identifying music documents in a collection of images.,2006,https://doi.org/10.5281/zenodo.1416424,"David Bainbridge, University of Waikato, NZL, education;Tim Bell, University of Canterbury, NZL, education","Digital libraries and search engines are now well-equipped
to ﬁnd images of documents based on queries. Many images
of music scores are now available, often mixed up with tex-
tual documents and images. For example, using the Google
“images” search feature, a search for “Beethoven” will re-
turn a number of scores and manuscripts as well as pictures
of the composer. In this paper we report on an investiga-
tion into methods to mechanically determine if a particular
document is indeed a score, so that the user can specify that
only musical scores should be returned. The goal is to ﬁnd a
minimal set of features that can be used as a quick test that
will be applied to large numbers of documents.
A variety of ﬁlters were considered, and two promising
ones (run-length ratios and Hough transform) were evalu-
ated.
We found that a method based around run-lengths
in vertical scans (RL) that out-performs a comparable al-
gorithm using the Hough transform (HT). On a test set of
1030 images, RL achieved recall and precision of 97.8% and
88.4% respectively while HT achieved 97.8% and 73.5%. In
terms of processor time, RL was more than ﬁve times as fast
as HT."
9,Laurent Pugin,Optical Music Recognitoin of Early Typographic Prints using Hidden Markov Models.,2006,https://doi.org/10.5281/zenodo.1416974,"Laurent Pugin, McGill University, Montreal, Canada, education","Music printed with movable type (typographic music) from
the 16th and 17th centuries contains speciﬁc graphic fea-
tures.
In this paper, we present a technique and associ-
ated experiments for performing optical music recognition
on such music prints using Hidden Markov Models (HMM).
Our original approach avoids the difﬁcult and unreliable re-
moval of staff lines usually required before processing. The
modeling of symbols on the staff is based on low-level sim-
ple features. We show that, using our technique, these fea-
tures are robust enough to obtain good recognition rates even
with poor quality images scanned from microﬁlm of origi-
nals. The music content retrieved by the optical recognition
process can be put to signiﬁcant use in, for example, the
creation of searchable digital music libraries."
10,Søren Tjagvad Madsen;Gerhard Widmer,Separating voices in MIDI.,2006,https://doi.org/10.5281/zenodo.1414752,"Søren Tjagvad Madsen, Austrian Research Institute for Artificial Intelligence, AUT, facility;Gerhard Widmer, Johannes Kepler University, AUT, education","""This paper presents an algorithm for converting midi events into logical voices. The algorithm is fundamentally based on the pitch proximity principle. New heuristics are introduced and evaluated in order to handle unsolved situations. The algorithm is tested on ground truth data: inventions and fugues by J. S. Bach. Due to its left to right processing it also runs on real time input."""
11,David Rizo;Pedro J. Ponce de León;Carlos Pérez-Sancho;Antonio Pertusa;José Manuel Iñesta Quereda,A Pattern Recognition Approach for Melody Track Selection in MIDI Files.,2006,https://doi.org/10.5281/zenodo.1417419,"David Rizo, Universidad de Alicante, ESP, education;Pedro J. Ponce de Le´on, Universidad de Alicante, ESP, education;Carlos P´erez-Sancho, Universidad de Alicante, ESP, education;Antonio Pertusa, Universidad de Alicante, ESP, education;Jos´e M. I˜nesta, Universidad de Alicante, ESP, education","Standard MIDI ﬁles contain data that can be considered as
a symbolic representation of music (a digital score), and
most of them are structured as a number of tracks. One of
them usually contains the melodic line of the piece, while
the other tracks contain accompaniment music. The goal of
this work is to identify the track that contains the melody us-
ing statistical properties of the musical content and pattern
recognition techniques. Finding that track is very useful for
a number of applications, like speeding up melody match-
ing when searching in MIDI databases or motif extraction,
among others. First, a set of descriptors from each track of
the target ﬁle are extracted. These descriptors are the input
to a random forest classiﬁer that assigns the probability of
being a melodic line to each track. The track with the high-
est probability is selected as the one containing the melodic
line of that MIDI ﬁle. Promising results have been obtained
testing a number of databases of different music styles."
12,Amaury Hazan;Maarten Grachten;Rafael Ramírez 0001,Evolving Performance Models by Performance Similarity: Beyond Note-to-note Transformations.,2006,https://doi.org/10.5281/zenodo.1417691,"Amaury Hazan, Pompeu Fabra University, ESP, education;Maarten Grachten, Spanish Council for Scientific Research, ESP, facility;Rafael Ramirez, Pompeu Fabra University, ESP, education","""This paper focuses on expressive music performance mod-
eling. We induce a population of score-driven performance
models using a database of annotated performances extracted
from saxophone acoustic recordings of jazz standards. In
addition to note-to-note timing transformations that are in-
variably introduced in human renditions, more extensive al-
terations that lead to insertions and deletions of notes are
usual in jazz performance. In spite of this, inductive ap-
proaches usually treat these latter alterations as artifacts. As
a ﬁrst step, we integrate part of the alterations occurring in
jazz performances in an evolutionary regression tree model
based on strongly typed genetic programming (STGP). This
is made possible (i) by creating a new regression data type
that includes a range of melodic alterations and (ii) by using
a similarity measurement based on an edit-distance ﬁt to hu-
man performance similarity judgments. Finally, we present
the results of both learning and generalization experiments
using a set of standards from the Real Book."""
13,Megan A. Winget,Heroic Frogs Save the Bow: Performing Musician's Annotation and Interaction Behavior with Written Music.,2006,https://doi.org/10.5281/zenodo.1417709,"Megan Winget, University of Texas at Austin, USA, education","""Although there have been a number of fairly recent studies in which researchers have explored the information seeking and management behaviors of people interacting with musical retrieval systems, there have been very few published studies of the interaction and use behaviors of musicians themselves. The qualitative research study reported here seeks to correct this deficiency in the literature. Drawing on data collected from nearly 300 annotated parts representing 15 unique works, and 20 musician interviews, we make a number of functionality recommendations for constructive music digital library tool development. For example, all musicians annotate their written music, although this action seems to become more important as the musician becomes more skilled. Musicians’ annotations are comprehensible to anyone who can read music, and are valuable as records of interpretation, interaction, and performance. Musicians annotate at the note (rather than at the phrase or movement) level, their annotations are standardized and formal, and are largely non-text. Music digital libraries that cater to musicians should attempt to provide annotation tools that work at the micro level, and extend the symbolic language of the primary document. Furthermore, preserving the annotations for future use would prove valuable for performance students, professionals, and historians alike."""
14,Matthias Robine;Mathieu Lagrange,Evaluation of the Technical Leval of Saxophone Performers by Considering the Evolution of Spectral Parameters of the Sound.,2006,https://doi.org/10.5281/zenodo.1416620,"Matthias Robine, Université Bordeaux 1, FRA, education;Mathieu Lagrange, Université Bordeaux 1, FRA, education","We introduce in this paper a new method to evaluate the technical level of a musical performer, by considering only the evolutions of the spectral parameters during one tone. The proposed protocol may be considered as front end for music pedagogy related softwares that intend to provide feedback to the performer. Although this study only considers alto saxophone recordings, the evaluation protocol intends to be as generic as possible and may surely be considered for wider range of classical instruments from winds to bowed strings."
15,James Bergstra;Alexandre Lacoste;Douglas Eck,Predicting genre labels for artist using FreeDB.,2006,https://doi.org/10.5281/zenodo.1416448,"James Bergstra, Université de Montréal, CAN, education;Alexandre Lacoste, Université de Montréal, CAN, education;Douglas Eck, Université de Montréal, CAN, education","""This paper explores the value of FreeDB as a source of genre and music similarity information. FreeDB is a public, dynamic, uncurated database for identifying and labelling CDs with album, song, artist and genre information. One quality of FreeDB is that there is high variance in, e.g., the genre labels assigned to a particular disc. We investigate here the ability to use these genre labels to predict a more constrained set of “canonical” genres as decided by the curated but private database AllMusic (i.e. multi-class learning). This work is relevant for study in music similarity: we present an automatic, data-driven method for embedding artists in a continuous space that corresponds to genre similarity judgements over a large population of music fans. At the same time, we observe that FreeDB is a valuable resource to researchers developing music classification algorithms; it serves as a reference for what music is popular over a large population, and provides relevant targets for supervised learning algorithms."""
16,Jeremy Reed;Chin-Hui Lee,A Study on Music Genre Classification Based on Universal Acoustic Models.,2006,https://doi.org/10.5281/zenodo.1417255,"Jeremy Reed, Georgia Institute of Technology, USA, education;Chin-Hui Lee, Georgia Institute of Technology, USA, education","""Classification of musical genres gives a useful measure of similarity and is often the most useful descriptor of a musical piece.  Previous techniques to use hidden Markov models (HMMs) for automatic genre classification have used a single HMM to model an entire song or genre.  This paper provides a framework to give finer segmentation of HMMs through acoustic segment modeling.  Modeling each of these acoustic segments with an HMM builds a timbral dictionary in the same fashion that one would create a phonetic dictionary for speech.  A symbolic transcription is created by finding the most likely sequence of symbols.  These transcriptions then serve as inputs into an efficient text classifier utilized to provide a solution to the genre classification problem.  This paper demonstrates that language-ignorant approaches provide results that are consistent with the current state-of-the-art for the genre classification problem.  However, the finer segmentation potentially allows for “musical language”-based syntactic rules to enhance performance."""
17,Arie Livshin;Xavier Rodet,"The Significance of the Non-Harmonic ""Noise"" Versis the Harmonic Series for Musical Instrument Recognition.",2006,https://doi.org/10.5281/zenodo.1416538,"Arie Livshin, IRCAM Centre Pompidou, FRA, facility;Xavier Rodet, IRCAM Centre Pompidou, FRA, facility","Sound produced by Musical instruments with definite pitch consists of the Harmonic Series and the non-harmonic Residual. It is common to treat the Harmonic Series as the main characteristic of the timbre of pitched musical instruments. But does the Harmonic Series indeed contain the complete information required for discriminating among different musical instruments? Could the non-harmonic Residual, the “noise”, be used all by itself for instrument recognition? The paper begins by performing musical instrument recognition with an extensive sound collection using a large set of feature descriptors, achieving a high instrument recognition rate. Next, using Additive Analysis/Synthesis, each sound sample is resynthesized using solely its Harmonic Series. These “Harmonic” samples are then subtracted from the original samples to retrieve the non-harmonic Residuals. Instrument recognition is performed on the resynthesized and the “Residual” sound sets. The paper shows that the Harmonic Series by itself is indeed enough for achieving a high instrument recognition rate; however, the non-harmonic Residuals by themselves can also be used for distinguishing among musical instruments, although with lesser success. Using feature selection, the best 10 feature descriptors for instrument recognition out of our extensive feature set are presented for the Original, Harmonic and Residual sound sets."
18,Cory McKay;Ichiro Fujinaga,Musical genre classification: Is it worth pursuing and how can it be improved?,2006,https://doi.org/10.5281/zenodo.1417417,"Cory McKay, Schulich School of Music, McGill University, CAN, education;Ichiro Fujinaga, Schulich School of Music, McGill University, CAN, education","Research in automatic genre classification has been producing increasingly small performance gains in recent years, with the result that some have suggested that such research should be abandoned in favor of more general similarity research. It has been further argued that genre classification is of limited utility as a goal in itself because of the ambiguities and subjectivity inherent to genre. This paper presents a number of counterarguments that emphasize the importance of continuing research in automatic genre classification. Specific strategies for overcoming current performance limitations are discussed, and a brief review of background research in musicology and psychology relating to genre is presented. Insights from these highly relevant fields are generally absent from discourse within the MIR community, and it is hoped that this will help to encourage a more multi-disciplinary approach to automatic genre classification in the future."
19,Aggelos Pikrakis;Theodoros Giannakopoulos;Sergios Theodoridis,A computationally efficient speech/music discriminator for radio recordings.,2006,https://doi.org/10.5281/zenodo.1414862,"Aggelos Pikrakis, University of Athens, GRC, education;Theodoros Giannakopoulos, University of Athens, GRC, education;Sergios Theodoridis, University of Athens, GRC, education","""This paper presents a speech/music discriminator for radio recordings, based on a new and computationally efﬁcient region growing technique, that bears its origins in the ﬁeld of image segmentation. The proposed scheme operates on a single feature, a variant of the spectral entropy, which is extracted from the audio recording by means of a short-term processing technique. The proposed method has been tested on recordings from radio stations broadcasting over the Internet and, despite its simplicity, has proved to yield performance results comparable to more sophisticated approaches."""
20,Arthur Flexer;Fabien Gouyon;Simon Dixon;Gerhard Widmer,Probabilistic Combination of Features for Music Classification.,2006,https://doi.org/10.5281/zenodo.1415524,"Arthur Flexer, Institute of Medical Cybernetics and Artificial Intelligence, Center for Brain Research, Medical University of Vienna, Austria, education;Fabien Gouyon, Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria, facility;Simon Dixon, Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria, facility;Gerhard Widmer, Department of Computational Perception, Johannes Kepler University, Linz, Austria, education",We describe an approach to the combination of music similarity feature spaces in the context of music classification. The approach is based on taking the product of posterior probabilities obtained from separate classifiers for the different feature spaces. This allows for a different influence of the classifiers per song and an overall classification accuracy improving those resulting from individual feature spaces alone. This is demonstrated by combining spectral and rhythmic similarity for classification of ballroom dance music.
21,Geoffroy Peeters,Chroma-based estimation of musical key from audio-signal analysis.,2006,https://doi.org/10.5281/zenodo.1416420,"Geoffroy Peeters, Ircam - Sound Analysis/Synthesis Team, CNRS - STMS, FRA, facility","This paper deals with the automatic estimation of key (key-
note and mode) of a music track from the analysis of its
audio signal.
Such a system usually relies on a succes-
sion of processes, each one making hypotheses about either
the signal content or the music content: spectral representa-
tion, mapping to chroma, decision about the global key of
the music piece. We review here the underlying hypothe-
ses, compare them and propose improvements over current
state of the art. In particular, we propose the use of a Har-
monic Peak Subtraction algorithm as a front-end of the sys-
tem and evaluate the performance of an approach based on
hidden Markov models.
We then compare our approach
with other approaches in an evaluation using a database of
302 baroque, classical and romantic music tracks."
22,Katy C. Noland;Mark B. Sandler,Key Estimation Using a Hidden Markov Model.,2006,https://doi.org/10.5281/zenodo.1415800,"Katy Noland, Queen Mary, University of London, GBR, education;Mark Sandler, Queen Mary, University of London, GBR, education","A novel technique to estimate the predominant key in a mu-
sical excerpt is proposed. The key space is modelled by a
24-state Hidden Markov Model (HMM), where each state
represents one of the 24 major and minor keys, and each
observation represents a chord transition, or pair of consec-
utive chords. The use of chord transitions as the observa-
tions models a greater temporal dependency between con-
secutive chords than would observations of single chords.
The key transition and chord emission probabilities are ini-
tialised using the results of perceptual tests in order to reﬂect
the human expectation of harmonic relationships. HMM pa-
rameters are then trained on a per-song basis using hand-
annotated chord symbols, before the model for each song
is decoded to give the likelihood of each key at each time
frame. Examples of the algorithm as a segmentation tech-
nique are given, and its capability to estimate the overall key
of a song is evaluated using a data set of 110 Beatles songs,
of which 91% were correctly classiﬁed. An extension to in-
clude operation from audio data instead of chord symbols
is planned, which will enable application to general music
retrieval purposes."
23,Özgür Izmirli,Audio Key Finding Using Low-Dimensional Spaces.,2006,https://doi.org/10.5281/zenodo.1415858,"Özgür İzmirli, Connecticut College, USA, education","""This paper presents two models of audio key finding: a template based correlational model and a template based model that uses a low-dimensional tonal representation. The first model uses a confidence weighted correlation to find the most probable key. The second model is distance based and employs dimensionality reduction to the tonal representation before generating a key estimate. Experiments to determine the dependence of key finding accuracy on dimensionality are presented. Results show that low dimensional representations, compared to commonly used 12 dimensions, may be utilized for key finding without sacrificing accuracy. The first model’s independently verified performance enabled it to be used as a benchmark for evaluation of the second model. Key finding accuracies for both models are given together with detailed results of the second model’s performance as a function of the number of dimensions used."""
24,Kyogu Lee;Malcolm Slaney,Automatic Chord Recognition from Audio Using a HMM with Supervised Learning.,2006,https://doi.org/10.5281/zenodo.1415158,"Kyogu Lee, Center for Computer Research in Music and Acoustics, Department of Music, Stanford University, USA, education;Malcolm Slaney, Yahoo! Research, USA, company","""In this paper, we propose a novel method for obtaining labeled training data to estimate the parameters in a supervised learning model for automatic chord recognition. To this end, we perform harmonic analysis on symbolic data to generate label files. In parallel, we generate audio data from the same symbolic data, which are then provided to a machine learning algorithm along with label files to estimate model parameters. Experimental results show higher performance in frame-level chord recognition than the previous approaches."""
25,Steffen Pauws;Wim Verhaegh;Mark Vossen,Fast Generation of Optimal Music Playlists using Local Search.,2006,https://doi.org/10.5281/zenodo.1417050,"Steffen Pauws, Philips Research Europe, NLD, facility;Wim Verhaegh, Philips Research Europe, NLD, facility;Mark Vossen, Philips Research Europe, NLD, facility","We present an algorithm for use in an interactive music system that automatically generates music playlists that fit the music preferences given by a user. To this end, we introduce a formal model, define the problem of automatic playlist generation (APG) and indicate its NP-hardness. We use a local search (LS) procedure based on simulated annealing (SA) to solve the APG problem. In order to employ this LS procedure, we introduce an optimization variant of the APG problem, which includes the definition of penalty functions and a neighborhood structure. To improve upon the performance of the standard SA algorithm, we incorporated three heuristics referred to as song domain reduction, partial constraint voting, and two-level neighborhood structure. In tests, LS performed better than a constraint satisfaction (CS) solution in terms of run time, scalability and playlist quality."
26,Michael A. Casey;Malcolm Slaney,Song Intersection by Approximate Nearest Neighbor Search.,2006,https://doi.org/10.5281/zenodo.1417827,"Michael Casey, Goldsmiths College, University of London, GBR, education;Malcolm Slaney, Yahoo! Research Inc., USA, company","We present new methods for computing inter-song similarities using intersections between multiple audio pieces. The intersection contains portions that are similar, when one song is a derivative work of the other for example, in two different musical recordings. To scale our search to large song databases we have developed an algorithm based on locality-sensitive hashing (LSH) of sequences of audio features called audio shingles. LSH provides an efﬁcient means to identify approximate nearest neighbors in a high-dimensional feature space. We combine these nearest neighbor estimates, each a match from a very large database of audio to a small portion of the query song, to form a measure of the approximate similarity. We demonstrate the utility of our methods on a derivative works retrieval experiment using both exact and approximate (LSH) methods. The results show that LSH is at least an order of magnitude faster than the exact nearest neighbor method and that accuracy is not impacted by the approximate method."
27,Raphaël Clifford;Manolis Christodoulakis;Tim Crawford;David Meredith 0001;Geraint A. Wiggins,"A Fast, Randomised, Maximal Subset Matching Algorithm for Document-Level Music Retrieval.",2006,https://doi.org/10.5281/zenodo.1414878,"Raphaël Clifford, University of Bristol, UK, education;Manolis Christodoulakis, King’s College, London, UK, education;Tim Crawford, Goldsmiths College, University of London, UK, education;David Meredith, Goldsmiths College, University of London, UK, education;Geraint Wiggins, Goldsmiths College, University of London, UK, education","""We present MSM, a new maximal subset matching algorithm, for MIR at score level with polyphonic texts and patterns. First, we argue that the problem MSM and its ancestors, the SIA family of algorithms, solve is 3SUM-hard and, therefore, subquadratic solutions must involve approximation. MSM is such a solution; we describe it, and argue that, at O(n log n) time with no large constants, it is orders of magnitude more time-efficient than its closest competitor. We also evaluate MSM’s performance on a retrieval problem addressed by the OMRAS project, and show that it outperforms OMRAS on this task by a considerable margin."""
28,Olivier Gillet;Gaël Richard,ENST-Drums: an extensive audio-visual database for drum signals processing.,2006,https://doi.org/10.5281/zenodo.1415902,"Olivier Gillet, GET / ENST, CNRS LTCI, FRA, facility;Ga¨el Richard, GET / ENST, CNRS LTCI, FRA, facility","One of the main bottlenecks in the progress of the Music Information Retrieval (MIR) research ﬁeld is the limited ac- cess to common, large and annotated audio databases that could serve for technology development and/or evaluation. The aim of this paper is to present in detail the ENST-Drums database, emphasizing on both the content and the recording process. This audiovisual database of drum performances by three professional drummers was recorded on 8 audio channels and 2 video channels. The drum sequences are fully annotated and will be, for a large part, freely distributed for research purposes. The large variety in its content should serve research in various domains of audio signal process- ing involving drums, ranging from single drum event clas- siﬁcation to complex multimodal drum track transcription and extraction from polyphonic music."
29,Cory McKay;Daniel McEnnis;Ichiro Fujinaga,A Large Publicly Accassible Prototype Audio Database for Music Research.,2006,https://doi.org/10.5281/zenodo.1416652,"Cory McKay, McGill University, CAN, education;Daniel McEnnis, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","""This paper introduces Codaich, a large and diverse publicly accessible database of musical recordings for use in music information retrieval (MIR) research. The issues that must be dealt with when constructing such a database are discussed, as are ways of addressing these problems. It is suggested that copyright restrictions may be overcome by allowing users to make customized feature extraction queries rather than allowing direct access to recordings themselves. The jMusicMetaManager software is introduced as a tool for improving metadata associated with recordings by automatically detecting inconsistencies and redundancies."""
30,Alex Loscos;Ye Wang;Wei Jie Jonathan Boo,Low Level Descriptors for Automatic Violin Transcription.,2006,https://doi.org/10.5281/zenodo.1416020,"Alex Loscos, Universitat Pompeu Fabra, ESP, education, National University of Singapore, SGP, education;Ye Wang, National University of Singapore, SGP, education;Wei Jie Jonathan Boo, National University of Singapore, SGP, education","""On top of previous work in automatic violin transcription we present a set of straight forward low level descriptors for assisting the transcription techniques and saving computational cost. Proposed descriptors have been tested against a database of 1500 violin notes and double stops."""
31,Motoyuki Suzuki;Toru Hosoya;Akinori Ito;Shozo Makino,Music Information Retrieval from a Singing Voice Based on Verification of Recognized Hypotheses.,2006,https://doi.org/10.5281/zenodo.1414786,"Motoyuki Suzuki, Graduate School of Engineering, Tohoku University, JPN, education;Toru Hosoya, Graduate School of Engineering, Tohoku University, JPN, education;Akinori Ito, Graduate School of Engineering, Tohoku University, JPN, education;Shozo Makino, Graduate School of Engineering, Tohoku University, JPN, education","Several music information retrieval (MIR) systems have been developed which retrieve musical pieces by the user’s singing voice. All of these systems use only melody information for retrieval, although lyrics information is also useful for retrieval. In this paper, we propose an MIR system that uses both melody and lyrics information in the singing voice. The MIR system verifies hypotheses output by a lyrics recognizer from a melodic point of view. Each hypothesis has time alignment information between the singing voice and recognized text, and the boundaries of each note can be estimated using the information. As a result, melody information is extracted from the singing voice. On the other hand, the melody information can be calculated from the musical score of the song because the recognized text must be a part of the lyrics of the song. The hypothesis is verified by calculating the similarity between the two types of melody information. From the experimental results, the verification method increased the retrieval accuracy. Especially, it was very effective when the number of words in the user’s singing voice was small. The proposed method increased the retrieval accuracy from 81.3% to 87.4% when the number of words was only three."
32,Katsutoshi Itoyama;Tetsuro Kitahara;Kazunori Komatani;Tetsuya Ogata;Hiroshi G. Okuno,Automatic Feature Weighting in Automatic Transcription of Specified Part in Polyphonic Music.,2006,https://doi.org/10.5281/zenodo.1417887,"Katsutoshi Itoyama, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuro Kitahara, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Kazunori Komatani, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuya Ogata, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education;Hiroshi G. Okuno, Dept. of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, JPN, education","We studied the problem of automatic music transcription (AMT) for polyphonic music. AMT is an important task for music information retrieval because AMT results enable retrieving musical pieces, high-level annotation, demixing, etc. We attempted to transcribe a part played by an instrument specified by users (specified part tracking). Only two timbre models are required in the specified part tracking to identify the specified musical instrument even when the number of instruments increases. This transcription is formulated into a time-series classification problem with multiple features. We furthermore attempted to automatically estimate weights of the features, because the importance of these features varies for each musical signal. We estimated quasi-optimal weights of the features using a genetic algorithm for each musical signal. We tested our AMT system using trio stereo musical signals. Accuracies with our feature weighting method were 69.8% on average, whereas those without feature weighting were 66.0%."
33,Yipeng Li;DeLiang Wang,Singing Voice Separation from Monaural Recordings.,2006,https://doi.org/10.5281/zenodo.1416006,"Yipeng Li, The Ohio State University, USA, education;DeLiang Wang, The Ohio State University, USA, education","""Separating singing voice from music accompaniment has wide applications in areas such as automatic lyrics recognition and alignment, singer identiﬁcation, and music information retrieval. Compared to the extensive studies of speech separation, singing voice separation has been little explored. We propose a system to separate singing voice from music accompaniment from monaural recordings. The system has three stages. The singing voice detection stage partitions and classiﬁes an input into vocal and non-vocal portions. Then the predominant pitch detection stage detects the pitch contour of the singing voice for vocal portions. Finally the separation stage uses the detected pitch contour to group the time-frequency segments of the singing voice. Quantitative results show that the system performs well in singing voice separation."""
34,Emilia Gómez;Perfecto Herrera,The song remains the same: identifying versions of the same piece using tonal descriptors.,2006,https://doi.org/10.5281/zenodo.1417273,"Emilia Gómez, Universitat Pompeu Fabra, ESP, education;Perfecto Herrera, Universitat Pompeu Fabra, ESP, education","Identifying versions of the same song by means of automatically extracted audio features is a complex task for a music information retrieval system, even though it may seem very simple for a human listener. The design of a system to perform this task gives the opportunity to analyze which features are relevant for music similarity. This paper focuses on the analysis of tonal similarity and its application to the identification of different versions of the same piece. This work formulates the situations where a song is versioned and several musical aspects are transformed with respect to the canonical version. A quantitative evaluation is made using tonal descriptors, including chroma representations and tonality. A simple similarity measure, based on Dynamic Time Warping over transposed chroma features, yields around 55% accuracy, which exceeds by far the expected random baseline rate."
35,Thomas Lidy;Andreas Rauber,Visually Profiling Radio Stations.,2006,https://doi.org/10.5281/zenodo.1418079,"Thomas Lidy, Vienna University of Technology, AUT, education;Andreas Rauber, Vienna University of Technology, AUT, education","The overwhelming number of radio stations, both online and over the air, makes the choice of an appropriate program difﬁcult. By proﬁling the program content of radio stations using Self-Organizing Maps we provide a reﬂection of a sta- tion’s program type and give potential listeners a visual clue for selecting radio stations. Proﬁles of current broadcasts indicate which program type a station is currently playing. By creating radio station maps it is possible to directly pick a speciﬁc program type instead of having to search for a suitable radio station."
36,Meinard Müller;Henning Mattes;Frank Kurth,An Efficient Multiscale Approach to Audio Synchronization.,2006,https://doi.org/10.5281/zenodo.1417409,"Meinard Müller, University of Bonn, DEU, education;Henning Mattes, University of Bonn, DEU, education;Frank Kurth, University of Bonn, DEU, education","""We present an efﬁcient and robust multiscale DTW (Ms-
DTW) approach to music synchronization for time-aligning
CD recordings of different interpretations of the same piece.
The general strategy is to recursively project an alignment
path computed at a coarse resolution level to the next higher
level and then to reﬁne the projected path. As main contribu-
tions, we address several crucial issues including the design
and speciﬁcation of robust and scalable audio features, suit-
able local cost measures, MsDTW levels, constraint regions,
as well as sampling rate adaptation and structural enhance-
ment strategies. Extensive experiments on Western classi-
cal music show that our MsDTW-based algorithm yields the
same alignment result as the classical DTW-based strategy
while signiﬁcantly reducing the running time and memory
requirements. Even for pieces of a duration of 10 to 15 min-
utes, the alignment (based on previously extracted feature
sequences) can be computed in less than a second."""
37,Michael J. Bruderer;Martin F. McKinney;Armin Kohlrausch,Structural boundary perception in popular music.,2006,https://doi.org/10.5281/zenodo.1418339,"Michael J. Bruderer, Technische Universiteit Eindhoven, NLD, education;Martin McKinney, Philips Research Laboratories, NLD, company;Armin Kohlrausch, Technische Universiteit Eindhoven, NLD, education; Philips Research Laboratories, NLD, company","""The automatic extraction of musical structure from audio is an important aspect for many music information retrieval (MIR) systems. The criteria on which structural elements in music are deﬁned in MIR systems is often not clearly stated but typically stem from (music) theoretical or signal-based properties. In many cases, however, perceptual-based crite- ria are the most relevant and systems need to be trained on or modeled after the perception of structural elements in music. Here, we investigate the perception of structural boundaries to Western popular music and examine the musical cues re- sponsible for their perception. We make links to music the- oretical descriptions of structural boundaries and to compu- tational methods for extracting structure. The methods and data presented here are useful for developing and training systems for the automatic extraction of musical structure as it is perceived by listeners."""
38,Eric Nichols;Christofer Raphael,Globally Optimal Audio Partitioning.,2006,https://doi.org/10.5281/zenodo.1416846,"Eric Nichols, Indiana University, USA, education;Christopher Raphael, Indiana University, USA, education","We present a technique for partitioning an audio ﬁle into maximally-sized segments having nearly uniform spec- tral content, ideally corresponding to notes or chords. Our method uses dynamic programming to globally optimize a measure of simplicity or homogeneity of the intervals in the partition. Here we have focused on an entropy-like mea- sure, though there is considerable ﬂexibility in choosing this measure. Experiments are presented for several musical scenarios."
39,Arshia Cont,Realtime Multiple Pitch Observation using Sparse Non-negative Constraints.,2006,https://doi.org/10.5281/zenodo.1416770,"Arshia Cont, Ircam, FRA, facility, Center for Research in Computing and the Arts, UCSD, USA, education","""In this paper we introduce a new approach for realtime multiple pitch observation of musical instruments. The proposed algorithm is quite different from others in the literature both in its purpose and approach. It is destined not for continuous multiple f0 recognition but rather for projection of the ongoing spectrum to learned pitch templates. The decomposition algorithm on the other hand, does not compromise signal processing models for pitches and consists of an algorithm for efficient decomposition of a spectrum using known pitch structures and based on sparse non-negative constraints. After introducing the algorithm along with evaluations, a real-time implementation of the algorithm is provided for free download for the MaxMSP realtime programming environment."""
40,Alexander Lerch,On the Requirement of Automatic Tuning Frequency Estimation.,2006,https://doi.org/10.5281/zenodo.1414812,"Alexander Lerch, zplane.development, DEU, company",The deviation of the tuning frequency from the standard tuning frequency 440 Hz is evaluated for a database of classical music. It is discussed if and under what circumstances such a deviation may affect the robustness of pitch-based systems for musical content analysis.
41,Anssi Klapuri,Multiple Fundamental Frequency Estimation by Summing Harmonic Amplitudes.,2006,https://doi.org/10.5281/zenodo.1416740,"Anssi Klapuri, Institute of Signal Processing, Tampere University of Technology, FIN, education","This paper proposes a conceptually simple and computationally efﬁcient fundamental frequency (F0) estimator for polyphonic music signals. The studied class of estimators calculate the salience, or strength, of a F0 candidate as a weighted sum of the amplitudes of its harmonic partials. A mapping from the Fourier spectrum to a “F0 salience spectrum” is found by optimization using generated training material. Based on the resulting function, three different estimators are proposed: a “direct” method, an iterative estimation and cancellation method, and a method that estimates multiple F0s jointly. The latter two performed as well as a considerably more complex reference method. The number of concurrent sounds is estimated along with their F0s."
42,Matti Ryynänen;Anssi Klapuri,Transcription of the Singing Melody in Polyphonic Music.,2006,https://doi.org/10.5281/zenodo.1418291,"Matti Ryynänen, Tampere University Of Technology, FIN, education;Anssi Klapuri, Tampere University Of Technology, FIN, education",This paper proposes a method for the automatic transcription of singing melodies in polyphonic music. The method is based on multiple-F0 estimation followed by acoustic and musicological modeling. The acoustic model consists of separate models for singing notes and for no-melody segments. The musicological model uses key estimation and note bigrams to determine the transition probabilities between notes. Viterbi decoding produces a sequence of notes and rests as a transcription of the singing melody. The performance of the method is evaluated using the RWC popular music database for which the recall rate was 63% and precision rate 46%. A significant improvement was achieved compared to a baseline method from MIREX05 evaluations.
43,Tim Pohle;Peter Knees;Markus Schedl;Gerhard Widmer,Independent Component Analysis for Music Similarity Computation.,2006,https://doi.org/10.5281/zenodo.1417877,"Tim Pohle, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, AUT, facility;Peter Knees, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, AUT, facility;Markus Schedl, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, AUT, facility;Gerhard Widmer, Johannes Kepler University Linz, AUT, education, Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, AUT, facility","In the recent years, a number of publications have ap- peared that deal with automatically calculating the similar- ity of music tracks. Most of them are based on features that are not intuitively understandable to humans, as they do not have a musically meaningful counterpart, but are merely measures of basic physical properties of the audio signal. Furthermore, most of these algorithms do not take into ac- count the temporal development of the audio signal, which certainly is an important aspect of music. All of them con- sider the musical signal as a whole, not trying to reconstruct the listening process of dividing the signal into a number of sources. In this work, we present a novel approach to ﬁll this gap by combining a number of existing ideas. At the heart of our approach, Independent Component Analysis (ICA) de- composes an audio signal into individual parts that appear maximally independent from each other. We present one basic algorithm to use these components for similarity com- putations, and evaluate a number of modiﬁcations to it with respect to genre classiﬁcation accuracy. Our results indicate that this approach is at least of similar quality as many ex- isting feature extraction routines."
44,Arpi Mardirossian;Elaine Chew,Music Summarization Via Key Distributions: Analyses of Similarity Assessment Across Variations.,2006,https://doi.org/10.5281/zenodo.1418295,"Arpi Mardirossian, University of Southern California Viterbi School of Engineering, USA, education;Elaine Chew, University of Southern California Viterbi School of Engineering, USA, education","""This paper presents a computationally efficient method
for quantifying the degree of tonal similarity between two
pieces of music. The properties we examine are key
frequencies and average time in key, and we propose two
metrics, based on the L
1 and L
2 norms, for quantifying
similarity using these descriptors. The methods are applied
to 711 classical themes and variations over 71 variation
sets by 10 composers of different genres. Quantile-quantile
plots and the Kolmogorov-Smirnov measure show that the
proposed metrics exhibit strongly distinct behaviour when
assessing pieces from the same variation set, and those that
are not. Comparisons across variation sets by the same
composer, and comparisons of pieces by different
composers although result in similar distributions, are
derived from fundamentally different underlying
distributions, according to the K-S measure. We present
probabilistic analyses of the two methods based on the
distributions derived empirically. When the discrimination
threshold is set at 55, the probabilities of Type I and Type
II errors are 18.41% and 20.56% respectively for Method
1, and 15.72% and 22.94% respectively for Method 2.
Method 1 has a success rate of 99.48% when labeling
pieces as dissimilar (not from the same variation set),
while the corresponding rate for Method 2 is 99.45%."""
45,Sally Jo Cunningham;David Bainbridge 0001;Annette Falconer,'More of an Art than a Science': Supporting the Creation of Playlists and Mixes.,2006,https://doi.org/10.5281/zenodo.1415662,"Sally Jo Cunningham, University of Waikato, NZL, education;David Bainbridge, University of Waikato, NZL, education;Annette Falconer, ","""This paper presents an analysis of how people construct playlists and mixes. Interviews with practitioners and postings made to a web site are analyzed using a grounded theory approach to extract themes and categorizations. The information sought is often encapsulated as music information retrieval tasks, albeit not as the traditional “known item search” paradigm. The collated data is analyzed and trends identified and discussed in relation to music information retrieval algorithms that could help support such activity."""
46,Alberto Novello;Martin F. McKinney;Armin Kohlrausch,Perceptual evaluation of music similarity.,2006,https://doi.org/10.5281/zenodo.1416700,"Alberto Novello, Philips Research Laboratories, NLD, company, Human Technology Interaction, Technische Universiteit Eindhoven, NLD, education;Martin F. McKinney, Philips Research Laboratories, NLD, company;Armin Kohlrausch, Philips Research Laboratories, NLD, company, Human Technology Interaction, Technische Universiteit Eindhoven, NLD, education","""This paper presents an empirical method for assessing music similarity on a set of stimuli using triadic comparisons in a balanced incomplete block design. We ﬁrst evaluated the consistency of subjects in their rankings and then the concordance across subjects. The concordance was also evaluated for different subject populations to assess the inﬂuence of experience of the subject with the musical material. We ﬁnally analysed subjects’ ranking by the means of multidimensional scaling. Similarity judgments were found to be rather concordant across subjects. Signiﬁcant differences between musicians and non-musicians and between subjects being familiar or non-familiar with the music were found for a small number of cases. Multidimensional scaling reveals a proximity of songs belonging to the same genre, congruent with the idea of genre being a perceptual dimension in subjects’ similarity ranking."""
47,Nuria Oliver;Lucas Kreger-Stickles,PAPA: Physiology and Purpose-Aware Automatic Playlist Generation.,2006,https://doi.org/10.5281/zenodo.1416794,"Nuria Oliver, Microsoft Research, USA, company;Lucas Kreger-Stickles, Microsoft Research, USA, company","In this paper we present PAPA, a novel approach for automatically generating playlists. The proposed framework utilizes the user’s physiological response to music, together with traditional song meta-data to generate a playlist the user will not only enjoy, but which will assist him or her in achieving various user-deﬁned goals (“purpose”). In addition to outlining the generic framework, we present an exemplary application named MPTrain that (1) creates a playlist in real-time to assist users in achieving speciﬁc exercise goals; and (2) incorporates the user’s physiological response to the music to determine the next song to play."
48,Douglas Turnbull;Luke Barrington;Gert R. G. Lanckriet,Modeling music and words using a multi-class naïve Bayes approach.,2006,https://doi.org/10.5281/zenodo.1415782,"Douglas Turnbull, UC San Diego, USA, education;Luke Barrington, UC San Diego, USA, education;Gert Lanckriet, UC San Diego, USA, education","""We propose a query-by-text system for modeling a heterogeneous data set of music and words. We quantitatively show that our system can both annotate a novel song with semantically meaningful words and retrieve relevant unlabeled songs from a database given a text-based query. We explain two feature extraction methods useful for summarizing the audio content of a song. We describe a supervised multi-class na¨ıve Bayes model and compare two parameter estimation techniques. Our approach is influenced by recent computer vision research on the related tasks of image annotation and retrieval."""
49,Markus Schedl;Tim Pohle;Peter Knees;Gerhard Widmer,Assigning and Visualizing Music Genres by Web-based Co-Occurrence Analysis.,2006,https://doi.org/10.5281/zenodo.1415176,"Markus Schedl, Johannes Kepler University, AUT, education, Austrian Research Institute for Artificial Intelligence, AUT, facility;Tim Pohle, Johannes Kepler University, AUT, education;Peter Knees, Johannes Kepler University, AUT, education;Gerhard Widmer, Johannes Kepler University, AUT, education, Austrian Research Institute for Artificial Intelligence, AUT, facility","We explore a simple, web-based method for predicting the
genre of a given artist based on co-occurrence analysis, i.e.
analyzing co-occurrences of artist and genre names on mu-
sic-related web pages. To this end, we use the page counts
provided by Google to estimate the relatedness of an arbi-
trary artist to each of a set of genres. We investigate four dif-
ferent query schemes for obtaining the page counts and two
different probabilistic approaches for predicting the genre
of a given artist. Evaluation is performed on two test collec-
tions, a large one with a quite general genre taxonomy and
a quite small one with rather speciﬁc genres.
Since our approach yields estimates for the relatedness of
an artist to every genre of a given genre set, we can de-
rive genre distributions which incorporate information about
artists that cannot be assigned a single genre. This allows
us to overcome the inﬂexible artist-genre assignment usu-
ally used in music information systems. We present a sim-
ple method to visualize such genre distributions with our
Traveller’s Sound Player. Finally, we brieﬂy outline how to
adapt the presented approach to extract other properties of
music artists from the web."
50,Gijs Geleijnse;Jan H. M. Korst,Web-Based Artist Categorization.,2006,https://doi.org/10.5281/zenodo.1417579,"Gijs Geleijnse, Philips Research, NLD, company;Jan Korst, Philips Research, NLD, company","""We present a novel approach in categorizing artists into subjective categories such as genre. We base our method on co-occurrences on the web, found with the Google search engine. A direct mapping between artists and categories proved to be unreliable. We use the categories mapped to closely related artists to obtain a more reliable mapping. The method is tested on a genre classification test set with convincing results. Moreover, mood categorization is explored using the same techniques."""
51,Eleanor Selfridge-Field,Social Cognition and Melodic Persistence: Where Metadata and Content Diverge.,2006,https://doi.org/10.5281/zenodo.1417699,"Eleanor Selfridge-Field, Stanford University, USA, education","The automatic retrieval of members of a tune family from a database of melodies is potentially complicated by well documented divergences between textual metadata and musical content. We examine recently reported cases of such divergences in search of musical features which persist even when titles change or the melodies themselves vary. We find that apart from meter and mode, the rate of preservation of searchable musical features is low. Social and gestural factors appear to play a varying role in establishing the “melodic” identity of widely transmitted songs. The rapid growth of social computing bring urgency to better understanding the different ways in which “same” or “similar” can be defined."
52,David Temperley,A Probabilistic Model of Melody Perception.,2006,https://doi.org/10.5281/zenodo.1414988,"David Temperley, Eastman School of Music, USA, education","This study presents a probabilistic model of melody 
perception, which infers the key of a melody and also 
judges the probability of the melody itself. (A “melody” is 
defined here as a sequence of pitches, without rhythmic 
information.) The model uses Bayesian reasoning. A 
generative probabilistic model is proposed, based on three 
principles: 1) melodies tend to remain within a narrow 
pitch range; 2) note-to-note intervals within a melody tend 
to be small; 3) notes tend to conform to a distribution (or 
“key-profile”) that depends on the key. The model is tested 
in three ways: on a key-finding task, on a melodic 
expectation task, and on an error-detection task."
53,Matija Marolt,A Mid-level Melody-based Representation for Calculating Audio Similarity.,2006,https://doi.org/10.5281/zenodo.1416252,"Matija Marolt, University of Ljubljana, SVN, education","We propose a mid-level melody-based representation that 
incorporates melodic, rhythmic and structural aspects of a 
music signal and is useful for calculating audio similarity 
measures. Most current approaches to music similarity use 
either low-level signal features, such as MFCCs that 
mostly capture timbral characteristics of music and contain 
little semantic information, or require symbolic representations, which are difficult to obtain from audio signals. The 
proposed mid-level representation is our attempt to bridge 
the gap between audio and symbolic domains by providing 
an integrated melodic, rhythmic and structural representation of music signals. The representation is based on a set 
of melodic fragments extracted from prominent melodic 
lines, it is beat-synchronous, which makes it independent 
of tempo variations and contains information on repetitions of short melodic phrases within the analyzed piece. 
We show how it can be calculated automatically from 
polyphonic audio signals and demonstrate its use for discovering melodic similarities between songs. We present 
results obtained by using the representation for finding 
different interpretations of songs in a music collection."
54,Sigurdur Sigurdsson;Kaare Brandt Petersen;Tue Lehn-Schiøler,Mel Frequency Cepstral Coefficients: An Evaluation of Robustness of MP3 Encoded Music.,2006,https://doi.org/10.5281/zenodo.1417149,"Sigurdur Sigurdsson, Technical University of Denmark, DNK, education;Kaare Brandt Petersen, Technical University of Denmark, DNK, education;Tue Lehn-Schiøler, Technical University of Denmark, DNK, education","""In large MP3 databases, ﬁles are typically generated with different parameter settings, i.e., bit rate and sampling rates. This is of concern for MIR applications, as encoding dif- ference can potentially confound meta-data estimation and similarity evaluation. In this paper we will discuss the in- ﬂuence of MP3 coding for the Mel frequency cepstral coe- ﬁcients (MFCCs). The main result is that the widely used subset of the MFCCs is robust at bit rates equal or higher than 128 kbits/s, for the implementations we have investi- gated. However, for lower bit rates, e.g., 64 kbits/s, the im- plementation of the Mel ﬁlter bank becomes an issue."""
55,Jerónimo Arenas-García;Jan Larsen;Lars Kai Hansen;Anders Meng,Optimal filtering of dynamics in short-time features for music organization.,2006,https://doi.org/10.5281/zenodo.1415078,"Jerónimo Arenas-García, Technical University of Denmark, DNK, education;Jan Larsen, Technical University of Denmark, DNK, education;Lars Kai Hansen, Technical University of Denmark, DNK, education;Anders Meng, Technical University of Denmark, DNK, education","There is an increasing interest in customizable methods for organizing music collections. Relevant music characterization can be obtained from short-time features, but it is not obvious how to combine them to get useful information. In this work, a novel method, denoted as the Positive Constrained Orthonormalized Partial Least Squares (POPLS), is proposed. Working on the periodograms of MFCCs time series, this supervised method finds optimal filters which pick up the most discriminative temporal information for any music organization task. Two examples are presented in the paper, the first being a simple proof-of-concept, where an altosax with and without vibrato is modelled. A more complex 11 music genre classification setup is also investigated to illustrate the robustness and validity of the proposed method on larger datasets. Both experiments showed the good properties of our method, as well as superior performance when compared to a fixed filter bank approach suggested previously in the MIR literature. We think that the proposed method is a natural step towards a customized MIR application that generalizes well to a wide range of different music organization tasks."
56,Kazuyoshi Yoshii;Masataka Goto;Kazunori Komatani;Tetsuya Ogata;Hiroshi G. Okuno,Hybrid Collaborative and Content-based Music Recommendation Using Probabilistic Model with Latent User Preferences.,2006,https://doi.org/10.5281/zenodo.1416826,"Kazuyoshi Yoshii, Graduate School of Informatics, Kyoto University, JPN, education;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Kazunori Komatani, Graduate School of Informatics, Kyoto University, JPN, education;Tetsuya Ogata, Graduate School of Informatics, Kyoto University, JPN, education;Hiroshi G. Okuno, Graduate School of Informatics, Kyoto University, JPN, education","""This paper presents a hybrid music recommendation method that solves problems of two prominent conventional methods: collaborative ﬁltering and content-based recommendation. The former cannot recommend musical pieces that have no ratings because recommendations are based on actual user ratings. In addition, artist variety in recommended pieces tends to be poor. The latter, which recommends musical pieces that are similar to users’ favorites in terms of music content, has not been fully investigated. This induces unreliability in modeling of user preferences; the content similarity does not completely reﬂect the preferences. Our method integrates both rating and content data by using a Bayesian network called an aspect model. Unobservable user preferences are directly represented by introducing latent variables, which are statistically estimated. To verify our method, we conducted experiments by using actual audio signals of Japanese songs and the corresponding rating data collected from Amazon. The results showed that our method outperforms the two conventional methods in terms of recommendation accuracy and artist variety and can reasonably recommend pieces even if they have no ratings."""
57,Masatoshi Hamanaka,Music Scope Headphones: Natural User Interface for Selection of Music.,2006,https://doi.org/10.5281/zenodo.1416566,"Masatoshi Hamanaka, Japan Science and Technology Agency, JPN, facility;Seunghee Lee, University of Tsukuba, JPN, education","This paper describes a novel audio only interface for selecting music which enables us to select songs without having to click a mouse. Using previous music players with normal headphones, we can hear only one song at a time and we thus have to play pieces individually to select the one we want to hear from numerous new music files, which involves a large number of mouse operations. The main advantage of our headphones is that they detect natural movements, such as the head or hand moving when users are listening to music and they can focus on a particular musical source that they want to hear. By moving their head left or right, listeners can hear the source from a frontal position as the digital compass detects the change in the direction they are facing. By looking up or down, the tilt sensor will detect the change in the face’s angle of elevation; they can better hear the source that is allocated to a more distant or closer position. By putting their hand behind their ear, listeners can adjust the focus sensor on the headphones to focus on a particular musical source that they want to hear."
58,Nik Corthaut;Sten Govaerts;Erik Duval,Moody Tunes: The Rockanango Project.,2006,https://doi.org/10.5281/zenodo.1418211,"Nik Corthaut, K.U. Leuven, BEL, education;Sten Govaerts, K.U. Leuven, BEL, education;Erik Duval, K.U. Leuven, BEL, education","""Wouldn’t it be nice if we had a tool that could offer people the right music for a specific time and place? For HORECA (hotel, restaurants and cafés) businesses, providing appropriate music is often not just nice, but essential. Typically this boils down to music that matches a certain situation on desired atmospheres, this will be defined as a musical context (MC). The developed tool, a music player, meeting the specific needs of HORECA, allows creation and management of those contexts. The user creates a musical context by selecting a number of appropriate atmospheres and can fine-tune the context with additional musical properties. The atmospheres are defined by a group of music experts, composed of DJ’s, music teachers, musicians, etc., who also manually annotate the properties of all musical content. To assist the music experts, a specially developed tool allows them to categorise and annotate the songs and evaluate their results. We provide insight on how we constructed and implemented our metadata schema and look at some existing schemas. The evaluation shows the economic value of such a system in the specific context of a HORECA business."""
59,John F. Woodruff;Bryan Pardo;Roger B. Dannenberg,Remixing Stereo Music with Score-Informed Source Separation.,2006,https://doi.org/10.5281/zenodo.1414898,"John Woodruff, Northwestern University, USA, education;Bryan Pardo, Northwestern University, USA, education;Roger Dannenberg, Carnegie Mellon University, USA, education","Musicians and recording engineers are often interested in manipulating and processing individual instrumental parts within an existing recording to create a remix of the recording. When individual source tracks for a stereo mixture are unavailable, remixing is typically difficult or impossible, since one cannot isolate the individual parts. We describe a method of informed source separation that uses knowledge of the written score and spatial information from an anechoic, stereo mixture to isolate individual sound sources, allowing remixing of stereo mixtures without access to the original source tracks. This method is tested on a corpus of string quartet performances, artificially created using Bach four-part chorale harmonizations and sample violin, viola and cello recordings. System performance is compared in cases where the algorithm has knowledge of the score and those in which it operates blindly.  The results show that source separation performance is markedly improved when the algorithm has access to a well-aligned score."
60,Tue Lehn-Schiøler;Jerónimo Arenas-García;Kaare Brandt Petersen;Lars Kai Hansen,A Genre Classification Plug-in for Data Collection.,2006,https://doi.org/10.5281/zenodo.1416202,"Tue Lehn-Schiøler, The Technical University of Denmark, DNK, education;Jerónimo Arenas-García, The Technical University of Denmark, DNK, education;Kaare Brandt Petersen, The Technical University of Denmark, DNK, education;Lars Kai Hansen, The Technical University of Denmark, DNK, education","""This demonstration illustrates how the methods developed in the MIR community can be used to provide real-time feedback to music users. By creating a genre classiﬁer plug-in for a popular media player we present users with rele- vant information as they play their songs. The plug-in can furthermore be used as a data collection platform. After informed consent from a selected set of users the plug-in will report on music consumption behavior back to a central server."""
61,Vegard Sandvold;Thomas Aussenac;Òscar Celma;Perfecto Herrera,Good Vibrations: Music Discovery through Personal Musical Concepts.,2006,https://doi.org/10.5281/zenodo.1418275,"Vegard Sandvold, Universitat Pompeu Fabra, ESP, education;Thomas Aussenac, Universitat Pompeu Fabra, ESP, education;`Oscar Celma, Universitat Pompeu Fabra, ESP, education;Perfecto Herrera, Universitat Pompeu Fabra, ESP, education","We present here Good Vibrations, a tool for music tagging,
exploration and discovery, shaped as a media player plugin,
and intended for home users. The plugin allows the quick
”invention” of concepts and properties that can be tagged
to songs. After some hours of active tagging, the plugin
starts automatically proposing the proper tags to the user,
who is also allowed to correct them. The plugin generates
playlists according to the user-deﬁned concepts, and recom-
mends related music either from the user’s personal collec-
tion or from the Internet (through it’s connection to Foaﬁng
the Music). The plugin runs, for the moment, in Nullsoft
Winamp on Windows XP systems."
62,Chris Cannam;Christian Landone;Mark B. Sandler;Juan Pablo Bello,The Sonic Visualiser: A Visualisation Platform for Semantic Descriptors from Musical Signals.,2006,https://doi.org/10.5281/zenodo.1416388,"Chris Cannam, Centre for Digital Music, Queen Mary University of London, GBR, education;Christian Landone, Centre for Digital Music, Queen Mary University of London, GBR, education;Mark Sandler, Centre for Digital Music, Queen Mary University of London, GBR, education;Juan Pablo Bello, Centre for Digital Music, Queen Mary University of London, GBR, education","Sonic Visualiser is the name for an implementation of a 
system to assist study and comprehension of the contents 
of audio data, particularly of musical recordings.
It is a C++  application  with  a Qt4 GUI that  runs  on 
Windows,  Mac,  and  Linux.  It  embodies  a  number  of 
concepts which are intended to improve interaction with 
audio data and features, most notably with respect to the 
representation  of  time-synchronous  information.  The 
architecture of the application allows for easy integration 
of third  party algorithms for the extraction of low and 
mid-level features from musical audio data. This paper 
describes  some  basic  principles  and  functionalities  of 
Sonic Visualiser."
63,Steven van de Par;Martin F. McKinney;André Redert,Musical Key Extraction from Audio Using Profile Training.,2006,https://doi.org/10.5281/zenodo.1417879,"Steven van de Par, Philips Research Laboratories Eindhoven, NLD, facility;Martin McKinney, Philips Research Laboratories Eindhoven, NLD, facility;André Redert, Philips Research Laboratories Eindhoven, NLD, facility","A new method is presented for extracting the musical key from raw audio data. The method is based on the extraction of chromagrams using a new approach for tonal component selection taking into account auditory masking. The extracted chromagrams were used to train three key profiles for major and three key profiles for minor keys. The three trained key profiles differ in their temporal weighting of information across the duration of the song. One profile is based on uniform weighting while the other two apply emphasis on the beginning and ending of the song, respectively. The actual key extraction is based on comparing the key profiles with three average chromagrams that were extracted from a particular piece of music using the same temporal weighting functions as used for the key profile training. A correct key classification of 98% was achieved using non-overlapping test and training sets drawn from a larger set of 237 CD recordings of classical piano sonatas."
64,Martijn Bosma;Remco C. Veltkamp;Frans Wiering,Muugle: A Modular Music Information Retrieval Framework.,2006,https://doi.org/10.5281/zenodo.1415916,"Martijn Bosma, Utrecht University, NLD, education;Remco C. Veltkamp, Utrecht University, NLD, education;Frans Wiering, Utrecht University, NLD, education","""Muugle (Musical Utrecht University Global Lookup Engine) is a modular framework that allows the comparison of different MIR techniques and usability studies. A system overview and a discussion of a pilot usability experiment are given. A demo version of the framework can be found on http://give-lab.cs.uu.nl/muugle."""
65,Jörg Garbers,An Integrated MIR Programming and Testing Environment.,2006,https://doi.org/10.5281/zenodo.1414864,"Jörg Garbers, Utrecht University, NLD, education","The process of shaping a music information retrieval algorithm is highly connected with implementing it and testing suitable parameterizations. Often music information retrieval scientists do not have a programmer at hand and must implement their experimental setup themselves. This paper describes an integrated tool setup OHR consisting of the music (analysis) systems OpenMusic, Humdrum and Rubato and a system for form based parametrization and comparison of algorithms. These packages and their programming environments provide the scientist with frameworks and existing libraries for implementing and testing algorithms. They differ in the programming languages that they support and in the type of testing user interfaces that they allow the scientist to build easily. The systems and their components are integrated by using their scripting languages. We sketch an example of the integrated use of these systems."
66,Dirk Moelants;Olmo Cornelis;Marc Leman;Jos Gansemans;Rita M. M. De Caluwe;Guy De Tré;Tom Matthé;Axel Hallez,Problems and Opportunities of Applying Data- & Audio-Mining Techniques to Ethnic Music.,2006,https://doi.org/10.5281/zenodo.1417787,"Dirk Moelants, Ghent University, BEL, education;Olmo Cornelis, Ghent University, BEL, education;Marc Leman, Ghent University, BEL, education;Jos Gansemans, Royal Museum of Central-Africa, BEL, facility;Rita De Caluwe, Ghent University, BEL, education;Guy De Tré, Ghent University, BEL, education;Tom Matthé, Ghent University, BEL, education;Axel Hallez, Ghent University, BEL, education","Current research in music information retrieval focuses on Western music. In music from other cultures, both musical structures and thinking about music can be very different. This creates problems for both the analysis of musical features and the construction of databases. On the other hand, a well-documented digitization offers interesting opportunities for the study and spread of ‘endangered’ music. Here, some general problems regarding the digital indexation of ethnic music are given, illustrated with a method for describing pitch structure, comparing Western standards with African music found in the digitization of the archives of the Royal Museum of Central-Africa in Tervuren (Brussels)."
67,Beatriz Magalhães Castro;Luiza Beth Nunes Alonso;Edilson Ferneda;Murilo Bastos da Cunha;Fernando William Cruz;Márcio da Costa P. Brandão,BDB-MUS: a project for the preservation of Brazilian musical heritage.,2006,https://doi.org/10.5281/zenodo.1414998,"Beatriz Magalhães Castro, University of Brasilia, BRA, education;Luiza Beth Nunes Alonso, Catholic University of Brasilia, BRA, education;Edilson Ferneda, Catholic University of Brasilia, BRA, education;Murilo Bastos da Cunha, University of Brasilia, BRA, education;Fernando William Cruz, University of Brasilia, BRA, education;Márcio da Costa P. Brandão, University of Brasilia, BRA, education","""This poster proposes a discussion on concepts evolving 
from the role of digital libraries on the preservation of tan-
gible and intangible cultural inheritance, including con-
cepts developed in 2003 by UNESCO and the World 
Summit on the Information Society. It further describes the 
construction and design process leading to the develop-
ment of BDB-MUS – Brazilian Digital Music Library, 
which aims to establish national recommendations on 
metadata attributions, and to develop means for appropria-
tion and retrieval of musical sources. The poster further 
explores the concept of digital music or culture within the 
aims and objectives of the project."""
68,Rebecca Fiebrink;Ichiro Fujinaga,Feature Selection Pitfalls and Music Classification.,2006,https://doi.org/10.5281/zenodo.1415144,"Rebecca Fiebrink, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","Previous work has employed an approach to the evaluation of wrapper feature selection methods that may overstate their ability to improve classification accuracy, because of a phenomenon akin to overfitting. This paper discusses this phenomenon in the context of recent work in machine learning, demonstrates that previous work in MIR has indeed exaggerated the efficacy of feature selection for music classification, and presents new testing providing a more realistic analysis of feature selection’s impact on music classification accuracy."
69,Shyamala Doraisamy;Hamdan Adnan;Noris Mohd. Norowi,Towards a MIR System for Malaysian Music.,2006,https://doi.org/10.5281/zenodo.1414744,"Shyamala Doraisamy, University Putra Malaysia, MYS, education;Hamdan Adnan, National Arts Academy, Ministry of Culture, Arts and Heritage, MYS, facility;Noris Mohd. Norowi, University Putra Malaysia, MYS, education","Systems for the archival of musical documents digitally and development of digital music libraries are currently being researched and developed extensively.  However, adapting these systems for the archival and retrieval of Malaysian music materials might not be as straightforward due to the distinct differences in musical structure and modes of non-Western music.  This paper covers the motivations for the creation of a MIR system for Malaysian Music and outlines the plans for its development."
70,Frank Seifert 0001;Katharina Rasch;Michael Rentzsch,Tempo Induction by Stream-Based Evaluation of Musical Events.,2006,https://doi.org/10.5281/zenodo.1418181,"Frank Seifert, University of Technology, Chemnitz, DEU, education;Katharina Rasch, University of Technology, Chemnitz, DEU, education;Michael Rentzsch, University of Technology, Chemnitz, DEU, education","We present an approach for tempo induction that is based 
on a more perception-oriented analysis of inter-onset 
intervals. Therefore we utilize auditory grouping concepts 
and define some rules for their formation. Finally, we 
show preliminary results that confirm our aim of 
improving the quality of tempo induction by reducing the 
amount of perceptually irrelevant data.  "
71,Kurt Jacobson,A Multifaceted Approach to Music Similarity.,2006,https://doi.org/10.5281/zenodo.1417016,"Kurt Jacobson, University of Miami, USA, education","Previous work has explored the concept of music similarity measures and a variety of methods have been proposed for calculating such measures.  This paper describes a system for music similarity which attempts to model and compare some of the more musically salient features of a set of audio signals.  A model for timbre and a model for rhythm are implemented directly from previous work, and a model for song structure is developed. The different models are weighted and combined to provide an overall music similarity measure.  The system is tested on a small set of popular music files spanning eleven different genres.  The system is tuned to estimate genre boundaries using multidimensional scaling – a technique that allows for quick visualization of similarity data.  An “automatic DJ” application, that generates playlists based on the music similarity models, serves as a subjective evaluation for the system."
72,Matthias Eichner;Matthias Wolff;Rüdiger Hoffmann,Instrument classification using Hidden Markov Models.,2006,https://doi.org/10.5281/zenodo.1414960,"Matthias Eichner, Technische Universität Dresden, DEU, education;Matthias Wolff, Technische Universität Dresden, DEU, education;Rüdiger Hoffmann, Technische Universität Dresden, DEU, education","In this paper we present ﬁrst results on musical instrument classiﬁcation using an HMM based recognizer. The ﬁnal goal of our work is to automatically evaluate instruments and to classify them according to their characteristics. The ﬁrst step in this direction was to train a system that is able to recognize a particular instrument among others of the same kind (e.g. guitars). The recognition is based on solo music pieces played on the instrument under various conditions. For this purpose a database was designed and is currently being recorded that comprises four instrument types: classical guitar, violin, trumpet and clarinet. We brieﬂy describe the classiﬁer and give ﬁrst experimental results on the classiﬁcation of acoustic guitars."
73,Rudolf Mayer;Thomas Lidy;Andreas Rauber,The Map of Mozart.,2006,https://doi.org/10.5281/zenodo.1416060,"Rudolf Mayer, Vienna University of Technology, AUT, education;Thomas Lidy, Vienna University of Technology, AUT, education;Andreas Rauber, Vienna University of Technology, AUT, education","We present a study on using a Mnemonic Self-Organizing Map for clustering a very homogeneous collection of music. In particular, we create a map containing the complete works of Wolfgang Amadeus Mozart. We study and analyze the clustering capabilities of the SOM on this very focused collection. We furthermore present a web-based application for exploring the map and accessing the music it represents."
74,Morteza Dehghani;Andrew M. Lovett,Efficient Genre Classification using Qualitative Representations.,2006,https://doi.org/10.5281/zenodo.1416964,"Morteza Dehghani, Northwestern University, USA, education;Andrew M. Lovett, Northwestern University, USA, education","""We have constructed a system that can compute a qualitative representation of music from high-level features extracted from MusicXML files. We use two cognitively motivated computational models called SME and SEQL to build generalizations of musical genres from these representations. We then categorize novel music pieces according to the generalizations. We demonstrate the feasibility of the system with training sets much smaller than those used in previous systems."""
75,Margaret Cahill;Donncha O'Maidín,Assessing the Performance of Melodic Similarity Algorithms Using Human Judgments of Similarity.,2006,https://doi.org/10.5281/zenodo.1417997,"Margaret Cahill, University of Limerick, IRL, education;Donncha Ó Maidín, University of Limerick, IRL, education","""This paper outlines a project to identify reliable algorithms for measuring melodic similarity by using melodies extracted from a piece of music in Theme and Variations form, for which human judgements of similarity have been gathered."""
76,Ian Leue;Özgür Izmirli,Tempo Tracking With a Periodicity Comb Kernel.,2006,https://doi.org/10.5281/zenodo.1416266,"Ian Leue, Connecticut College, USA, education;Ozgur Izmirli, Connecticut College, USA, education","""Automatic tempo extraction and beat tracking from audio 
is an important ability, with many applications in music 
information retrieval. This paper describes a method for 
tempo tracking which builds on current research in the 
field. In this algorithm, an autocorrelation surface is 
calculated from the output of a spectral energy flux onset 
novelty function. The most salient repetition rate is 
calculated by cross-correlating dilations of a comb-like 
prototype spanning multiple frames and the autocorrelation 
surface. The method addresses tempo tracking through 
time to account for pieces with variable tempos. In order to 
compare the performance of our method on music with 
strong and weak percussive onsets we have evaluated it on 
both classical music with and without percussion and 
popular music with percussion. Additionally, beats are 
phase-aligned and superimposed on the signal for aural 
evaluation. Results show the comb kernel to be a useful 
feature in determining the correct beat level."""
77,Masataka Goto,AIST Annotation for the RWC Music Database.,2006,https://doi.org/10.5281/zenodo.1418125,"Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility","In this paper, we introduce our activities regarding the manual annotation of the musical pieces of the RWC Music Database. Although the RWC Music Database is widely used, its annotated descriptions are not widely available. We therefore annotated a set of music-scene descriptions consisting of the beat structure, melody line, and chorus sections. We call this AIST Annotation. We also manually synchronized standard MIDI files with the corresponding audio signals at the beat level. We hope that the AIST Annotation will contribute to further advances in the field of music information processing."
78,Matthew D. Hoffman;Perry R. Cook,"Feature-Based Synthesis: A Tool for Evaluating, Designing, and Interacting with Music IR Systems.",2006,https://doi.org/10.5281/zenodo.1417515,"Matt Hoffman, Princeton University, USA, education;Perry R. Cook, Princeton University, USA, education","""We present a general framework for performing feature-based synthesis – that is, for producing audio characterized by arbitrarily specified sets of perceptually motivated, quantifiable acoustic features of the sort used in many music information retrieval systems."""
79,Ajay Kapur;Eric Singer,A Retrieval Approach for Human/Robotic Musical Performance.,2006,https://doi.org/10.5281/zenodo.1414894,"Matt Hoffman, Princeton University, USA, education;Perry R. Cook, Princeton University, USA, education","""We present a general framework for performing feature-based synthesis – that is, for producing audio characterized by arbitrarily specified sets of perceptually motivated, quantifiable acoustic features of the sort used in many music information retrieval systems."""
80,Òscar Celma;Pedro Cano;Perfecto Herrera,Search Sounds: An audio crawler focused on weblogs.,2006,https://doi.org/10.5281/zenodo.1415142,"Oscar Celma, Universitat Pompeu Fabra, ESP, education;Pedro Cano, Universitat Pompeu Fabra, ESP, education;Perfecto Herrera, Universitat Pompeu Fabra, ESP, education","""In this paper we present a focused audio crawler that mines audio weblogs (MP3 blogs). This source of semi-structured information contains links to audio ﬁles, plus some textual information that is referring to the media ﬁle. A retrieval system —that exploits the mined data— fetches relevant audio ﬁles related to user’s text query. Based on these results, the user can navigate and discover new music by means of content-based audio similarity. The system is available at: http://www.searchsounds.net."""
81,Elias Pampalk;Masataka Goto,MusicRainbow: A New User Interface to Discover Artists Using Audio-based Similarity and Web-based Labeling.,2006,https://doi.org/10.5281/zenodo.1417313,"Elias Pampalk, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Masataka Goto, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility","""In this paper we present MusicRainbow which is a simple interface for discovering artists where colors encode different types of music. MusicRainbow is based on a new audio-based approach to compute artist similarity. This approach scores 15 percentage points higher in a genre classification task than the similarity computed on track level. Using a traveling salesman algorithm, similar artists are mapped near each other on a circular rainbow. Furthermore, we present a new approach of combining this audio-based information with information from the web. In particular, we label the rainbow and summarize the artists with words extracted from web pages related to the artists. We use different vocabularies for different hierarchical levels and heuristics to select the most descriptive labels. We conclude with a discussion of the results. The first impressions are very promising."""
82,Gijs Geleijnse;Jan H. M. Korst,Efficient Lyrics Extraction from the Web.,2006,https://doi.org/10.5281/zenodo.1415982,"Gijs Geleijnse, Philips Research, NLD, company;Jan Korst, Philips Research, NLD, company","""We present a novel method to extract lyrics from the Web. The aim is to extract a set of multiple versions of the lyrics to a song. Lyrics can be identiﬁed within a text by a regular expression. We use a projection of a document to efﬁciently identify lyrics within the document by mapping it to a regu- lar expression. We describe a method to cluster the multiple versions of the lyrics by ﬁltering out erroneous texts such as lyrics to other songs. For reasons of efﬁciency, we do this by comparing ﬁngerprints instead of the texts themselves."""
83,Jin Ha Lee;M. Cameron Jones;J. Stephen Downie,Factors Affecting Response Rates for Real-Life MIR Queries.,2006,https://doi.org/10.5281/zenodo.1416840,"Jin Ha Lee, University of Illinois at Urbana-Champaign, USA, education;M. Cameron Jones, University of Illinois at Urbana-Champaign, USA, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education","""In this poster we present preliminary findings of an exploratory study of natural language music information queries posted to the Google Answers web site. We discuss the proportion of queries answered as a function of time and attempt to identify factors which affect the probability of a query being answered."""
84,Peter van Kranenburg,Composer attribution by quantifying compositional strategies.,2006,https://doi.org/10.5281/zenodo.1415062,"Peter van Kranenburg, Utrecht University, NLD, education","Taking a theory of musical style, developed by Leonard B. Meyer, as a starting point, an experiment is described in which statistical pattern recognition algorithms are used to characterize a particular musical style with respect to other styles. The resulting description can be used in authorship discussions. In the current study, a number of disputed or- gan works from the Bach catalog is used to illustrate the possibilities of this approach."
85,Jochen Schwenninger;Raymond Brueckner;Daniel Willett;Marcus E. Hennecke,Language Identification in Vocal Music.,2006,https://doi.org/10.5281/zenodo.1416574,"Jochen Schwenninger, University of Ulm, DEU, education;Raymond Brueckner, Harman/Becker Automotive Systems, DEU, company;Daniel Willett, Harman/Becker Automotive Systems, DEU, company;Marcus Hennecke, Harman/Becker Automotive Systems, DEU, company","Language identiﬁcation is an important ﬁeld in spoken lan- guage processing. The identiﬁcation of the language sung or spoken in music, however, has attracted only minor attention so far. This, however, is an important task when it comes to categorizing, classifying and labelling of music data. In this paper, we review our efforts of transferring well- established techniques from spoken language identiﬁcation to the area of language identiﬁcation in music. We present results of distinguishing German and English sung modern music and propose and evaluate techniques designed for im- proving the classiﬁcation performance. These techniques involve limiting the classiﬁcation on song segments that ap- pear to have vocals and on frames that are not distorted by heavy beat onsets."
86,Beinan Li;John Ashley Burgoyne;Ichiro Fujinaga,Extending Audacity for Audio Annotation.,2006,https://doi.org/10.5281/zenodo.1417963,"Beinan Li, McGill University, CAN, education;John Ashley Burgoyne, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","By implementing a cached region selection scheme and automatic label completion, we extended an open-source audio editor to become a more convenient audio annotation tool for tasks such as ground-truth annotation for audio and music classification. A usability experiment was conducted with encouraging preliminary results."
87,Audrey Laplante;J. Stephen Downie,Everyday Life Music Information-Seeking Behaviour of Young Adults.,2006,https://doi.org/10.5281/zenodo.1417957,"Audrey Laplante, McGill University, CAN, education;J. Stephen Downie, University of Illinois at Urbana-Champaign, USA, education","""This poster presents the preliminary results of an ongoing qualitative study on the everyday-life music information-seeking behaviour of young adults. The data were collected through in-depth interviews and analyzed following a grounded theory approach. The analysis showed a strong penchant for informal channels (e.g., friends, relative) and, conversely, a distrust of experts. It also emerged that music seeking was mostly motivated by curiosity rather than by actual information needs, which in turn explains why browsing is such a popular strategy."""
88,Cynthia M. Grund,A Philosophical Wish List for Research in Music Information Retrieval.,2006,https://doi.org/10.5281/zenodo.1415190,"Cynthia M. Grund, University of Southern Denmark, DNK, education","Within a framework provided by the traditional trio consisting of metaphysics, epistemology and ethics, a first stab is made at a wish list for MIR-research from a philosophical point of view. Since the tools of MIR are equipped to study language and its use from a purely sonic standpoint, MIR research could result in another revealing revolution within the linguistic turn in philosophy."
89,Daniel McEnnis;Cory McKay;Ichiro Fujinaga,jAudio: Additions and Improvements.,2006,https://doi.org/10.5281/zenodo.1416838,"Daniel McEnnis, McGill University, CAN, education;Cory McKay, McGill University, CAN, education;Ichiro Fujinaga, McGill University, CAN, education","jAudio is an application designed to extract features for use in a variety of MIR tasks. It eliminates the need for re-implementing existing feature extraction algorithms and provides a framework that greatly facilitates the development and deployment of new features. Three classes of features are presented and explained—features, metafeatures, and aggregators. A detailed description of jAudio’s dependency resolution algorithm is also discussed. Finally, ways in which jAudio can be embedded in and integrated with new systems are discussed, along with a description of jAudio’s ability to add new features or aggregators, potentially at runtime."
90,Stephen Sinclair;Michael Droettboom;Ichiro Fujinaga,Lilypond for pyScore: Approaching a universal translator for music notation.,2006,https://doi.org/10.5281/zenodo.1418245,"Stephen Sinclair, Schulich School of Music, McGill University, CAN, education;Michael Droettboom, ;Ichiro Fujinaga, Schulich School of Music, McGill University, CAN, education","""Several languages for music notation have been deﬁned in recent years. pyScore, a framework for translating between notation formats, and new module for it which can generate input for the LilyPond music engraving system are described. This shows the potential for developing pyScore into a “universal translator” for musical scores."""
91,Elias Pampalk;Martin Gasser,An Implementation of a Simple Playlist Generator Based on Audio Similarity Measures and User Feedback.,2006,https://doi.org/10.5281/zenodo.1415130,"Elias Pampalk, National Institute of Advanced Industrial Science and Technology (AIST), JPN, facility;Martin Gasser, Austrian Research Institute for Artificial Intelligence (OFAI), AUT, facility","""This paper presents an implementation of a simple playlist generator. An audio-based music similarity measure and simple heuristics are used to create playlists given minimum user input. The ultimate goal of this work is to conduct a ﬁeld study, i.e., to run the system on the users’ personal collection and study the usage behavior over a longer period of time. The functions include, for example, allowing the user to control the variance of the playlists in terms of how often the same song or songs from the same artists are repeated."""
92,Rosemary Mountain,Name that mood! Describe that tune! Invitation to the IMP.,2006,https://doi.org/10.5281/zenodo.1418187,"Rosemary Mountain, Concordia University, CAN, education","The ongoing research project The Interactive Multimedia Playroom (IMP) was established to stimulate discourse about issues relating to our perception and description of sounds in artistic and multimedia contexts. Although it was originally conceived to help develop better analytical tools for music, the unique and playful design is well-adapted to helping establish common references for potential collaborators in media arts.  As the team working on the project development includes experts in psychology as well as creative artists and theorists, the format of the project is being designed to maximize its transfer to psychological studies.  Unlike most psychological studies, however, we are particularly interested in the reactions of those intimately involved in the arts, and ask participants to comment on the suitability of the terminology, perceived relevance of the questions, etc.  It is believed that the issues being addressed by the project are fundamental ones which could have high relevance for MIR research, including descriptors, sound-image associations, and the recognition of salient characteristics of a musical excerpt."
93,Youngmoo E. Kim;Donald S. Williamson;Sridhar Pilli,"Towards Quantifying the ""Album Effect"" in Artist Identification.",2006,https://doi.org/10.5281/zenodo.1415722,"Youngmoo E. Kim, Drexel University, USA, education;Donald S. Williamson, Drexel University, USA, education;Sridhar Pilli, Drexel University, USA, education","Recent systems for automatically identifying the perform-
ing artist from the acoustic signal of music have demon-
strated reasonably high accuracy when discriminating be-
tween hundreds of known artists. A well-documented issue,
however, is that the performance of these systems degrades
when music from different albums is used for training and
evaluation. Conversely, accuracy improves when systems
are trained and evaluated using music from the same album.
This performance characteristic has been labeled the “album
effect”. The unfortunate corollary to this result is that the
classiﬁcation results of these systems are based not entirely
on the music itself, but on other audio features common to
the album that may be unrelated to the underlying music.
We hypothesize that one of the primary reasons for this phe-
nomenon is the production process of commercial record-
ings, speciﬁcally, post-production. Understanding the pri-
mary aspects of post-production, we can attempt to model
its effect on the acoustic features used for classiﬁcation. By
quantifying and accounting for this transformation, we hope
to improve future systems for automatic artist identiﬁcation."
94,Janto Skowronek;Martin F. McKinney;Steven van de Par,Ground truth for automatic music mood classification.,2006,https://doi.org/10.5281/zenodo.1416696,"Janto Skowronek, Philips Research Laboratories, NLD, facility;Martin F. McKinney, Philips Research Laboratories, NLD, facility;Steven van de Par, Philips Research Laboratories, NLD, facility","Automatic music classification based on audio signals provides a core technology for tools that help users to manage and browse their music collections. Since “mood” is also used as a browsing criterium, automatic mood classification could support the creation of the necessary metadata. We have developed a method to obtain a reliable “ground truth” database for automatic music mood classification. Our results confirm that excerpt selection is a non-trivial issue and that there are some mood labels that are relatively consistent across subjects."
95,Adi Ruppin;Hezy Yeshurun,MIDI Music Genre Classification by Invariant Features.,2006,https://doi.org/10.5281/zenodo.1415744,"Adi Ruppin, Tel Aviv University, ISR, education;Hezy Yeshurun, Tel Aviv University, ISR, education","MIDI music genre classification methods are largely 
based on generic text classification techniques. We 
attempt to leverage music domain knowledge in order to 
improve classification results. 
We combine techniques of selection and extraction of 
musically invariant features with classification using 
compression distance similarity metric, which is an 
approximation of the theoretical, yet computationally 
intractable, Kolmogorov complexity.  
We introduce several methods for extracting features 
which are invariant under certain transformations 
commonly found in music. These methods, combined 
with data compression, generate a lossy compressed 
representation which attempts to preserve feature 
invariance. We analyze the performance of each method, 
thus gaining insight into the features that are significant to 
the human perception of music."
